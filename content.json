{"meta":{"title":"晓风残月的博客","subtitle":"晓风残月","description":"个人技术的一些积累","author":"晓风残月","url":"http://www.baiyp.ren"},"pages":[{"title":"所有分类","date":"2019-08-22T02:23:57.116Z","updated":"2019-08-22T02:23:57.116Z","comments":true,"path":"categories/index.html","permalink":"http://www.baiyp.ren/categories/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2019-08-22T02:23:47.798Z","updated":"2019-08-22T02:23:47.798Z","comments":true,"path":"tags/index.html","permalink":"http://www.baiyp.ren/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"JAVA中的死锁","slug":"JAVA中的死锁","date":"2019-08-28T07:33:17.000Z","updated":"2019-08-28T10:16:25.687Z","comments":true,"path":"JAVA中的死锁.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的死锁.html","excerpt":"","text":"JAVA中的死锁什么是死锁​ 在多线程环境中，多个进程可以竞争有限数量的资源。当一个进程申请资源时，如果这时没有可用资源，那么这个进程进入等待状态。有时，如果所申请的资源被其他等待进程占有，那么该等待进程有可能再也无法改变状态。这种情况称为死锁​ 在Java中使用多线程，就会有可能导致死锁问题。死锁会让程序一直卡住，不再程序往下执行。我们只能通过中止并重启的方式来让程序重新执行。造成死锁的原因当前线程拥有其他线程需要的资源当前线程等待其他线程已拥有的资源都不放弃自己拥有的资源死锁的必要条件互斥​ 进程要求对所分配的资源（如打印机）进行排他性控制，即在一段时间内某资源仅为一个进程所占有。此时若有其他进程请求该资源，则请求进程只能等待。不可剥夺​ 进程所获得的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放（只能是主动释放)。请求与保持​ 进程已经保持了至少一个资源，但又提出了新的资源请求，而该资源已被其他进程占有，此时请求进程被阻塞，但对自己已获得的资源保持不放。循环等待​ 是指进程发生死锁后，必然存在一个进程–资源之间的环形链，通俗讲就是你等我的资源，我等你的资源，大家一直等。死锁的分类静态顺序型死锁线程之间形成相互等待资源的环时，就会形成顺序死锁lock-ordering deadlock，多个线程试图以不同的顺序来获取相同的锁时，容易形成顺序死锁，如果所有线程以固定的顺序来获取锁，就不会出现顺序死锁问题​ 经典案例是LeftRightDeadlock，两个方法，分别是leftRigth、rightLeft。如果一个线程调用leftRight，另一个线程调用rightLeft，且两个线程是交替执行的，就会发生死锁。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class LeftRightDeadLock &#123; //左边锁 private static Object left = new Object(); //右边锁 private static Object right = new Object(); /** * 现持有左边的锁，然后获取右边的锁 */ public static void leftRigth() &#123; synchronized (left) &#123; System.out.println(\"leftRigth: left lock，threadId:\" + Thread.currentThread().getId()); //休眠增加死锁产生的概率 sleep(100); synchronized (right) &#123; System.out.println(\"leftRigth: right lock，threadId:\" + Thread.currentThread().getId()); &#125; &#125; &#125; /** * 现持有右边的锁，然后获取左边的锁 */ public static void rightLeft() &#123; synchronized (right) &#123; System.out.println(\"rightLeft: right lock，threadId:\" + Thread.currentThread().getId()); //休眠增加死锁产生的概率 sleep(100); synchronized (left) &#123; System.out.println(\"rightLeft: left lock，threadId:\" + Thread.currentThread().getId()); &#125; &#125; &#125; /** * 休眠 * * @param time */ private static void sleep(long time) &#123; try &#123; Thread.sleep(time); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; //创建一个线程池 ExecutorService executorService = Executors.newFixedThreadPool(10); executorService.execute(() -&gt; leftRigth()); executorService.execute(() -&gt; rightLeft()); executorService.shutdown(); &#125;&#125;输出12leftRigth: left lock，threadId:12rightLeft: right lock，threadId:13我们发现，12号线程锁住了左边要向右边获取锁，13号锁住了右边，要向左边获取锁，因为两边都不释放自己的锁，互不相让，就产生了死锁。解决方案固定加锁的顺序(针对锁顺序死锁)只要交换下锁的顺序，让线程来了之后先获取同一把锁，获取不到就等待，等待上一个线程释放锁再获取锁。1234567891011121314151617public static void leftRigth() &#123; synchronized (left) &#123; ... synchronized (right) &#123; ... &#125; &#125; &#125; public static void rightLeft() &#123; synchronized (left) &#123; ... synchronized (right) &#123; ... &#125; &#125; &#125;动态锁顺序型死锁由于方法入参由外部传递而来，方法内部虽然对两个参数按照固定顺序进行加锁，但是由于外部传递时顺序的不可控，而产生锁顺序造成的死锁，即动态锁顺序死锁。​ 上例告诉我们，交替的获取锁会导致死锁，且锁是固定的。有时候并锁的执行顺序并不那么清晰，参数导致不同的执行顺序。经典案例是银行账户转账，from账户向to账户转账，在转账之前先获取两个账户的锁，然后开始转账，如果这是to账户向from账户转账，角色互换，也会导致锁顺序死锁。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273/** * 动态顺序型死锁 * 转账业务 */public class TransferMoneyDeadlock &#123; public static void transfer(Account from, Account to, int amount) &#123; //先锁住转账的账户 synchronized (from) &#123; System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】获取【\" + from.name + \"】账户锁成功\"); //休眠增加死锁产生的概率 sleep(100); //在锁住目标账户 synchronized (to) &#123; System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】获取【\" + to.name + \"】账户锁成功\"); if (from.balance &lt; amount) &#123; System.out.println(\"余额不足\"); return; &#125; else &#123; from.debit(amount); to.credit(amount); System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】从【\" + from.name + \"】账户转账到【\" + to.name + \"】账户【\" + amount + \"】元钱成功\"); &#125; &#125; &#125; &#125; private static class Account &#123; String name; int balance; public Account(String name, int balance) &#123; this.name = name; this.balance = balance; &#125; void debit(int amount) &#123; this.balance = balance - amount; &#125; void credit(int amount) &#123; this.balance = balance + amount; &#125; &#125; /** * 休眠 * * @param time */ private static void sleep(long time) &#123; try &#123; Thread.sleep(time); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; //创建线程池 ExecutorService executorService = Executors.newFixedThreadPool(10); //创建账户A Account A = new Account(\"A\", 100); //创建账户B Account B = new Account(\"B\", 200); //A -&gt; B 的转账 executorService.execute(() -&gt; transfer(A, B, 5)); //B -&gt; A 的转账 executorService.execute(() -&gt; transfer(B, A, 10)); executorService.shutdown(); &#125;&#125;输出12线程【12】获取【A】账户锁成功线程【13】获取【B】账户锁成功然后就没有然后了，产生了死锁，我们发现 因为对象的调用关系，产生了互相锁住资源的问题。解决方案​ 根据传入对象的hashCode硬性确定加锁顺序，消除可变性，避免死锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145package com.test.thread.deadlock;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;/** * 动态顺序型死锁解决方案 */public class TransferMoneyDeadlock &#123; /** * 监视器，第三把锁，为了方式HASH冲突 */ private static Object lock = new Object(); /** * 我们经过上一次得失败，明白了不能依赖参数名称简单的确定锁的顺序，因为参数是 * 具有动态性的，所以，我们改变一下思路，直接根据传入对象的hashCode()大小来 * 对锁定顺序进行排序(这里要明白的是如何排序不是关键，有序才是关键)。 * * @param from * @param to * @param amount */ public static void transfer(Account from, Account to, int amount) &#123; /** * 这里需要说明一下为什么不使用HashCode()因为HashCode方法可以被重写， * 所以，我们无法简单的使用父类或者当前类提供的简单的hashCode()方法， * 所以，我们就使用系统提供的identityHashCode()方法，该方法保证无论 * 你是否重写了hashCode方法，都会在虚拟机层面上调用一个名为JVM_IHashCode * 的方法来根据对象的存储地址来获取该对象的hashCode(),HashCode如果不重写 * 的话，其实也是通过这个虚拟机层面上的方法，JVM_IHashCode()方法实现的 * 这个方法是用C++实现的。 */ int fromHash = System.identityHashCode(from); int toHash = System.identityHashCode(to); if (fromHash &gt; toHash) &#123; //先锁住转账的账户 synchronized (from) &#123; System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】获取【\" + from.name + \"】账户锁成功\"); //休眠增加死锁产生的概率 sleep(100); //在锁住目标账户 synchronized (to) &#123; System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】获取【\" + to.name + \"】账户锁成功\"); if (from.balance &lt; amount) &#123; System.out.println(\"余额不足\"); return; &#125; else &#123; from.debit(amount); to.credit(amount); System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】从【\" + from.name + \"】账户转账到【\" + to.name + \"】账户【\" + amount + \"】元钱成功\"); &#125; &#125; &#125; &#125; else if (fromHash &lt; toHash) &#123; //先锁住转账的账户 synchronized (to) &#123; System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】获取【\" + from.name + \"】账户锁成功\"); //休眠增加死锁产生的概率 sleep(100); //在锁住目标账户 synchronized (from) &#123; System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】获取【\" + to.name + \"】账户锁成功\"); if (from.balance &lt; amount) &#123; System.out.println(\"余额不足\"); return; &#125; else &#123; from.debit(amount); to.credit(amount); System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】从【\" + from.name + \"】账户转账到【\" + to.name + \"】账户【\" + amount + \"】元钱成功\"); &#125; &#125; &#125; &#125; else &#123; //如果传入对象的Hash值相同，那就加让加第三层锁 synchronized (lock) &#123; //先锁住转账的账户 synchronized (from) &#123; System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】获取【\" + from.name + \"】账户锁成功\"); //休眠增加死锁产生的概率 sleep(100); //在锁住目标账户 synchronized (to) &#123; System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】获取【\" + to.name + \"】账户锁成功\"); if (from.balance &lt; amount) &#123; System.out.println(\"余额不足\"); return; &#125; else &#123; from.debit(amount); to.credit(amount); System.out.println(\"线程【\" + Thread.currentThread().getId() + \"】从【\" + from.name + \"】账户转账到【\" + to.name + \"】账户【\" + amount + \"】元钱成功\"); &#125; &#125; &#125; &#125; &#125; &#125; private static class Account &#123; String name; int balance; public Account(String name, int balance) &#123; this.name = name; this.balance = balance; &#125; void debit(int amount) &#123; this.balance = balance - amount; &#125; void credit(int amount) &#123; this.balance = balance + amount; &#125; &#125; /** * 休眠 * * @param time */ private static void sleep(long time) &#123; try &#123; Thread.sleep(time); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; //创建线程池 ExecutorService executorService = Executors.newFixedThreadPool(10); //创建账户A Account A = new Account(\"A\", 100); //创建账户B Account B = new Account(\"B\", 200); //A -&gt; B 的转账 executorService.execute(() -&gt; transfer(A, B, 5)); //B -&gt; A 的转账 executorService.execute(() -&gt; transfer(B, A, 10)); executorService.shutdown(); &#125;&#125;输出123456线程【12】获取【A】账户锁成功线程【12】获取【B】账户锁成功线程【12】从【A】账户转账到【B】账户【5】元钱成功线程【13】获取【B】账户锁成功线程【13】获取【A】账户锁成功线程【13】从【B】账户转账到【A】账户【10】元钱成功协作对象间的死锁在协作对象之间可能存在多个锁获取的情况，但是这些获取多个锁的操作并不像在LeftRightDeadLock或transferMoney中那么明显，这两个锁并不一定必须在同一个方法中被获取。如果在持有锁时调用某个外部方法，那么这就需要警惕死锁问题，因为在这个外部方法中可能会获取其他锁，或者阻塞时间过长，导致其他线程无法及时获取当前被持有的锁。​ 上述两例中，在同一个方法中获取两个锁。实际上，锁并不一定在同一方法中被获取。经典案例，如出租车调度系统。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182/** * 协作对象间的死锁 */public class CoordinateDeadlock &#123; /** * Taxi 类 */ static class Taxi &#123; private String location; private String destination; private Dispatcher dispatcher; public Taxi(Dispatcher dispatcher, String destination) &#123; this.dispatcher = dispatcher; this.destination = destination; &#125; public synchronized String getLocation() &#123; return this.location; &#125; /** * 该方法先获取Taxi的this对象锁后，然后调用Dispatcher类的方法时，又需要获取 * Dispatcher类的this方法。 * * @param location */ public synchronized void setLocation(String location) &#123; this.location = location; System.out.println(Thread.currentThread().getName() + \" taxi set location:\" + location); if (this.location.equals(destination)) &#123; dispatcher.notifyAvailable(this); &#125; &#125; &#125; /** * 调度类 */ static class Dispatcher &#123; private Set&lt;Taxi&gt; taxis; private Set&lt;Taxi&gt; availableTaxis; public Dispatcher() &#123; taxis = new HashSet&lt;Taxi&gt;(); availableTaxis = new HashSet&lt;Taxi&gt;(); &#125; public synchronized void notifyAvailable(Taxi taxi) &#123; System.out.println(Thread.currentThread().getName() + \" notifyAvailable.\"); availableTaxis.add(taxi); &#125; /** * 打印当前位置：有死锁风险 * 持有当前锁的时候，同时调用Taxi的getLocation这个外部方法；而这个外部方法也是需要加锁的 * reportLocation的锁的顺序与Taxi的setLocation锁的顺序完全相反 */ public synchronized void reportLocation() &#123; System.out.println(Thread.currentThread().getName() + \" report location.\"); for (Taxi t : taxis) &#123; t.getLocation(); &#125; &#125; public void addTaxi(Taxi taxi) &#123; taxis.add(taxi); &#125; &#125; public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); final Dispatcher dispatcher = new Dispatcher(); final Taxi taxi = new Taxi(dispatcher, \"软件园\"); dispatcher.addTaxi(taxi); //先获取dispatcher锁，然后是taxi的锁 executorService.execute(() -&gt; dispatcher.reportLocation()); //先获取taxi锁，然后是dispatcher的锁 executorService.execute(() -&gt; taxi.setLocation(\"软件园\")); executorService.shutdown(); &#125;&#125;解决方案使用开放调用，开放调用指调用该方法不需要持有锁。​ 开放调用，是指在调用某个方法时不需要持有锁。开放调用可以避免死锁，这种代码更容易编写。上述调度算法完全可以修改为开发调用，修改同步代码块的范围，使其仅用于保护那些涉及共享状态的操作，避免在同步代码块中执行方法调用。修改Dispatcher的reportLocation方法：setLocation方法1234567891011121314/** * 开放调用，不持有锁期间进行外部方法调用 * * @param location */ public void setLocation(String location) &#123; synchronized (this) &#123; this.location = location; &#125; System.out.println(Thread.currentThread().getName() + \" taxi set location:\" + location); if (this.location.equals(destination)) &#123; dispatcher.notifyAvailable(this); &#125; &#125;reportLocation 方法12345678910111213/** * 同步块只包含对共享状态的操作代码 */ public synchronized void reportLocation() &#123; System.out.println(Thread.currentThread().getName() + \" report location.\"); Set&lt;Taxi&gt; taxisCopy; synchronized (this) &#123; taxisCopy = new HashSet&lt;Taxi&gt;(taxis); &#125; for (Taxi t : taxisCopy) &#123; t.getLocation(); &#125; &#125;死锁问题排查​ 拿动态顺序型死锁举例，其他的都一样12345678public static void main(String[] args) &#123; ExecutorService executorService = Executors.newFixedThreadPool(10); Account A = new Account(\"A\", 100); Account B = new Account(\"B\", 200); executorService.execute(() -&gt; transfer(A, B, 5)); executorService.execute(() -&gt; transfer(B, A, 10)); executorService.shutdown(); &#125;死锁的现象系统越来越卡，没有任何报错信息，随机性比较高排查死锁使用 jps + jstack在 window或linux中使用jps + jstack命令找到可能发生死锁的类对应的PID我们对应的类是TransferMoneyDeadlock PID是 13964使用jstack -l PID执行 jstack -l 13964 命令我们观察BLOCKED 就表示阻塞状态pool-1-thread-2 等待锁 &lt;0x00000000d673baa8&gt;并且已经获取了锁 &lt;0x00000000d673baf0&gt;pool-1-thread-1 等待锁 &lt;0x00000000d673baf0&gt; 并且已经获取了锁&lt;0x00000000d673baa8&gt;我们发现他们互相持有各自的锁，并且想获取对方的锁，这就是明显的死锁。使用jconsole使用命令打开jconsole打开jconsole界面工具选择我们需要检测的类选择检查死锁点击检查死锁","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"死锁","slug":"并发/死锁","permalink":"http://www.baiyp.ren/categories/并发/死锁/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"死锁","slug":"死锁","permalink":"http://www.baiyp.ren/tags/死锁/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"死锁","slug":"并发/死锁","permalink":"http://www.baiyp.ren/categories/并发/死锁/"}]},{"title":"布隆过滤器","slug":"布隆过滤器","date":"2019-08-27T06:23:36.000Z","updated":"2019-08-27T07:54:23.666Z","comments":true,"path":"布隆过滤器.html","link":"","permalink":"http://www.baiyp.ren/布隆过滤器.html","excerpt":"","text":"布隆过滤器什么是布隆过滤器布隆过滤器（Bloom Filter）是1970年由布隆提出的。它实际上是一个很长的二进制向量和一系列随机映射函数。布隆过滤器可以用于检索一个元素是否在一个集合中。它的优点是空间效率和查询时间都比一般的算法要好的多，缺点是有一定的误识别率和删除困难。​ 布隆过滤器可以理解为一个不怎么精确的 set 结构，当你使用它的 contains 方法判断某个对象是否存在时，它可能会误判。但是布隆过滤器也不是特别不精确，只要参数设置的合理，它的精确度可以控制的相对足够精确，只会有小小的误判概率。​ 当布隆过滤器说某个值存在时，这个值可能不存在；当它说不存在时，那就肯定不存在。打个比方，当它说不认识你时，肯定就不认识；当它说见过你时，可能根本就没见过面，不过因为你的脸跟它认识的人中某脸比较相似 (某些熟脸的系数组合)，所以误判以前见过你。套在上面的使用场景中，布隆过滤器能准确过滤掉那些已经看过的内容，那些没有看过的新内容，它也会过滤掉极小一部分 (误判)，但是绝大多数新内容它都能准确识别。这样就可以完全保证推荐给用户的内容都是无重复的。布隆过滤器的原理​ 其本质就是一个只包含0和1的数组。具体操作当一个元素被加入到集合里面后，该元素通过K个Hash函数运算得到K个hash后的值，然后将K个值映射到这个位数组对应的位置，把对应位置的值设置为1。查询是否存在时，我们就看对应的映射点位置如果全是1，他就很可能存在（跟hash函数的个数和hash函数的设计有关），如果有一个位置是0，那这个元素就一定不存在。首先需要初始化一个二进制的数组，长度设为 L，同时初始值全为 0 。当写入一个 A1=1000 的数据时，需要进行 H 次 hash 函数的运算（这里为 2 次）；与 HashMap 有点类似，通过算出的 HashCode 与 L 取模后定位到 0、2 处，将该处的值设为 1。A2=2000 也是同理计算后将 4、7 位置设为 1。当有一个 B1=1000 需要判断是否存在时，也是做两次 Hash 运算，定位到 0、2 处，此时他们的值都为 1 ，所以认为 B1=1000 存在于集合中。当有一个 B2=3000 时，也是同理。第一次 Hash 定位到 index=4 时，数组中的值为 1，所以再进行第二次 Hash 运算，结果定位到 index=5 的值为 0，所以认为 B2=3000 不存在于集合中。整个的写入、查询的流程就是这样，汇总起来就是：对写入的数据做 H 次 hash 运算定位到数组中的位置，同时将数据改为 1 。当有数据查询时也是同样的方式定位到数组中。一旦其中的有一位为 0 则认为数据肯定不存在于集合，否则数据可能存在于集合中。布隆过滤器的特点只要返回数据不存在，则肯定不存在。返回数据存在，但只能是大概率存在。同时不能清除其中的数据。在有限的数组长度中存放大量的数据，即便是再完美的 Hash 算法也会有冲突，所以有可能两个完全不同的 A、B 两个数据最后定位到的位置是一模一样的。删除数据也是同理，当我把 B 的数据删除时，其实也相当于是把 A 的数据删掉了，这样也会造成后续的误报。基于以上的 Hash 冲突的前提，所以 Bloom Filter 有一定的误报率，这个误报率和 Hash 算法的次数 H，以及数组长度 L 都是有关的。应用场景缓存穿透​ 我们经常会把一部分数据放在Redis等缓存，比如产品详情。这样有查询请求进来，我们可以根据产品Id直接去缓存中取数据，而不用读取数据库，这是提升性能最简单，最普遍，也是最有效的做法。一般的查询请求流程是这样的：先查缓存，有缓存的话直接返回，如果缓存中没有，再去数据库查询，然后再把数据库取出来的数据放入缓存，一切看起来很美好。但是如果现在有大量请求进来，而且都在请求一个不存在的产品Id，会发生什么？既然产品Id都不存在，那么肯定没有缓存，没有缓存，那么大量的请求都怼到数据库，数据库的压力一下子就上来了，还有可能把数据库打死。​ 使用布隆过滤器的特点，只要返回数据不存在，则肯定不存在，返回数据存在，但只能是大概率存在，这种特点可以大批量的无效请求过滤掉，能够穿透缓存的知识漏网之鱼，无关紧要。检查单词拼写​ 检查一个单词拼写是否正确，因为有海量的单词数量，每天可能有新的单词，使用布隆过滤器，可以将单词映射到很小的内存中，可以经过简单的几次hash运行就可以进行校验，只要返回数据不存在，则肯定不存在，返回数据存在，但只能是大概率存在，虽然可能有误报，但是对系统的提升是革命性的。Guava的布隆过滤器这就又要提起我们的Guava了，它是Google开源的Java包，提供了很多常用的功能。Guava中，布隆过滤器的实现主要涉及到2个类，BloomFilter和BloomFilterStrategies，首先来看一下BloomFilter的成员变量。需要注意的是不同Guava版本的BloomFilter实现不同。布隆过滤器解析成员变量分析12345678910/** guava实现的以CAS方式设置每个bit位的bit数组 */ private final LockFreeBitArray bits; /** hash函数的个数 */ private final int numHashFunctions; /** guava中将对象转换为byte的通道 */ private final Funnel&lt;? super T&gt; funnel; /** * 将byte转换为n个bit的策略，也是bloomfilter hash映射的具体实现 */ private final Strategy strategy;这是它的4个成员变量:LockFreeBitArray是定义在BloomFilterStrategies中的内部类，封装了布隆过滤器底层bit数组的操作。numHashFunctions表示哈希函数的个数。Funnel，它和PrimitiveSink配套使用，能将任意类型的对象转化成Java基本数据类型，默认用java.nio.ByteBuffer实现，最终均转化为byte数组。Strategy是定义在BloomFilter类内部的接口，代码如下，主要有2个方法，put和mightContain。12345678interface Strategy extends java.io.Serializable &#123; /** 设置元素 */ &lt;T&gt; boolean put(T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits); /** 判断元素是否存在*/ &lt;T&gt; boolean mightContain( T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits); .....&#125;创建布隆过滤器，BloomFilter并没有公有的构造函数，只有一个私有构造函数，而对外它提供了5个重载的create方法，在缺省情况下误判率设定为3%，采用BloomFilterStrategies.MURMUR128_MITZ_64的实现。BloomFilterStrategies.MURMUR128_MITZ_64是Strategy的两个实现之一，Guava以枚举的方式提供这两个实现，这也是《Effective Java》书中推荐的提供对象的方法之一。1234enum BloomFilterStrategies implements BloomFilter.Strategy &#123; MURMUR128_MITZ_32() &#123;//....&#125; MURMUR128_MITZ_64() &#123;//....&#125;&#125;​ 二者对应了32位哈希映射函数，和64位哈希映射函数，后者使用了murmur3 hash生成的所有128位，具有更大的空间，不过原理是相通的，我们选择相对简单的MURMUR128_MITZ_32来分析。先来看一下它的put方法，它用两个hash函数来模拟多个hash函数的情况，这是布隆过滤器的一种优化。put方法1234567891011121314151617181920212223public &lt;T&gt; boolean put( T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits) &#123; long bitSize = bits.bitSize(); // 先利用murmur3 hash对输入的funnel计算得到128位的哈希值，funnel现将object转换为byte数组， // 然后在使用哈希函数转换为long long hash64 = Hashing.murmur3_128().hashObject(object, funnel).asLong(); // 根据hash值的高低位算出hash1和hash2 int hash1 = (int) hash64; int hash2 = (int) (hash64 &gt;&gt;&gt; 32); boolean bitsChanged = false; // 循环体内采用了2个函数模拟其他函数的思想,相当于每次累加hash2 for (int i = 1; i &lt;= numHashFunctions; i++) &#123; int combinedHash = hash1 + (i * hash2); // 如果是负数就变为正数 if (combinedHash &lt; 0) &#123; combinedHash = ~combinedHash; &#125; // 通过基于bitSize取模的方式获取bit数组中的索引，然后调用set函数设置。 bitsChanged |= bits.set(combinedHash % bitSize); &#125; return bitsChanged;&#125;在put方法中，先是将索引位置上的二进制置为1，然后用bitsChanged记录插入结果，如果返回true表明没有重复插入成功，而mightContain方法则是将索引位置上的数值取出，并判断是否为0，只要其中出现一个0，那么立即判断为不存在。mightContain方法1234567891011121314151617181920public &lt;T&gt; boolean mightContain( T object, Funnel&lt;? super T&gt; funnel, int numHashFunctions, BitArray bits) &#123; long bitSize = bits.bitSize(); long hash64 = Hashing.murmur3_128().hashObject(object, funnel).asLong(); int hash1 = (int) hash64; int hash2 = (int) (hash64 &gt;&gt;&gt; 32); for (int i = 1; i &lt;= numHashFunctions; i++) &#123; int combinedHash = hash1 + (i * hash2); // Flip all the bits if it's negative (guaranteed positive number) if (combinedHash &lt; 0) &#123; combinedHash = ~combinedHash; &#125; // 和put的区别就在这里，从set转换为get，来判断是否存在 if (!bits.get(combinedHash % bitSize)) &#123; return false; &#125; &#125; return true;&#125;Guava为了提供效率，自己实现了LockFreeBitArray来提供bit数组的无锁设置和读取。我们只来看一下它的put函数。12345678910111213141516171819202122boolean set(long bitIndex) &#123; if (get(bitIndex)) &#123; return false; &#125; int longIndex = (int) (bitIndex &gt;&gt;&gt; LONG_ADDRESSABLE_BITS); long mask = 1L &lt;&lt; bitIndex; // only cares about low 6 bits of bitIndex long oldValue; long newValue; // 经典的CAS自旋重试机制 do &#123; oldValue = data.get(longIndex); newValue = oldValue | mask; if (oldValue == newValue) &#123; return false; &#125; &#125; while (!data.compareAndSet(longIndex, oldValue, newValue)); bitCount.increment(); return true;&#125;Guava布隆过滤器使用引入坐标12345&lt;dependency&gt; &lt;groupId&gt;com.google.guava&lt;/groupId&gt; &lt;artifactId&gt;guava&lt;/artifactId&gt; &lt;version&gt;28.0-jre&lt;/version&gt;&lt;/dependency&gt;代码实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class GuavaBloomFilter &#123; /** * 设置布隆过滤器大小 */ private static final int size = 100000; /** * 构建一个BloomFilter * 第一个参数Funnel类型的参数 * 第二个参数 期望处理的数据量 * 第三个参数 误判率 可不加，默认 0.03D */ private static final BloomFilter&lt;CharSequence&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(), size); public static void main(String[] args) &#123; //成功计数 float success = 0; //失败计数 float fial = 0; Set&lt;String&gt; stringSet = new HashSet&lt;String&gt;(); for (int i = 0; i &lt; size; i++) &#123; //生成随机字符串 String randomStr = RandomStringUtils.randomNumeric(10); //加入到set中 stringSet.add(randomStr); //加入到布隆过滤器 bloomFilter.put(randomStr); &#125; for (int i = 0; i &lt; size; i++) &#123; //生成随机字符串 String randomStr = RandomStringUtils.randomNumeric(10); //布隆过滤器校验存在 if (bloomFilter.mightContain(randomStr)) &#123; //set中存在 if (stringSet.contains(randomStr)) &#123; //成功计数 success++; &#125; else &#123; //失败计数 fial++; &#125; //布隆过滤器校验不存在 &#125; else &#123; // set中存在 if (stringSet.contains(randomStr)) &#123; //失败计数 fial++; &#125; else &#123; //成功计数 success++; &#125; &#125; &#125; System.out.println(\"判断成功数：\"+success + \"，判断失败数:\" + fial + \"，误判率:\" + fial / 100000); &#125;输出1判断成功数：97084.0，判断失败数:2916.0，误判率:0.02916可以通过增加误判率的参数来调整误判率1234567/** * 构建一个BloomFilter * 第一个参数Funnel类型的参数 * 第二个参数 期望处理的数据量 * 第三个参数 误判率 可不加，默认 0.03D */private static final BloomFilter&lt;CharSequence&gt; bloomFilter = BloomFilter.create(Funnels.stringFunnel(), size,0.00001);输出1判断成功数：100000.0，判断失败数:0.0，误判率:0.0","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"布隆过滤器","slug":"架构/布隆过滤器","permalink":"http://www.baiyp.ren/categories/架构/布隆过滤器/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"布隆过滤器","slug":"布隆过滤器","permalink":"http://www.baiyp.ren/tags/布隆过滤器/"},{"name":"BloomFilter","slug":"BloomFilter","permalink":"http://www.baiyp.ren/tags/BloomFilter/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"布隆过滤器","slug":"架构/布隆过滤器","permalink":"http://www.baiyp.ren/categories/架构/布隆过滤器/"}]},{"title":"JAVA线程池实现03-其余方法","slug":"JAVA线程池实现03","date":"2019-08-25T02:55:59.000Z","updated":"2019-08-27T06:10:17.903Z","comments":true,"path":"JAVA线程池实现03.html","link":"","permalink":"http://www.baiyp.ren/JAVA线程池实现03.html","excerpt":"","text":"JAVA线程池实现03-其余方法shutdown安全停止任务注意该方法不会马上停止线程池，会先将线程池置于shutdown状态然后发起中断请求，等待任务自己结束，线程内部要实现中断请求的响应处理，否则就不会终止。12345678910111213141516171819202122//安全的中断任务 public void shutdown() &#123; //获取重入锁 final ReentrantLock mainLock = this.mainLock; //加锁 mainLock.lock(); try &#123; //检查权限 checkShutdownAccess(); //更改运行状态 advanceRunState(SHUTDOWN); //中断任务 interruptIdleWorkers(); //模板方法，不继承实现则是一个空方法 onShutdown(); &#125; finally &#123; //解锁 mainLock.unlock(); &#125; //尝试中断任务 tryTerminate(); &#125;检查权限 checkShutdownAccess这主要的目的是为了在系统层面对线程池进行保护，防止其发生意外。比如中断系统进程等，获取了安全管理器之后接下来再对其进行权限检查。12345678910111213141516171819202122 //检查线程池个任务权限private void checkShutdownAccess() &#123; //获取安全管理器 SecurityManager security = System.getSecurityManager(); if (security != null) &#123; //检查任务权限 security.checkPermission(shutdownPerm); //获取重入锁 final ReentrantLock mainLock = this.mainLock; //加锁 mainLock.lock(); try &#123; //检查个任务的权限 for (ThreadPoolExecutor.Worker w : workers) &#123; security.checkAccess(w.thread); &#125; &#125; finally &#123; //解锁 mainLock.unlock(); &#125; &#125;&#125;更改运行状态 advanceRunState更改线程池的状态123456789//设置运行状态 private void advanceRunState(int targetState) &#123; for (; ; ) &#123; int c = ctl.get(); //非运行状态 当前状态&gt; targetState 或者 设置运行状态为 targetState状态成功 if (runStateAtLeast(c, targetState) || ctl.compareAndSet(c, ctlOf(targetState, workerCountOf(c)))) break; &#125; &#125;中断工作任务 interruptIdleWorkers中断任务，但是只是发起中断请求，不会强制中断任务。1234567891011121314151617181920212223242526272829303132333435363738/** * 中断任务 */ private void interruptIdleWorkers() &#123; interruptIdleWorkers(false); &#125; /** * 中断任务 * @param onlyOne 是否只中断一次 */ private void interruptIdleWorkers(boolean onlyOne) &#123; //获取重入锁 final ReentrantLock mainLock = this.mainLock; //加锁 mainLock.lock(); try &#123; for (Worker w : workers) &#123; Thread t = w.thread; //任务未中断 并且尝试获取锁成功 if (!t.isInterrupted() &amp;&amp; w.tryLock()) &#123; try &#123; //发起中断请求 t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; finally &#123; //解锁 w.unlock(); &#125; &#125; if (onlyOne) break; &#125; &#125; finally &#123; //解锁 mainLock.unlock(); &#125; &#125;尝试终止任务尝试终止任务如果有正在运行的任务或者任务队列不为空且运行状态是SHUTDOWN就返回，不进行前置终止。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 尝试终止任务 */final void tryTerminate() &#123; //自旋 for (;;) &#123; //获取运行状态 int c = ctl.get(); /** * isRunning 线程正在运行 * runStateAtLeast 线程池已经中断 * 或者 线程池停止并且任务队列不为空 返回 * 不进行强制终止 * */ //正在运行或者 if (isRunning(c) || runStateAtLeast(c, TIDYING) || (runStateOf(c) == SHUTDOWN &amp;&amp; ! workQueue.isEmpty())) &#123; return; &#125; //当前工作线程不为0 if (workerCountOf(c) != 0) &#123; // Eligible to terminate //发起中断请求 只终止一次 interruptIdleWorkers(ONLY_ONE); //返回 return; &#125; //获取重入锁 final ReentrantLock mainLock = this.mainLock; //加锁 mainLock.lock(); try &#123; //设置运行状态为真理状态 if (ctl.compareAndSet(c, ctlOf(TIDYING, 0))) &#123; try &#123; //空方法，用于终止线程后的自定义任务 terminated(); &#125; finally &#123; //设置线程池为终止状态 ctl.set(ctlOf(TERMINATED, 0)); //通知所有线程 termination.signalAll(); &#125; return; &#125; &#125; finally &#123; //解锁 mainLock.unlock(); &#125; // else retry on failed CAS &#125;&#125;shutdownNow马上终止线程该方法是马上中断线程池，如果有未完成的任务先发起中断请求，然后将线程池中的任务删除，并将删除的数据放进一个临时的队列并且返回。1234567891011121314151617181920212223242526/** * 马上终止线程 * @return 未完成的任务列表 */public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; //获取重入锁 final ReentrantLock mainLock = this.mainLock; //加锁 mainLock.lock(); try &#123; //检查权限 checkShutdownAccess(); //设置状态为终止 advanceRunState(STOP); //发起中断请求 interruptWorkers(); //将线程池任务队列清空，并返回未完成的任务 tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; //尝试终止任务 tryTerminate(); return tasks;&#125;drainQueue 清空队列清理队列并且返回未完成任务的列表123456789101112131415161718192021/** * 清空队列，并返回清除的数据 * @return */private List&lt;Runnable&gt; drainQueue() &#123; BlockingQueue&lt;Runnable&gt; q = workQueue; ArrayList&lt;Runnable&gt; taskList = new ArrayList&lt;Runnable&gt;(); //批量获取任务 q.drainTo(taskList); //为防止还有剩余数据，做一次查询 if (!q.isEmpty()) &#123; for (Runnable r : q.toArray(new Runnable[0])) &#123; //删除队列中的元素 if (q.remove(r)) &#123; //添加到队列 taskList.add(r); &#125; &#125; &#125; return taskList;&#125;shutdown与shutdownNow到这里我们发现shutdown和 shutdownNow很像，但是有差别，shutdownNow就强制在调用后会清空任务列表，强制终止任务，但是shutdown不会，shutdown会等待任务完成然后才会进行终止。isShutdown 线程池是否关闭123public boolean isShutdown() &#123; return ! isRunning(ctl.get()); &#125;isTerminating 线程池是否正在终止1234public boolean isTerminating() &#123; int c = ctl.get(); return ! isRunning(c) &amp;&amp; runStateLessThan(c, TERMINATED); &#125;线程池是否终止123public boolean isTerminated() &#123; return runStateAtLeast(ctl.get(), TERMINATED); &#125;","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"线程池","slug":"源码/线程池","permalink":"http://www.baiyp.ren/categories/源码/线程池/"}],"tags":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"},{"name":"线程池","slug":"线程池","permalink":"http://www.baiyp.ren/tags/线程池/"},{"name":"ThreadPoolExecutor","slug":"ThreadPoolExecutor","permalink":"http://www.baiyp.ren/tags/ThreadPoolExecutor/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"线程池","slug":"源码/线程池","permalink":"http://www.baiyp.ren/categories/源码/线程池/"}]},{"title":"JAVA线程池实现02-提交任务","slug":"JAVA线程池实现02","date":"2019-08-21T02:55:59.000Z","updated":"2019-08-27T02:48:29.586Z","comments":true,"path":"JAVA线程池实现02.html","link":"","permalink":"http://www.baiyp.ren/JAVA线程池实现02.html","excerpt":"","text":"JAVA线程池实现02-提交任务submit提交任务12345678910111213141516171819202122232425/** * 提交一个带有返回值的任务 * @param task 任务 * @param result 结果 * @param &lt;T&gt; 泛型 * @return Future */public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); //调用execute进行执行 execute(ftask); return ftask;&#125;/** * 创建一个FutureTask * @param runnable 运行的任务 * @param value 返回结果 * @param &lt;T&gt; 泛型 * @return FutureTask */protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value);&#125;流程步骤如下调用submit方法，传入Runnable或者Callable对象判断传入的对象是否为null，为null则抛出异常，不为null继续流程将传入的对象转换为RunnableFuture对象执行execute方法，传入RunnableFuture对象返回RunnableFuture对象execute 执行线程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/** * 在未来执行任务 * 任务将新建或者现有的线程池中执行 * 如果线程池关闭或者线程池满了将执行拒绝策略 * @param command */ public void execute(Runnable command) &#123; if (command == null) throw new NullPointerException(); int c = ctl.get(); /** * 1、运行线程数少于核心线程数，则调用addWorker启动一个新的线程 * 需要检查否应该添加线程 */ if (workerCountOf(c) &lt; corePoolSize) &#123; //添加线程 if (addWorker(command, true)) &#123; return; &#125; c = ctl.get(); &#125; /** * 运行线程数量大于核心线程数量时，上面的if分支针对大于corePoolSize，并且缓存队列加入任务操作成功的情况。 * 运行中并且将任务加入缓冲队列成功，正常来说这样已经完成了处理逻辑。 * 但是为了保险起见，增加了状态出现异常的确认判断，如果状态出现异常会继续remove操作，如果执行true，则按照拒绝处理策略驳回任务； */ //线程运行状态，并且添加进队列成功 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); //线程未运行并且删除成功 if (! isRunning(recheck) &amp;&amp; remove(command)) //拒绝任务 reject(command); //线程正在运行中 else if (workerCountOf(recheck) == 0) //添加任务 addWorker(null, false); &#125; /** * 这里针对运行线程数量超过了corePoolSize，并且缓存队列也已经放满的情况。 * 注意第二个参数是false，可以在下面addWorker方法看到，就是针对线程池最大线程数量maximumPoolSize的判断。 */ else if (!addWorker(command, false)) //拒绝任务 reject(command); &#125;其实从上面代码注释中可以看出就三个判断，核心线程数是否已满队列是否已满线程池是否已满调用execute方法，传入Runable对象判断传入的对象是否为null，为null则抛出异常，不为null继续流程获取当前线程池的状态和线程个数变量判断当前线程数是否小于核心线程数，是走流程5，否则走流程6添加线程数，添加成功则结束，失败则重新获取当前线程池的状态和线程个数变量,判断线程池是否处于RUNNING状态，是则添加任务到阻塞队列，否则走流程10，添加任务成功则继续流程7重新获取当前线程池的状态和线程个数变量重新检查线程池状态，不是运行状态则移除之前添加的任务，有一个false走流程9，都为true则走流程11检查线程池线程数量是否为0，否则结束流程，是调用addWorker(null, false)，然后结束调用!addWorker(command, false)，为true走流程11，false则结束调用拒绝策略reject(command)，结束addWorker 增加工作线程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105/** * 添加工作线程 * @param firstTask 任务 * @param core 是否是核心线程 * @return */private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: //自旋 for (;;) &#123; int c = ctl.get(); //获取运行状态 int rs = runStateOf(c); // 检查当前线程池状态是否是SHUTDOWN、STOP、TIDYING或者TERMINATED // 且！（当前状态为SHUTDOWN、且传入的任务为null，且队列不为null） // 条件都成立则返回false if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) &#123; return false; &#125; //有一个自旋 for (;;) &#123; //获取工作线程数 int wc = workerCountOf(c); /** * 工作线程数 &gt;= 队列容量 返回fasle * 如果是核心线程 工作线程数&gt;=核心线程数 返回false * 如果不是核心线程 工作线程数&gt;=最大线程数 返回false */ if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) &#123; return false; &#125; //CAS增加c，成功则跳出retry if (compareAndIncrementWorkerCount(c)) &#123; break retry; &#125; c = ctl.get(); // Re-read ctl //CAS失败执行下面方法，查看当前线程数是否变化，变化则继续retry循环，没变化则继续内部循环 if (runStateOf(c) != rs) &#123; continue retry; &#125; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; //CAS成功 //工作线程状态 boolean workerStarted = false; //工作线程添加状态 boolean workerAdded = false; Worker w = null; try &#123; //创建一个工作线程 w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; //获取重入锁 final ReentrantLock mainLock = this.mainLock; //加锁 mainLock.lock(); try &#123; //重新检查线程池状态 //避免ThreadFactory退出故障或者在锁获取前线程池被关闭 int rs = runStateOf(ctl.get()); //再次检查线程池状态 ？？？ if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; //检查thread的状态 if (t.isAlive()) &#123; // precheck that t is startable throw new IllegalThreadStateException(); &#125; //任务列表添加任务 workers.add(w); //获取任务列表大小 int s = workers.size(); //最大线程数 计数 if (s &gt; largestPoolSize) &#123; largestPoolSize = s; &#125; //线程添加成功 workerAdded = true; &#125; &#125; finally &#123; //解锁 mainLock.unlock(); &#125; //判断worker是否添加成功，成功则启动线程，然后将workerStarted设置为true if (workerAdded) &#123; t.start(); //启动状态成功 workerStarted = true; &#125; &#125; &#125; finally &#123; //判断线程有没有启动成功，没有则调用addWorkerFailed方法 if (! workerStarted) &#123; addWorkerFailed(w); &#125; &#125; //返回任务启动状态 return workerStarted;&#125;这里可以将addWorker分为两部分，第一部分增加线程池个数，第二部分是将任务添加到workder里面并执行。第一部分主要是两个循环，外层循环主要是判断线程池状态1234rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())展开！运算后等价于1234s &gt;= SHUTDOWN &amp;&amp; (rs != SHUTDOWN || firstTask != null || workQueue.isEmpty())也就是说下面几种情况下会返回false：当前线程池状态为STOP，TIDYING，TERMINATED当前线程池状态为SHUTDOWN并且已经有了第一个任务当前线程池状态为SHUTDOWN并且任务队列为空内层循环作用是使用cas增加线程个数，如果线程个数超限则返回false，否者进行cas，cas成功则退出双循环，否者cas失败了，要看当前线程池的状态是否变化了，如果变了，则重新进入外层循环重新获取线程池状态，否者进入内层循环继续进行cas尝试。到了第二部分说明CAS成功了，也就是说线程个数加一了，但是现在任务还没开始执行，这里使用全局的独占锁来控制workers里面添加任务，其实也可以使用并发安全的set，但是性能没有独占锁好（这个从注释中知道的）。这里需要注意的是要在获取锁后重新检查线程池的状态，这是因为其他线程可可能在本方法获取锁前改变了线程池的状态，比如调用了shutdown方法。添加成功则启动任务执行。所以这里也将流程图分为两部分来描述第一部分流程图第二部分流程图这里面有一个核心的工作类 WorkerAQS的Worker工作任务这个类继承了抽象队列同步器 是标准的AQS线程安全的类。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131/** * 工作任务对象 * 继承了AQS 抽象队列同步器 以及 Runnable 接口 */ private final class Worker extends AbstractQueuedSynchronizer implements Runnable &#123; /** * This class will never be serialized, but we provide a * serialVersionUID to suppress a javac warning. */ private static final long serialVersionUID = 6138294804551838833L; /** * Thread this worker is running in. Null if factory fails. */ //正在运行的线程，工厂创建线程失败则为null final Thread thread; /** * Initial task to run. Possibly null. */ //运行的初始任务，可能为null Runnable firstTask; /** * Per-thread task counter */ //完成任务的计数器 volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * * @param firstTask the first task (null if none) */ //构造方法 Worker(Runnable firstTask) &#123; //设置状态为未运行 setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; //使用线程工厂创建线程 this.thread = getThreadFactory().newThread(this); &#125; /** * Delegates main run loop to outer runWorker */ //实现Runnable的run方法 @Override public void run() &#123; //运行任务方法 runWorker(this); &#125; // Lock methods // // The value 0 represents the unlocked state. // The value 1 represents the locked state. /*是否是独占的 * @return 0 未锁 1 已锁定 */ protected boolean isHeldExclusively() &#123; return getState() != 0; &#125; /** * 尝试获取占用权 * @param unused * @return */ protected boolean tryAcquire(int unused) &#123; //CAS 设置锁定状态 if (compareAndSetState(0, 1)) &#123; //设置持有者是当前线程 setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; /** * 尝试释放锁 * @param unused * @return */ protected boolean tryRelease(int unused) &#123; //设置是持有者为null setExclusiveOwnerThread(null); //设置锁定状态为 未锁定 setState(0); return true; &#125; /** * 加锁 */ public void lock() &#123; acquire(1); &#125; /** * 尝试获取锁 * @return */ public boolean tryLock() &#123; return tryAcquire(1); &#125; //释放锁 public void unlock() &#123; release(1); &#125; /** * 释放 * @return */ public boolean isLocked() &#123; return isHeldExclusively(); &#125; /** * 中断启动 */ void interruptIfStarted() &#123; Thread t; if (getState() &gt;= 0 &amp;&amp; (t = thread) != null &amp;&amp; !t.isInterrupted()) &#123; try &#123; t.interrupt(); &#125; catch (SecurityException ignore) &#123; &#125; &#125; &#125; &#125;这个类很值得学习，里面最核心的方法是 runWorker 方法runWorker方法运行任务的主体，通过循环从阻塞队列中拿任务，进行执行12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061/** * 运行任务 * @param w 任务 */final void runWorker(Worker w) &#123; //获取当前线程 Thread wt = Thread.currentThread(); //获取任务 task Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts //是否突然完成任务(异常，或者其他情况) boolean completedAbruptly = true; try &#123; //循环获取任务 while (task != null || (task = getTask()) != null) &#123; //加锁 w.lock(); // 当线程池是处于STOP状态或者TIDYING、TERMINATED状态时，设置当前线程处于中断状态 // 如果不是，当前线程就处于RUNNING或者SHUTDOWN状态，确保当前线程不处于中断状态 // 重新检查当前线程池的状态是否大于等于STOP状态 if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) &#123; wt.interrupt(); &#125; try &#123; //线程执行前执行一些任务，在ThreadPoolExecutor是空实现 beforeExecute(wt, task); Throwable thrown = null; try &#123; //运行任务 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; //完成任务后执行一些任务，在ThreadPoolExecutor是空实现 afterExecute(task, thrown); &#125; &#125; finally &#123; //完成任务task置为空，交给GC处理 task = null; //完成任务计数器+1 w.completedTasks++; //解锁 w.unlock(); &#125; &#125; /** * 正常完成任务为false * 否则completedAbruptly 为true */ completedAbruptly = false; &#125; finally &#123; //整个线程结束时调用，线程退出操作。统计整个线程池完成的任务个数之类的工作 processWorkerExit(w, completedAbruptly); &#125;&#125;这里面有两个核心方法getTask：从队列中获取任务processWorkerExit：处任务并退出我们先从getTask开始getTask 方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354 /** * 获取待执行的任务 * * @return */private Runnable getTask() &#123; //最后一次poll()是否超时 boolean timedOut = false; //自旋 for (; ; ) &#123; int c = ctl.get(); //获取运行状态 int rs = runStateOf(c); //线程不在运行状态并且队列为空 if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; //使用CAS进行工作任务数-1 decrementWorkerCount(); return null; &#125; //获取当前工作任务数 int wc = workerCountOf(c); /** * 是否进行任务淘汰 如果 allowCoreThreadTimeOut为true 就一直淘汰下去 */ boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; //（当前线程数是否大于最大线程数或者） //且（线程数大于1或者任务队列为空） //这里有个问题(timed &amp;&amp; timedOut)timedOut = false，好像(timed &amp;&amp; timedOut)一直都是false吧 if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; //CAS方式进行工作线程-1 if (compareAndDecrementWorkerCount(c)) &#123; return null; &#125; continue; &#125; try &#123; /** * 如果需要淘汰淘汰从工作先队列中在指定keepAliveTime时间内获取一个工作线程否则返回null * 否则工作线程池为空就一直等待 */ Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) &#123; return r; &#125; //如果获取超时设置超时时间为true timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125;接下来我们分析下processWorkerExit方法processWorkerExit 方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 处理完成后续的线程统计工作 * 删除完成工作的线程 * @param w 工作线程 * @param completedAbruptly 是否突然完成（异常情况） */ private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; //如果突然完成，工作线程数统计未统计 if (completedAbruptly) &#123; // If abrupt, then workerCount wasn't adjusted //重新对工作线程数-1 decrementWorkerCount(); &#125; //获取锁 final ReentrantLock mainLock = this.mainLock; //加锁 mainLock.lock(); try &#123; //完成任务数统计 completedTaskCount += w.completedTasks; //从工作任务队列删除队列 workers.remove(w); &#125; finally &#123; //解锁 mainLock.unlock(); &#125; //尝试终止线程池 tryTerminate(); int c = ctl.get(); //正在运行或者停止 if (runStateLessThan(c, STOP)) &#123; //没有突然完成 if (!completedAbruptly) &#123; // 计算最小工作线程，如果allowCoreThreadTimeOut为true 就是 0 否则就是核心线程数 int min = allowCoreThreadTimeOut ? 0 : corePoolSize; //如果最小线程为0并且工作任务队列不为空则设置最小线程数为1 if (min == 0 &amp;&amp; !workQueue.isEmpty()) &#123; min = 1; &#125; //如果工作线程数&gt;=最小线程数返回 if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125; &#125;到这里为止,submit 和 execute已经分析完成了。","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"线程池","slug":"源码/线程池","permalink":"http://www.baiyp.ren/categories/源码/线程池/"}],"tags":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"},{"name":"线程池","slug":"线程池","permalink":"http://www.baiyp.ren/tags/线程池/"},{"name":"ThreadPoolExecutor","slug":"ThreadPoolExecutor","permalink":"http://www.baiyp.ren/tags/ThreadPoolExecutor/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"线程池","slug":"源码/线程池","permalink":"http://www.baiyp.ren/categories/源码/线程池/"}]},{"title":"JAVA线程池实现01-简介","slug":"JAVA线程池实现01","date":"2019-08-20T06:55:59.000Z","updated":"2019-08-27T02:48:20.553Z","comments":true,"path":"JAVA线程池实现01.html","link":"","permalink":"http://www.baiyp.ren/JAVA线程池实现01.html","excerpt":"","text":"JAVA线程池实现01-简介什么是线程池​ 线程池是一种多线程处理形式，处理过程中将任务添加到队列，然后在创建线程后自动启动这些任务。线程池线程都是后台线程。每个线程都使用默认的堆栈大小，以默认的优先级运行，并处于多线程单元中。如果某个线程在托管代码中空闲（如正在等待某个事件），则线程池将插入另一个辅助线程来使所有处理器保持繁忙。如果所有线程池线程都始终保持繁忙，但队列中包含挂起的工作，则线程池将在一段时间后创建另一个辅助线程但线程的数目永远不会超过最大值。超过最大值的线程可以排队，但他们要等到其他线程完成后才启动。为什么使用线程池操作系统创建线程、切换线程状态、终结线程都要进行CPU调度——这是一个耗费时间和系统资源的事情。​ 大多数实际场景中是这样的：处理某一次请求的时间是非常短暂的，但是请求数量是巨大的。这种技术背景下，如果我们为每一个请求都单独创建一个线程，那么物理机的所有资源基本上都被操作系统创建线程、切换线程状态、销毁线程这些操作所占用，用于业务请求处理的资源反而减少了。所以最理想的处理方式是，将处理请求的线程数量控制在一个范围，既保证后续的请求不会等待太长时间，又保证物理机将足够的资源用于请求处理本身。另外，一些操作系统是有最大线程数量限制的。当运行的线程数量逼近这个值的时候，操作系统会变得不稳定。这也是我们要限制线程数量的原因。线程池的优点降低资源消耗：通过重复利用已创建的线程降低线程创建和销毁带来的消耗。提高响应速度：当任务到达时，任务可以不需要等待线程创建就能立即执行。提高线程的可管理性：使用线程池可以统一进行线程分配、调度和监控。线程统一管理：线程池具有创建线程和销毁线程的能力，线程集中在一起比起分散开来，更加便于管理### 继承关系线程池都继承自Exceutor接口Executor接口Executor接口只有一个方法execute,传入线程任务参数123public interface Executor &#123; void execute(Runnable command);&#125;ExecutorService接口ExecutorService接口继承Executor接口，并增加了submit、shutdown、invokeAll等等一系列方法。1234567891011121314151617181920212223242526272829303132333435public interface ExecutorService extends Executor &#123; void shutdown(); List&lt;Runnable&gt; shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException; &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException; &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125;AbstractExecutorService抽象类bstractExecutorService抽象类实现ExecutorService接口，并且提供了一些方法的默认实现，例如submit方法、invokeAny方法、invokeAll方法。像execute方法、线程池的关闭方法（shutdown、shutdownNow等等）就没有提供默认的实现。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public abstract class AbstractExecutorService implements ExecutorService &#123; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) &#123; return new FutureTask&lt;T&gt;(runnable, value); &#125; protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Callable&lt;T&gt; callable) &#123; return new FutureTask&lt;T&gt;(callable); &#125; public Future&lt;?&gt; submit(Runnable task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task, result); execute(ftask); return ftask; &#125; public &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task) &#123; if (task == null) throw new NullPointerException(); RunnableFuture&lt;T&gt; ftask = newTaskFor(task); execute(ftask); return ftask; &#125; private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException &#123;...&#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException, ExecutionException &#123;... &#125; public &lt;T&gt; T invokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException &#123;...&#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks) throws InterruptedException &#123;...&#125; public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException &#123;...&#125;&#125;线程池的分类和作用newCachedThreadPool创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们，并在需要时使用提供的 ThreadFactory 创建新线程。线程池中数量没有固定，可达到最大值（Interger. MAX_VALUE）线程池中的线程可进行缓存重复利用和回收（回收默认时间为1分钟）当线程池中，没有可用线程，会重新创建一个线程newFixedThreadPool创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数 nThreads 线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之前，池中的线程将一直存在。线程池中的线程处于一定的量，可以很好的控制线程的并发量线程可以重复被使用，在显示关闭之前，都将一直存在超出一定量的线程被提交时候需在队列中等待newSingleThreadExecutor创建一个使用单个 worker 线程的 Executor，以无界队列方式来运行该线程。（注意，如果因为在关闭前的执行期间出现失败而终止了此单个线程，那么如果需要，一个新线程将代替它执行后续的任务）。可保证顺序地执行各个任务，并且在任意给定的时间不会有多个线程是活动的。与其他等效的 newFixedThreadPool(1) 不同，可保证无需重新配置此方法所返回的执行程序即可使用其他的线程。线程池中最多执行1个线程，之后提交的线程活动将会排在队列中以此执行newScheduleThreadPool创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。线程池中具有指定数量的线程，即便是空线程也将保留可定时或者延迟执行线程活动newSingleThreadScheduledExecutor创建一个单线程执行程序，它可安排在给定延迟后运行命令或者定期地执行。线程池中最多执行1个线程，之后提交的线程活动将会排在队列中以此执行可定时或者延迟执行线程活动ThreadPoolExecutor源码分析为什么要讲ThreadPoolExector类​ Exector是ThreadPoolExector的祖父类接口，ThreadPoolExector的直接父类接口是ExectorService，而我们所讲的第三点，其中的不同线程池的分类其实都是Exector中的方法，而在ThreadPoollExector中得到了实现，所以我们要构建的不同种类的线程池主要还是依赖这个类完成，接下来我们就聚焦ThreadPoolExector来看其具体的实现方法。线程池的执行流程成员变量分析123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778 //记录线程池状态和线程数量（总共32位，前三位表示线程池状态，后29位表示线程数量） private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//线程数量统计位数29 Integer.SIZE=32 private static final int COUNT_BITS = Integer.SIZE - 3;//容量 000 11111111111111111111111111111 private static final int CAPACITY = (1 &lt;&lt; COUNT_BITS) - 1; //运行中 111 00000000000000000000000000000 private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; //关闭 000 00000000000000000000000000000 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; //停止 001 00000000000000000000000000000 private static final int STOP = 1 &lt;&lt; COUNT_BITS; //整理 010 00000000000000000000000000000 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; //终止 011 00000000000000000000000000000 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; //获取运行状态（获取前3位） private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125; //获取线程个数（获取后29位） private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125; private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; // 存放任务的阻塞队列泛型是Runnable private final BlockingQueue&lt;Runnable&gt; workQueue; //可重入锁 private final ReentrantLock mainLock = new ReentrantLock(); //获取锁的一个条件 private final Condition termination = mainLock.newCondition(); //存放任务Worker 的集合 private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //线程池正在运行的数量 private int largestPoolSize; //已完成任务的计数器 private long completedTaskCount; //线程工厂，可以手工传入 自己构建线程 private volatile ThreadFactory threadFactory; //拒接策略 private volatile RejectedExecutionHandler handler; //默认拒绝策略为AbortPolicy private static final RejectedExecutionHandler defaultHandler = new ThreadPoolExecutor.AbortPolicy(); //空闲线程等待超时时间 private volatile long keepAliveTime; /** * 是否允许核心线程超时 * 默认为 false * true 核心线程等待超时后 也将会销毁 */ private volatile boolean allowCoreThreadTimeOut; /** * 核心池大小 不允许超时 * 除非allowCoreThreadTimeOut为true 这种情况下可为0 */ private volatile int corePoolSize; //最大线程池大小 最大不超过 CAPACITY private volatile int maximumPoolSize;我们也可以看出我们在线程池介绍中谈到的关于coreSize和maxiumSize等参数，这些int值对线程池的中的线程池数量进行了限制，还有一些关于锁ReentrantLock的类，这是一个可重入锁，它的主要目的是锁住其操作，因为线程的操作要保证其原子性，防止冲突发生，所以在其源码中很多都对其进行了上锁操作。还有一个很重要的值的全局的变量state:线城池的状态12345678910//表示正在运行中 private static final int RUNNING = -1 &lt;&lt; COUNT_BITS;//表示关闭 private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS;//表示停止 private static final int STOP = 1 &lt;&lt; COUNT_BITS;//表示整理 private static final int TIDYING = 2 &lt;&lt; COUNT_BITS;//表示结束 private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS;这些状态值是线程池目前所处环境的状态的体现，它采用int数字来表现，记住这些值很重要，因为后面有很多方法调用线程池的运行状态，有很多对其值进行判断。构造方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596/** * 创建线程池 * @param corePoolSize 核心线程池大小 * @param maximumPoolSize 最大线程池大小 * @param keepAliveTime 空闲等待时间 * @param unit 时间单位 * @param workQueue 传入的阻塞队列 */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue) &#123; //调用重载的构造方法 this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); &#125; /** * 创建线程池 * @param corePoolSize 核心线程池大小 * @param maximumPoolSize 最大线程池大小 * @param keepAliveTime 空闲等待时间 * @param unit 时间单位 * @param workQueue 传入的阻塞队列 * @param threadFactory 线程工厂 */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory) &#123; ///调用重载的构造方法 this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, threadFactory, defaultHandler); &#125; /** * 创建线程池 * @param corePoolSize 核心线程池大小 * @param maximumPoolSize 最大线程池大小 * @param keepAliveTime 空闲等待时间 * @param unit 时间单位 * @param workQueue 传入的阻塞队列 * @param handler 拒绝策略 */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, RejectedExecutionHandler handler) &#123; ///调用重载的构造方法 this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), handler); &#125; /** * 创建线程池 * @param corePoolSize 核心线程池大小 * @param maximumPoolSize 最大线程池大小 * @param keepAliveTime 空闲等待时间 * @param unit 时间单位 * @param workQueue 传入的阻塞队列 * @param threadFactory 线程工厂 * @param handler 拒绝策略 */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; //条件校验，不满足抛出异常 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); // 阻塞队列，线程工厂，拒绝策略不允许为空 if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); //java安全模式 this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; &#125;可以看出ThreadPoolExector一共有四个构造函数，但是最后调用的都是最后一个，我们可以只看最后一个，它主要有核心池大小、最大池大小、存活时间、时间单位、阻塞队列、线程工厂这几个参数，其中又对其进行了值范围的检查，如果参数违法就抛出异常，然后构造进去。关于这几个参数，随着后面我们对其方法的讲解，会理解越来越深刻的。","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"线程池","slug":"源码/线程池","permalink":"http://www.baiyp.ren/categories/源码/线程池/"}],"tags":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"},{"name":"线程池","slug":"线程池","permalink":"http://www.baiyp.ren/tags/线程池/"},{"name":"ThreadPoolExecutor","slug":"ThreadPoolExecutor","permalink":"http://www.baiyp.ren/tags/ThreadPoolExecutor/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"线程池","slug":"源码/线程池","permalink":"http://www.baiyp.ren/categories/源码/线程池/"}]},{"title":"JAVA阻塞队列实现","slug":"JAVA阻塞队列实现","date":"2019-08-19T06:55:59.000Z","updated":"2019-08-22T02:10:10.403Z","comments":true,"path":"JAVA阻塞队列实现.html","link":"","permalink":"http://www.baiyp.ren/JAVA阻塞队列实现.html","excerpt":"","text":"JAVA阻塞队列实现什么是阻塞队列​ 阻塞队列（BlockingQueue）是一个支持两个附加操作的队列。这两个附加的操作是：在队列为空时，获取元素的线程会等待队列变为非空。当队列满时，存储元素的线程会等待队列可用。阻塞队列常用于生产者和消费者的场景，生产者是往队列里添加元素的线程，消费者是从队列里拿元素的线程。阻塞队列就是生产者存放元素的容器，而消费者也只从容器里拿元素。队列的特点是：先进先出（FIFO）BlockingQueue的方法阻塞队列提供了四种处理方法:方法\\处理方式抛出异常返回特殊值一直阻塞超时退出插入add(e)offer(e)put(e)offer(e, time, unit)移除remove()poll()take()poll(time, unit)检查remove()peek()不可用不可用抛出异常：是指当阻塞队列满时候，再往队列里插入元素，会抛出IllegalStateException(“Queue full”)异常。当队列为空时，从队列里获取元素时会抛出NoSuchElementException异常 。返回特殊值：插入方法会返回是否成功，成功则返回true。移除方法，则是从队列里拿出一个元素，如果没有则返回null一直阻塞：当阻塞队列满时，如果生产者线程往队列里put元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里take元素，队列也会阻塞消费者线程，直到队列可用。超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。Java里的阻塞队列ArrayBlockingQueue ：一个由数组结构组成的有界阻塞队列，遵循FIFO原则。LinkedBlockingQueue ：一个由链表结构组成的有界阻塞队列，遵循FIFO原则，默认和最大长度为Integer.MAX_VALUE。PriorityBlockingQueue ：一个支持优先级排序的无界阻塞队列。DelayQueue：一个使用优先级队列实现的支持延时无界阻塞队列。SynchronousQueue：一个不存储元素的阻塞队列。LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。有界：有初始化最大长度，达到最大程度继续添加要莫阻塞，要莫抛出异常无界：没有初始化最大长度，能够一直添加，不会阻塞或抛出异常，一直到OOM。因为阻塞队列实现都差不多，我们就拿ArrayBlockingQueue来看下实现ArrayBlockingQueue结构阻塞队列的实现都差不多，我们就拿ArrayBlockingQueue 来举例1234567891011121314151617 //底层数据结构 private final E[] items;//用来为下一个take/poll/remove的索引（出队） private int takeIndex;//用来为下一个put/offer/add的索引（入队） private int putIndex;//队列中元素的个数 private int count;//定义的可重入锁 final ReentrantLock lock; //非空的条件 private final Condition notEmpty; //非满的条件 private final Condition notFull;构造方法123456789101112131415161718192021222324252627282930 /** * 创造一个队列，指定队列容量，默认模式为非公平模式 * @param capacity &lt;1会抛异常 */ public ArrayBlockingQueue(int capacity) &#123; this(capacity, false); &#125;/** * ArrayBlockingQueue 的构造方法 * * @param capacity 初始化大小 默认Integer * @param fair 是否使用公平锁 */ public ArrayBlockingQueue(int capacity, boolean fair) &#123; //指定大小&lt;=0 抛出异常 if (capacity &lt;= 0) &#123; throw new IllegalArgumentException(); &#125; //初始化数组的大小 this.items = new Object[capacity]; //创建可重入锁 lock = new ReentrantLock(fair); //创建非空条件 notEmpty = lock.newCondition(); //创建非满条件 notFull = lock.newCondition(); &#125;入队offer不阻塞添加在队尾插入一个元素， 如果队列没满，立即返回true； 如果队列满了，立即返回false1234567891011121314151617181920212223242526 /** * 在队尾插入一个元素， * 如果队列没满，立即返回true； * 如果队列满了，立即返回false * 注意：该方法通常优于add(),因为add()失败直接抛异常 */public boolean offer(E e) &#123; //检查非空 checkNotNull(e); final ReentrantLock lock = this.lock; //加锁 lock.lock(); try &#123; //队列满了 if (count == items.length) &#123; return false; //队列没有满 &#125; else &#123; //入队 enqueue(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125;offer等待超时阻塞添加12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 在队尾插入一个元素,如果数组已满，则进入等待，直到出现以下三种情况： * 1、被唤醒 * 2、等待时间超时 * 3、当前线程被中断 * @param e 需要添加的元素 * @param timeout 超时时间 * @param unit 时间单位 * @return * @throws InterruptedException */public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; //检查非空 checkNotNull(e); //计算等待时间 long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; //可中断锁加锁 lock.lockInterruptibly(); try &#123; //队列满 while (count == items.length) &#123; //如果超时返回fasle if (nanos &lt;= 0) return false; /* * 进行等待： * 在这个过程中可能发生三件事： * 1、被唤醒--&gt;继续当前这个for(;;)循环 * 2、超时--&gt;继续当前这个for(;;)循环 * 3、被中断--&gt;之后直接执行catch部分的代码 */ nanos = notFull.awaitNanos(nanos); &#125; //入队 enqueue(e); return true; &#125; finally &#123; //解锁 lock.unlock(); &#125;&#125;put阻塞添加在队尾插入一个元素，如果队列满了，一直阻塞，直到数组不满了或者线程被中断12345678910111213141516171819202122/** * 在队尾插入一个元素 * 如果队列满了，一直阻塞，直到数组不满了或者线程被中断 */public void put(E e) throws InterruptedException &#123; //检查非空 checkNotNull(e); final ReentrantLock lock = this.lock; //可中断锁-加锁 lock.lockInterruptibly(); try &#123; //队列满了 阻塞 while (count == items.length) &#123; notFull.await(); &#125; //入队 enqueue(e); &#125; finally &#123; //解锁 lock.unlock(); &#125;&#125;这里使用的lock.lockInterruptibly() ,当前线程如果调用了Thread.interrupt()方法，那么lockInterruptible()判断的Thread.interrupted()聚会成立，就会抛出异常，其实就是线程中断，该方法就抛出异常。enqueue入队操作1234567891011121314151617181920/** * 入队操作 * * @param x 需要入队的袁旭 */ private void enqueue(E x) &#123; // assert lock.getHoldCount() == 1; // assert items[putIndex] == null; final Object[] items = this.items; //putIndex 默认为队列数据的长度 items[putIndex] = x; //队列满了重置为0 从头开始 if (++putIndex == items.length) &#123; putIndex = 0; &#125; //统计数字+1 count++; //非空的条件阻塞的线程唤醒 notEmpty.signal(); &#125;队列没满items[putIndex] = data;达到数组长度重置putIndex，达到环形队列目的出队poll非阻塞出队如果没有元素，直接返回null；如果有元素，将队头元素置null，但是要注意队头是随时变化的，并非一直是items[0]。1234567891011121314/** * 出队 * @return */ public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; //队列为空返回努力了,否则出队操作 return (count == 0) ? null : dequeue(); &#125; finally &#123; lock.unlock(); &#125; &#125;poll 等待超时阻塞出队从对头删除一个元素，如果数组不空，出队；如果数组已空且已经超时，返回null；如果数组已空且时间未超时，则进入等待，直到出现以下三种情况：被唤醒等待时间超时当前线程被中断1234567891011121314151617181920212223242526272829303132333435/** * 等待超时出队 * @param timeout 超时时间 * @param unit 单位 * @return 出队的元素 * @throws InterruptedException */ public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; //计算等待时间 long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; //可中断锁 lock.lockInterruptibly(); try &#123; //队列为空 while (count == 0) &#123; //等待时间到了还未没有元素返回null if (nanos &lt;= 0) &#123; return null; &#125; /* * 进行等待： * 在这个过程中可能发生三件事： * 1、被唤醒--&gt;继续当前这个for(;;)循环 * 2、超时--&gt;继续当前这个for(;;)循环 * 3、被中断--&gt;之后直接执行catch部分的代码 */ nanos = notEmpty.awaitNanos(nanos); &#125; //出队 return dequeue(); &#125; finally &#123; lock.unlock(); &#125; &#125;take阻塞移除12345678910111213141516171819202122/** * 阻塞移除操作 * @return 返回移除的元素 * @throws InterruptedException */ public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; //可中断锁 lock.lockInterruptibly(); try &#123; //如果元素为空就阻塞 while (count == 0) &#123; //非空阻塞 notEmpty.await(); &#125; //出队操作 return dequeue(); &#125; finally &#123; //解锁 lock.unlock(); &#125; &#125;dequeue出队操作1234567891011121314151617181920212223242526/** * 出队操作 * @return 返回出队的元素 */private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; //获取第takeIndex个元素 E x = (E) items[takeIndex]; //删除元素，让GC进行回收 items[takeIndex] = null; //takeIndex+1 如果移除到最后一个元素 重置为0 从头开始 if (++takeIndex == items.length) &#123; takeIndex = 0; &#125; //统计长度-1 count--; if (itrs != null) &#123; //元素 itrs.elementDequeued(); &#125; //队列不满了唤醒非满线程 notFull.signal(); return x;&#125;使用场景延时队列 DelayQueue在我们的业务中通常会有一些需求是这样的淘宝订单业务:下单之后如果三十分钟之内没有付款就自动取消订单。饿了吗订餐通知:下单成功后60s之后给用户发送短信通知。缓存系统，如果key到期了取出来删除那么这类业务我们可以总结出一个特点:需要延迟工作。由此的情况，就是我们的DelayQueue应用需求的产生。看一个简单的例子123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class DelayedTask implements Delayed &#123; public DelayedTask(int delayedTime, TimeUnit unit, String message) &#123; this.delayedTime = delayedTime; //计算到期时间 this.expireTime = System.currentTimeMillis() + (delayedTime &gt; 0 ? unit.toMillis(delayedTime) : 0); this.message = message; &#125; //延时时长 private int delayedTime; /** * 到期时间 */ private long expireTime; /** * 消息 */ private String message; /** * 获取队列需要演示获取水煎 * @param unit * @return */ @Override public long getDelay(TimeUnit unit) &#123; return expireTime - System.currentTimeMillis(); &#125; /** * 对比，将延时比较小的放在前面 * @param other * @return */ @Override public int compareTo(Delayed other) &#123; long d = (getDelay(TimeUnit.NANOSECONDS) - other.getDelay(TimeUnit.NANOSECONDS)); return (d == 0) ? 0 : ((d &lt; 0) ? -1 : 1); &#125; @Override public String toString() &#123; return \"出队，延时:\"+delayedTime+\",消息：\"+message; &#125; public static void main(String[] args) throws InterruptedException &#123; Random random = new Random(); ExecutorService executorService = Executors.newCachedThreadPool(); DelayQueue&lt;DelayedTask&gt; delayedTasks = new DelayQueue&lt;DelayedTask&gt;(); //生产者 executorService.submit(() -&gt; &#123; while (true) &#123; //生成随机消息 String randomStr = RandomStringUtils.randomNumeric(10); //生成随机数 int randomTime = random.nextInt(10); DelayedTask task = new DelayedTask(randomTime, TimeUnit.SECONDS, randomStr); //入队 delayedTasks.add(task); System.out.println(\"入队，消息：\" + randomStr + \"延时：\" + randomTime + \"秒\"); Thread.sleep(1000); &#125; &#125;); //消费者 executorService.submit(() -&gt; &#123; while (true) &#123; DelayedTask task = delayedTasks.take(); System.out.println(task); &#125; &#125;); //显示时间进度 executorService.submit(() -&gt; &#123; float time = 0F; while (true) &#123; System.out.println(time+\"秒\"); Thread.sleep(500); time += 0.5; &#125; &#125;); executorService.shutdown(); &#125;&#125;输出12345678910111213141516171819202122232425262728293031320.0秒入队，消息：8675326967延时：5秒0.5秒入队，消息：8861554454延时：0秒出队，延时:0,消息：88615544541.0秒1.5秒入队，消息：9123579697延时：1秒2.0秒2.5秒出队，延时:1,消息：9123579697入队，消息：5909478713延时：6秒3.0秒3.5秒入队，消息：6287328130延时：0秒出队，延时:0,消息：62873281304.0秒4.5秒出队，延时:5,消息：8675326967入队，消息：4056656965延时：7秒5.0秒5.5秒入队，消息：8250385270延时：9秒6.0秒6.5秒入队，消息：1949026689延时：1秒7.0秒7.5秒出队，延时:1,消息：1949026689入队，消息：2952840210延时：9秒8.0秒8.5秒总结ArrayBlockingQueue是有界的阻塞队列，不接受null底层数据接口是数组，下标putIndex/takeIndex，构成一个环形FIFO队列所有的增删改查数组公用了一把锁ReentrantLock，入队和出队数组下标和count变更都是靠这把锁来维护安全的。阻塞的场景：1获取lock锁，2进入和取出还要满足condition 满了或者空了都等待出队和加入唤醒，ArrayBlockingQueue我们主要是put和take真正用到的阻塞方法（条件不满足）。成员cout /putIndex、takeIndex是共享的,所以一些查询方法size、peek、toString、方法也是加上锁保证线程安全，但没有了并发损失了性能。remove(Object obj) 返回了第一个equals的Object三种入队对比offer(E e)：如果队列没满，立即返回true； 如果队列满了，立即返回false–&gt;不阻塞put(E e)：如果队列满了，一直阻塞，直到数组不满了或者线程被中断–&gt;阻塞offer(E e, long timeout, TimeUnit unit)：在队尾插入一个元素,，如果数组已满，则进入等待，直到出现以下三种情况：–&gt;阻塞被唤醒等待时间超时当前线程被中断三种出对对比poll()：如果没有元素，直接返回null；如果有元素，出队take()：如果队列空了，一直阻塞，直到数组不为空或者线程被中断–&gt;阻塞poll(long timeout, TimeUnit unit)：如果数组不空，出队；如果数组已空且已经超时，返回null；如果数组已空且时间未超时，则进入等待，直到出现以下三种情况：被唤醒等待时间超时当前线程被中断等待通知模式这里面要理解等待/通知模式阻塞队列使用了等待/通知的设计模式标准范式等待方123456789101112 //等待方public void wait() &#123; lock.lock(); try &#123; while (条件) &#123; condition.await(); &#125; //todo 业务代码 &#125; finally &#123; lock.unlock(); &#125;&#125;通知方1234public void notify() &#123; //todo 改变数据 condition.signal();&#125;等待超时模式标准范式12345678910111213141516public Integer wait(long time, TimeUnit timeUnit) &#123; //获取到期时间 long duration = timeUnit.toMillis(time); lock.lock(); try &#123; while (duration &gt; 0) &#123; duration += System.currentTimeMillis(); condition.await(time, timeUnit); duration -= System.currentTimeMillis(); &#125; //todo 业务代码 return null; &#125; finally &#123; lock.unlock(); &#125; &#125;","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"阻塞队列","slug":"源码/阻塞队列","permalink":"http://www.baiyp.ren/categories/源码/阻塞队列/"}],"tags":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"},{"name":"阻塞队列","slug":"阻塞队列","permalink":"http://www.baiyp.ren/tags/阻塞队列/"},{"name":"ArrayBlockingQueue","slug":"ArrayBlockingQueue","permalink":"http://www.baiyp.ren/tags/ArrayBlockingQueue/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"阻塞队列","slug":"源码/阻塞队列","permalink":"http://www.baiyp.ren/categories/源码/阻塞队列/"}]},{"title":"JAVA中的分布式事务08-分布式事务总结","slug":"JAVA中的分布式事务08","date":"2019-08-18T02:05:25.000Z","updated":"2019-08-22T02:09:38.642Z","comments":true,"path":"JAVA中的分布式事务08.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的分布式事务08.html","excerpt":"","text":"JAVA中的分布式事务08-分布式事务总结各方案使用场景​ 介绍完分布式事务相关理论和常见解决方案后，最终的目的在实际项目中运用，因此，总结一下各个方案的常见的使用场景。2PC/3PC依赖于数据库，能够很好的提供强一致性和强事务性，但相对来说延迟比较高，比较适合传统的单体应用，在同一个方法中存在跨库操作的情况，不适合高并发和高性能要求的场景。TCC适用于执行时间确定且较短，实时性要求高，对数据一致性要求高，比如互联网金融企业最核心的三个服务：交易、支付、账务。本地消息表/MQ事务都适用于事务中参与方支持操作幂等，对一致性要求不高，业务上能容忍数据不一致到一个人工检查周期，事务涉及的参与方、参与环节较少，业务上有对账/校验系统兜底。Saga事务由于Saga事务不能保证隔离性，需要在业务层控制并发，适合于业务场景事务并发操作同一资源较少的情况。Saga相比缺少预提交动作，导致补偿动作的实现比较麻烦，例如业务是发送短信，补偿动作则得再发送一次短信说明撤销，用户体验比较差。Saga事务较适用于补偿动作容易处理的场景。分布式事务的分类刚性事务刚性事务是指再解决事务中需要锁表的操作,相对来说性能低2PC，3PC柔性事务是指再解决事务中不需要锁表的操作，因为不需要锁表，导致会发生临时不一致。TCC，本地消息表，MQ事务，Saga分布式事务方案设计​ 实际运用理论时进行架构设计时，许多人容易犯“手里有了锤子，看什么都觉得像钉子”的错误，设计方案时考虑的问题场景过多，各种重试，各种补偿机制引入系统，导致设计出来的系统过于复杂，落地遥遥无期。世界上解决一个计算机问题最简单的方法：“恰好”不需要解决它！—— 阿里中间件技术专家沈询​ 有些问题，看起来很重要，但实际上我们可以通过合理的设计或者将问题分解来规避。设计分布式事务系统也不是需要考虑所有异常情况，不必过度设计各种回滚，补偿机制。如果硬要把时间花在解决问题本身，实际上不仅效率低下，而且也是一种浪费。​ 如果系统要实现回滚流程的话，有可能系统复杂度将大大提升，且很容易出现Bug，估计出现Bug的概率会比需要事务回滚的概率大很多。在设计系统时，我们需要衡量是否值得花这么大的代价来解决这样一个出现概率非常小的问题，可以考虑当出现这个概率很小的问题，能否采用人工解决的方式，这也是大家在解决疑难问题时需要多多思考的地方。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.baiyp.ren/tags/分布式事务/"},{"name":"总结","slug":"总结","permalink":"http://www.baiyp.ren/tags/总结/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}]},{"title":"ThreadLocal源码解析02","slug":"ThreadLocal源码解析02","date":"2019-08-17T02:49:37.000Z","updated":"2019-08-22T02:08:13.186Z","comments":true,"path":"ThreadLocal源码解析02.html","link":"","permalink":"http://www.baiyp.ren/ThreadLocal源码解析02.html","excerpt":"","text":"ThreadLocal源码解析02上一节我们详细解析了set方法，现在我们来解析get方法ThreadLocal.get 方法ThreadLocal.get 方法相对来说简单我们先来看下get的流程图下面我们解析代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647//获取ThreadLocal 中的值 public T get() &#123; //获取当前线程 Thread t = Thread.currentThread(); //同set方法类似获取对应线程中的ThreadLocalMap实例 ThreadLocal.ThreadLocalMap map = getMap(t); if (map != null) &#123; //从Map中根据ThreadLocal获取entry ThreadLocal.ThreadLocalMap.Entry e = map.getEntry(this); //如果Entry 不为空 则返回 if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T) e.value; return result; &#125; &#125; //为空返回初始化值 return setInitialValue(); &#125; /** * 初始化设值的方法，可以被子类覆盖。 */ protected T initialValue() &#123; return null; &#125; /** * 设置初始化的方法 * @return */ private T setInitialValue() &#123; //获取初始化值，默认为null(如果没有子类进行覆盖) T value = initialValue(); Thread t = Thread.currentThread(); //同set方法类似获取对应线程中的ThreadLocalMap实例 ThreadLocalMap map = getMap(t); //不为空不用再初始化，直接调用set操作设值 if (map != null) map.set(this, value); else &#123; //第一次初始化，createMap在上面介绍set()的时候有介绍过。 createMap(t, value); &#125; //返回初始化后的值 return value; &#125;我们发现首先从当前线程中获取ThreadLocalMap 然后从map中根据ThreadLocal获取entry，entry不为空则返回value，否则调用setInitialValue设置初始值并返回。我们深入到 map.getEntry(this);方法ThreadLocalMap.getEntry 方法123456789101112131415161718/** * 根据 ThreadLocal 获取获取entry * @param key 当前的threadLocal * @return */ private ThreadLocal.ThreadLocalMap.Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; //计算 table 中需要映射的下标 int i = key.threadLocalHashCode &amp; (table.length - 1); //从table中获取entry ThreadLocal.ThreadLocalMap.Entry e = table[i]; //如果entry 不为空且entry中的key和传入的key匹配则返回entry if (e != null &amp;&amp; e.get() == key) return e; else &#123; //发生了hash冲突，当前的entry为空或者key和传入的key不一致 return getEntryAfterMiss(key, i, e); &#125; &#125;getEntryAfterMiss123456789101112131415161718192021222324/** * 通过直接计算出来的key找不到对于的value的时候适用这个方法. */ private ThreadLocal.ThreadLocalMap.Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, ThreadLocal.ThreadLocalMap.Entry e) &#123; ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); //如果当前的key和传入的key匹配则返回 if (k == key) return e; if (k == null) //清除无效的entry expungeStaleEntry(i); else &#123; //基于线性探测法向后扫描 i = nextIndex(i, len); &#125; e = tab[i]; &#125; //找不到返回null return null; &#125;到这里 get方法以及完结了。ThreadLocal.remove 方法1234567891011121314151617181920212223242526272829public void remove() &#123; //同set方法类似获取对应线程中的ThreadLocalMap实例 ThreadLocal.ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) &#123; //调用ThreadLocalMap的remove方法进行清除entry m.remove(this); &#125; &#125; /** * 根据ThreadLocal 删除entry * @param key 当前的ThreadLocal */ private void remove(ThreadLocal&lt;?&gt; key) &#123; ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; //计算 table 中需要映射的下标 int i = key.threadLocalHashCode &amp; (len - 1); //进行线性探测，查找正确的key for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; if (e.get() == key) &#123; //调用weakrefrence的clear()清除引用 e.clear(); //连续段清除 expungeStaleEntry(i); return; &#125; &#125; &#125;​ remove()在有上面了解后可以说极为简单了，就是找到对应的table[],调用weakrefrence的clear()清除引用，然后再调用expungeStaleEntry()进行清除。ThreadLocal 防止hash冲突的到这里整个threadLocal 基本介绍完成了，但是还少一块，如何处理hash冲突的生成映射下标1int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1);这一段代码和 求模的效果类似，根据hash生成一个0-(INITIAL_CAPACITY-1)之间的数我们发现计算冲突与threadLocalHashCode 和 INITIAL_CAPACITY有关INITIAL_CAPACITY值的设置例如 ：10 0001 0111 110100 0000 0000 1111 &amp; (INITIAL_CAPACITY-1) 即 1500 0000 0000 1101 13所以这种算法只对后半段的数据敏感 如果是其他值 后面可能包含0 例如 0011 这样只有两位参与了运算，重复率就增加了，如果下面的值全是1 就更加平均了，什么时候全是1呢 就是 2的N次幂-1例如2^4=16=10000B16-1=15= 01111B所以只有当INITIAL_CAPACITY值时2的n次幂的时候才对hash的数据敏感，因为是与运算，只利用了hahs二进制的后半段。threadLocalHashCode 值的设置我们看下threadLocalHashCode 的声明123456private final int threadLocalHashCode = nextHashCode(); //返回下一个hashCode private static int nextHashCode() &#123; //通过CAS的方式进行获取并且相加 return nextHashCode.getAndAdd(HASH_INCREMENT);&#125;这里面有一个神奇的数字 HASH_INCREMENT他的声明是1private static final int HASH_INCREMENT = 0x61c88647;神奇的数字既然ThreadLocal用map就避免不了冲突的产生这里碰撞其实有两种类型只有一个ThreadLocal实例的时候(上面推荐的做法)，当向thread-local变量中设置多个值的时产生的碰撞，碰撞解决是通过开放定址法， 且是线性探测(linear-probe)多个ThreadLocal实例的时候，最极端的是每个线程都new一个ThreadLocal实例，此时利用特殊的哈希码0x61c88647大大降低碰撞的几率， 同时利用开放定址法处理碰撞注意 0x61c88647的利用主要是为了多个ThreadLocal实例的情况下用的注意实例变量threadLocalHashCode, 每当创建ThreadLocal实例时这个值都会累加 0x61c88647,为了让哈希码能均匀的分布在2的N次方的数组里, 即 Entry[] table的大小必须是2的N次方我们看下table的定义1234567/** * The table, resized as necessary. * 该表根据需要调整大小。 * table.length MUST always be a power of two. * table.length必须始终是2的幂。 */private Entry[] table;key.threadLocalHashCode &amp; (len-1)这么用是什么意思? 我们上面定义了table数组的长度是16 =2^4​ ThreadLocalMap 中Entry[] table的大小必须是2的N次方呀(len = 2^N)，那 len-1 的二进制表示就是低位连续的N个1， 那 key.threadLocalHashCode &amp; (len-1) 的值就是 threadLocalHashCode 的低N位, 这样就能均匀的产生均匀的分布? 我们做个实验。1234567891011121314151617181920212223//神奇的数字private static final int HASH_INCREMENT = 0x61c88647;//模拟table大小 16 2^4private static final int tableSize = 1 &lt;&lt; 4;public static void main(String[] args) &#123; getHashIndex(1000);&#125;public static void getHashIndex(int num) &#123; Map&lt;Integer, Integer&gt; map = new HashMap&lt;&gt;(); int nextHashCode = HASH_INCREMENT; for (int i = 0; i &lt; num; i++) &#123; //每次进行*2 计算 nextHashCode += HASH_INCREMENT; //计算映射的小标 int index = nextHashCode &amp; (tableSize - 1); //用Map进行统计 Integer count = map.computeIfAbsent(index, x -&gt; 0); map.put(index, ++count); &#125; System.out.println(map);&#125;输出1&#123;0=62, 1=63, 2=62, 3=63, 4=62, 5=63, 6=62, 7=62, 8=63, 9=62, 10=63, 11=62, 12=63, 13=62, 14=63, 15=63&#125;我们发现数据分布的惊人的平均，比我们写的随机数更平均。总结Hash冲突怎么解决​ 和HashMap的最大的不同在于，ThreadLocalMap结构非常简单，没有next引用，也就是说ThreadLocalMap中解决Hash冲突的方式并非链表的方式，而是采用线性探测的方式，所谓线性探测，就是根据初始key的hashcode值确定元素在table数组中的位置，如果发现这个位置上已经有其他key值的元素被占用，则利用固定的算法寻找一定步长的下个位置，依次判断，直至找到能够存放的位置。内存泄露问题​ threadlocal里面使用了一个存在弱引用的map,当释放掉threadlocal的强引用以后,map里面的value却没有被回收.而这块value永远不会被访问到了. 所以存在着内存泄露. 最好的做法是将调用threadlocal的remove方法.​ 因为ThreadLocal本身又清理机制，调用，get,set,remove等方法时会触发自动清理机制，清理掉key为空的主句，但是不是实时的，会有延后，在没有调用get,set,remove方法时，过期的entry时内存泄漏状态，推荐不适用了调用remove方法。hash散列算法​ 在实际使用中，不同的输入可能会散列成相同的输出，这时也就产生了冲突。通过上文提到的 HASH_INCREMENT 再借助一定的算法，就可以将哈希码能均匀的分布在 2 的 N 次方的数组里，保证了散列表的离散度，从而降低了冲突几率，使用nextHashCode &amp; (tableSize - 1);这种方式进行下标映射性能更高，使用用HASH_INCREMENT 0x61c88647 这个神奇的数字让数据分布的更平均。","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"ThreadLocal","slug":"源码/ThreadLocal","permalink":"http://www.baiyp.ren/categories/源码/ThreadLocal/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://www.baiyp.ren/tags/ThreadLocal/"},{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"ThreadLocal","slug":"源码/ThreadLocal","permalink":"http://www.baiyp.ren/categories/源码/ThreadLocal/"}]},{"title":"ThreadLocal源码解析01","slug":"ThreadLocal源码解析01","date":"2019-08-16T11:49:37.000Z","updated":"2019-08-22T02:08:03.643Z","comments":true,"path":"ThreadLocal源码解析01.html","link":"","permalink":"http://www.baiyp.ren/ThreadLocal源码解析01.html","excerpt":"","text":"ThreadLocal源码解析01先看下set的流程图ThreadLocal 简介​ ThreadLocal 在面试中经常提到，关于ThreadLocal使用不当造成OOM以及在特殊场景下，通过ThreadLocal可以轻松实现一些看起来复杂的功能，都说明值得花时间研究其原理。​ ThreadLocal 不是 Thread，是一个线程内部的数据存储类，通过它可以在指定的线程中存储数据，每个线程存储的是主线程变量的副本，子线程操作的是对副本进行操作，不影响其他子线程的中的数据，所以一般说，ThreadLocal不保证线程的安全，只保证线程的隔离。​ 举个例子，如果ThreadLocal保存保存的是一个静态变量，副本都是静态变量自己，这样就又会出现线程安全问题。ThreadLocal 注意事项ThreadLocal类封装了getMap()、set()、get()、remove()4个核心方法通过getMap()获取每个子线程Thread持有自己的ThreadLocalMap实例, 因此它们是不存在并发竞争的。可以理解为每个线程有自己的变量副本。ThreadLocalMap中Entry[]数组存储数据，初始化长度16，后续每次都是2倍扩容。主线程中定义了几个变量，Entry[]中就有几个key。Entry的key是对ThreadLocal的弱引用，当抛弃掉ThreadLocal对象时，垃圾收集器会忽略这个key的引用而清理掉ThreadLocal对象， 防止了内存泄漏。源码解读看源码要有入口我们先从初始化开始ThreadLocal 初始化方式123456789/** * 定义一个ThreadLocal */ private static ThreadLocal&lt;Integer&gt; threadLocal = new ThreadLocal&lt;Integer&gt;(); public static void main(String[] args) &#123; //设置变量的值 threadLocal.set(1); &#125;我们发现ThreadLocal的set方法是设置值的，他为什么能是变量的副本呢我们进入set方法ThreadLocal.set 方法123456789101112//设置此线程局部变量的当前线程副本public void set(T value) &#123; //获取当前线程 Thread t = Thread.currentThread(); //根据当前线程获取ThreadLocalMap ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else //如果map为空就创建一个显得Map参数是当前线程和我们需要设置的值 createMap(t, value); &#125;我看看set方法 很简单，获取当前线程，根据当前线程获取ThreadLocalMap，有的话就set没有就创建我们可以这样理解 ThreadLocalMap 和当前线程有关，我们进去看下ThreadLocal.getMap方法1234//从当前线程获取 ThreadLocalMapThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125;好吧到这里 确定了ThreadLocalMap 实在当前线程中存储了，这也解释了为什么是变量的副本，调用ThreadLocal的set方法实际上是将值放进当前的线程中了，每个线程中的值是不一样的。我们需要进入Thread内部看源码了12//再Thread 中定义的ThreadLocalMapThreadLocal.ThreadLocalMap threadLocals = null;我们发现ThreadLocalMap 实在Thread类中定义的到这里ThreadLocal.getMap方法解析完了，我们需要看createMap方法了。ThreadLocal.createMap方法set 方法是获取线程内部的ThreadLocalMap，初始化肯定为空，就需要调用createMap了123456789//创建ThreadLocalMap void createMap(Thread t, T firstValue) &#123; /** * this 就是ThreadLocal 本身 * * firstValue 就是我们需要保存的值 */ t.threadLocals = new ThreadLocalMap(this, firstValue); &#125;我看看这段代码，很有意思，ThreadLocalMap的key是threadLocal本身，value则是我们需要设置的值，这里就出现一个问题，key是相同的，如果一个ThreadLocal有多个值肯定会被覆盖，所以可以确定，ThreadLocalMap是用来处理一个线程中存在多个ThreadLocal的问题，value肯定有更细化的对象存储，我们进去看看ThreadLocalMap的构造方法。ThreadLocalMap的构造方法12345678910111213141516171819202122232425/** *构建一个最初包含（firstkey，firstvalue）的新的 ThreadLocalMap。 *因为Thread中的 ThreadLocalMaps是懒加载构造的，所以我们只创建 * * @param firstKey ThreadLocal 本身 * @param firstValue 需要存放的第一个值 */ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; //创建一个Entry数组的表，初始化大小为INITIAL_CAPACITY table = new ThreadLocal.ThreadLocalMap.Entry[INITIAL_CAPACITY]; //通过与运算将threadLocalHashCode映射到一个数组下标 //他比取模或者求余速度快性能高 int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); //将取模后的值映射到对应的Entry数组中的某个位置 table[i] = new ThreadLocal.ThreadLocalMap.Entry(firstKey, firstValue); //因为第一次调用设置size为1 size = 1; //计算下次需要扩容的值 setThreshold(INITIAL_CAPACITY);&#125;//setThreshold方法是计算扩容下次扩容的阈值的private void setThreshold(int len) &#123; threshold = len * 2 / 3;&#125;我们来看下EntryThreadLocalMap.Entry123456789//ThreadLocal作为key进行软引用static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; //与ThreadLocal相绑定的值 Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125;这里使用了WeakReference 软引用WeakReference： 当一个对象仅仅被weak reference（软引用）指向, 而没有任何其他strong reference（强引用）指向的时候, 如果这时GC运行, 那么这个对象就会被回收，不论当前的内存空间是否足够，这个对象都会被回收。也就是如果当前线程的ThreadLocal 被销毁后，因为当前线程引用了ThreadLocalMap，所以当前线程和entry还是强引用，因为ThreadLocal在entry是软引用，所以垃圾回收key(ThreadLocal)会被销毁，entry中的value没有被销毁，但是没有key造成无法访问，这就造成了内存泄漏，ThreadLocal为了防止内存泄漏我们会在后面详细的说。整体结构我们回顾上面介绍的内容我们看下ThreadLocal整体结构的图解ThreadLocalMap.set方法我们上面介绍了getMap和createMap方法，我们来看看map.set方法线性探测算法​ ThreadLocalMap使用线性探测法来解决哈希冲突，线性探测法的地址增量di = 1, 2, … , m-1，其中，i为探测次数。该方法一次探测下一个地址，直到有空的地址后插入，若整个空间都找不到空余的地址，则产生溢出。假设当前table长度为16，也就是说如果计算出来key的hash值为14，如果table[14]上已经有值，并且其key与当前key不一致，那么就发生了hash冲突，这个时候将14加1得到15，取table[15]进行判断，这个时候如果还是冲突会回到0，取table[0],以此类推，直到可以插入。先看一下线性探测相关的代码，从中也可以看出来table实际是一个环：12345678910111213/**java * 获取环形数组的下一个索引 */ private static int nextIndex(int i, int len) &#123; return ((i + 1 &lt; len) ? i + 1 : 0); &#125; /** * 获取环形数组的上一个索引 */ private static int prevIndex(int i, int len) &#123; return ((i - 1 &gt;= 0) ? i - 1 : len - 1); &#125;ThreadLocalMap的set()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * 将Value设置进对应的ThreadLocal 的key 中 * * @param key * @param value */private void set(ThreadLocal&lt;?&gt; key, Object value) &#123; // We don't use a fast path as with get() because it is at // least as common to use set() to create new entries as // it is to replace existing ones, in which case, a fast // path would fail more often than not. /** * 不使用 get的快速路径 set一般是替换方式 * 快速路径一般会失败 */ ThreadLocal.ThreadLocalMap.Entry[] tab = table; //获取table的长度 int len = tab.length; //计算需要映射的table下标 int i = key.threadLocalHashCode &amp; (len - 1); /** * 根据获取到的索引进行循环，如果当前索引上的table[i]不为空，在没有return的情况下， * 就使用nextIndex()获取下一个（上面提到到线性探测法）。 */ for (ThreadLocal.ThreadLocalMap.Entry e = tab[i]; e != null; e = tab[i = nextIndex(i, len)]) &#123; //获取当前的ThreadLocal ThreadLocal&lt;?&gt; k = e.get(); //如果entry中的ThreadLocal(k) 和 传进来的 ThreadLocal(key)是同一个 if (k == key) &#123; //将 e.value替换为新的value e.value = value; return; &#125; /** * table[i]上的key为空，说明被回收了（上面的弱引用中提到过）。 * 这个时候说明改table[i]可以重新使用，用新的key-value将其替换,并删除其他无效的entry */ if (k == null) &#123; //对key为空的entry进行重新赋值替换 replaceStaleEntry(key, value, i); return; &#125; &#125; //找到为空的插入位置，插入值，在为空的位置插入需要对size进行加1操作 tab[i] = new ThreadLocal.ThreadLocalMap.Entry(key, value); int sz = ++size; /** * cleanSomeSlots用于清除那些e.get()==null，也就是table[index] != null &amp;&amp; table[index].get()==null * 之前提到过，这种数据key关联的对象已经被回收，所以这个Entry(table[index])可以被置null。 * 如果没有清除任何entry,并且当前使用量达到了负载因子所定义(长度的2/3)，那么进行rehash() */ if (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold) rehash();&#125;​ 大致分析上面都已经标注出来了，需要注意的是Entry对象是继承是WeakReference也就是一个弱引用是会被回收的，所以对应 的key值可能是为null的。存放对象之后是需要判断数组中存储对象的个数是否超过了设定的临界值threshold的大小，如果超过了需要扩容，并且还要重新计算扩容后所有对象的位置。扩容的方法是rehash()replaceStaleEntry 替换无效的key1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465/** * 替换无效entry */ private void replaceStaleEntry(ThreadLocal&lt;?&gt; key, Object value, int staleSlot) &#123; ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; ThreadLocal.ThreadLocalMap.Entry e; /** * 根据传入的无效entry的位置（staleSlot）,向前扫描 * 一段连续的entry(这里的连续是指一段相邻的entry并且table[i] != null), * 直到找到一个无效entry，或者扫描完也没找到 */ int slotToExpunge = staleSlot;//之后用于清理的起点 for (int i = prevIndex(staleSlot, len); (e = tab[i]) != null; i = prevIndex(i, len)) if (e.get() == null) slotToExpunge = i; /** * 向后扫描一段连续的entry */ for (int i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); /** * 如果找到了key，将其与传入的无效entry替换，也就是与table[staleSlot]进行替换 */ if (k == key) &#123; e.value = value; tab[i] = tab[staleSlot]; tab[staleSlot] = e; //如果向前查找没有找到无效entry，则更新slotToExpunge为当前值i if (slotToExpunge == staleSlot) slotToExpunge = i; cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); return; &#125; /** * 如果向前查找没有找到无效entry，并且当前向后扫描的entry无效，则更新slotToExpunge为当前值i */ if (k == null &amp;&amp; slotToExpunge == staleSlot) slotToExpunge = i; &#125; /** * 如果没有找到key,也就是说key之前不存在table中 * 就直接最开始的无效entry——tab[staleSlot]上直接新增即可 */ tab[staleSlot].value = null; tab[staleSlot] = new ThreadLocal.ThreadLocalMap.Entry(key, value); /** * slotToExpunge != staleSlot,说明存在其他的无效entry需要进行清理。 */ if (slotToExpunge != staleSlot) cleanSomeSlots(expungeStaleEntry(slotToExpunge), len); &#125;expungeStaleEntry 连续段清除123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/** * 连续段清除 * 根据传入的staleSlot,清理对应的无效entry——table[staleSlot], * 并且根据当前传入的staleSlot,向后扫描一段连续的entry(这里的连续是指一段相邻的entry并且table[i] != null), * 对可能存在hash冲突的entry进行rehash，并且清理遇到的无效entry. * * @param staleSlot key为null,需要无效entry所在的table中的索引 * @return 返回下一个为空的solt的索引。 */ private int expungeStaleEntry(int staleSlot) &#123; ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; // 清理无效entry，置空 tab[staleSlot].value = null; tab[staleSlot] = null; //size减1，置空后table的被使用量减1 size--; ThreadLocal.ThreadLocalMap.Entry e; int i; /** * 从staleSlot开始向后扫描一段连续的entry */ for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); //如果遇到key为null,表示无效entry，进行清理. if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; //如果key不为null,计算索引 int h = k.threadLocalHashCode &amp; (len - 1); /** * 计算出来的索引——h，与其现在所在位置的索引——i不一致，置空当前的table[i] * 从h开始向后线性探测到第一个空的slot，把当前的entry挪过去。 */ if (h != i) &#123; tab[i] = null; while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; //下一个为空的solt的索引。 return i; &#125;cleanSomeSlots 清理脏数据1234567891011121314151617181920212223242526272829/** * 启发式的扫描清除，扫描次数由传入的参数n决定 * * @param i 从i向后开始扫描（不包括i，因为索引为i的Slot肯定为null） * * @param n 控制扫描次数，正常情况下为 log2(n) ， * 如果找到了无效entry，会将n重置为table的长度len,进行段清除。 * * map.set()点用的时候传入的是元素个数，replaceStaleEntry()调用的时候传入的是table的长度len * * @return true if any stale entries have been removed. */ private boolean cleanSomeSlots(int i, int n) &#123; boolean removed = false; ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; do &#123; i = nextIndex(i, len); ThreadLocal.ThreadLocalMap.Entry e = tab[i]; if (e != null &amp;&amp; e.get() == null) &#123; //重置n为len n = len; removed = true; //依然调用expungeStaleEntry来进行无效entry的清除 i = expungeStaleEntry(i); &#125; &#125; while ( (n &gt;&gt;&gt;= 1) != 0);//无符号的右移动，可以用于控制扫描次数在log2(n) return removed; &#125;n的用途​ 主要用于扫描控制（scan control），从while中是通过n来进行条件判断的说明n就是用来控制扫描趟数（循环次数）的。在扫描过程中，如果没有遇到脏entry就整个扫描过程持续log2(n)次，log2(n)的得来是因为n &gt;&gt;&gt;= 1，每次n右移一位相当于n除以2。如果在扫描过程中遇到脏entry的话就会令n为当前hash表的长度（n=len），再扫描log2(n)趟，注意此时n增加无非就是多增加了循环次数从而通过nextIndex往后搜索的范围扩大，示意图如下rehash 重新整理rehash 方法分两步1、先是删除过期的对象：expungeStaleEntries()；2、如果存储对象个数大于临界值的3/4，扩容12345678910111213141516/** * 刷新ThreadLocal */private void rehash() &#123; //全清理过期的数据 expungeStaleEntries(); /** * threshold = 2/3 * len * 所以threshold - threshold / 4 = 1en/2 * 这里主要是因为上面做了一次全清理所以size减小，需要进行判断。 * 判断的时候把阈值调低了。 */ if (size &gt;= threshold - threshold / 4) //扩容 resize();&#125;expungeStaleEntries 全清理无效的entry123456789101112131415/** * 全清理，清理所有无效entry */ private void expungeStaleEntries() &#123; ThreadLocal.ThreadLocalMap.Entry[] tab = table; int len = tab.length; //遍历整个table for (int j = 0; j &lt; len; j++) &#123; ThreadLocal.ThreadLocalMap.Entry e = tab[j]; // Entry存在且key不存在 就是 threadLoca已被GC回收 if (e != null &amp;&amp; e.get() == null) //使用连续段清理 expungeStaleEntry(j); &#125; &#125;​ 删除数组中过时的Entry对象。有些小伙伴可能会有些疑问什么是过时的Entry？为什么会过时？其实这个在前面说过，Entry是弱引用会被回收。这个方法中判断的删除条件是，Entry对象不为空并且key值为空。可见expungStaleEntry(j) 方法就是删除指定索引的Entry对象。resize扩容方法123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 扩容，扩大为原来的2倍（这样保证了长度为2的冥） */private void resize() &#123; //将table 赋值为old table ThreadLocal.ThreadLocalMap.Entry[] oldTab = table; int oldLen = oldTab.length; //扩容是原来的二倍 int newLen = oldLen * 2; //创建一个新的table ThreadLocal.ThreadLocalMap.Entry[] newTab = new ThreadLocal.ThreadLocalMap.Entry[newLen]; int count = 0; //遍历old table for (int j = 0; j &lt; oldLen; ++j) &#123; //获取当前遍历到的entry ThreadLocal.ThreadLocalMap.Entry e = oldTab[j]; //如果存在entry if (e != null) &#123; //获取key ThreadLocal&lt;?&gt; k = e.get(); //虽然做过一次清理，但在扩容的时候可能会又存在key==null的情况。 if (k == null) &#123; //将value置为空，让GC进行回收 e.value = null; // Help the GC &#125; else &#123; //重新计算下标 int h = k.threadLocalHashCode &amp; (newLen - 1); //同样适用线性探测来设置值，如果发生hahs冲突找到向后找到最近的一个空位 while (newTab[h] != null) &#123; h = nextIndex(h, newLen); &#125; //将entry 放进计算出的table对应的下标数组中 newTab[h] = e; count++; &#125; &#125; &#125; //重新设置下次扩容的阈值 setThreshold(newLen); //赋值threadLocal 的size size = count; //将新的table赋值为 table对象 table = newTab;&#125;​ 先是创建一个是原来容量两倍的Entry[]数组，在遍历原来的数组，将key值为空的Entry对象的value置为空方便GC回收，key不为空的Entry对象先根据key的hashcode计算需要存放的位置存入新的数组中，存储结束后别忘了更新临界值。到这里整个set方法的过程也完结了下一篇介绍其他的方法以及threadlocal的总结","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"ThreadLocal","slug":"源码/ThreadLocal","permalink":"http://www.baiyp.ren/categories/源码/ThreadLocal/"}],"tags":[{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://www.baiyp.ren/tags/ThreadLocal/"},{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"ThreadLocal","slug":"源码/ThreadLocal","permalink":"http://www.baiyp.ren/categories/源码/ThreadLocal/"}]},{"title":"JAVA中的分布式事务07-Saga事务(最终一致性)","slug":"JAVA中的分布式事务07","date":"2019-08-16T02:05:25.000Z","updated":"2019-08-22T02:09:30.959Z","comments":true,"path":"JAVA中的分布式事务07.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的分布式事务07.html","excerpt":"","text":"JAVA中的分布式事务07-Saga事务(最终一致性)方案简介​ Saga事务源于1987年普林斯顿大学的Hecto和Kenneth发表的如何处理long lived transaction（长活事务）论文，Saga事务核心思想是将长事务拆分为多个本地短事务，由Saga事务协调器协调，如果正常结束那就正常完成，如果某个步骤失败，则根据相反顺序一次调用补偿操作。处理流程Saga事务基本协议每个Saga事务由一系列幂等的有序子事务(sub-transaction) Ti 组成。每个Ti 都有对应的幂等补偿动作Ci，补偿动作用于撤销Ti造成的结果。可以看到，和TCC相比，Saga没有“预留”动作，它的Ti就是直接提交到库。下面以下单流程为例，整个操作包括：创建订单、扣减库存、支付、增加积分Saga的执行顺序有两种：事务正常执行完成T1, T2, T3, …, Tn，例如：扣减库存(T1)，创建订单(T2)，支付(T3)，依次有序完成整个事务。事务回滚T1, T2, …, Tj, Cj,…, C2, C1，其中0 &lt; j &lt; n，例如：扣减库存(T1)，创建订单(T2)，支付(T3，支付失败)，支付回滚(C3)，订单回滚(C2)，恢复库存(C1)。Saga的两种恢复策略向前恢复(forward recovery)对应于上面第一种执行顺序，适用于必须要成功的场景，发生失败进行重试，执行顺序是类似于这样的：T1, T2, …, Tj(失败), Tj(重试),…, Tn，其中j是发生错误的子事务(sub-transaction)。该情况下不需要Ci。向后恢复(backward recovery)对应于上面提到的第二种执行顺序，其中j是发生错误的子事务(sub-transaction)，这种做法的效果是撤销掉之前所有成功的子事务，使得整个Saga的执行结果撤销。Saga事务常见的有两种不同的实现方式命令协调(Order Orchestrator)中央协调器负责集中处理事件的决策和业务逻辑排序。​ 中央协调器（Orchestrator，简称OSO）以命令/回复的方式与每项服务进行通信，全权负责告诉每个参与者该做什么以及什么时候该做什么。以电商订单的例子为例：1、事务发起方的主业务逻辑请求OSO服务开启订单事务2、OSO向库存服务请求扣减库存，库存服务回复处理结果。3、OSO向订单服务请求创建订单，订单服务回复创建结果。4、OSO向支付服务请求支付，支付服务回复处理结果。5、主业务逻辑接收并处理OSO事务处理结果回复。​ 中央协调器必须事先知道执行整个订单事务所需的流程(例如通过读取配置)。如果有任何失败，它还负责通过向每个参与者发送命令来撤销之前的操作来协调分布式的回滚。基于中央协调器协调一切时，回滚要容易得多，因为协调器默认是执行正向流程，回滚时只要执行反向流程即可。事件编排 (Event Choreography)没有中央协调器（没有单点风险）时，每个服务产生并观察其他服务的事件，并决定是否应采取行动。​ 在事件编排方法中，第一个服务执行一个事务，然后发布一个事件。该事件被一个或多个服务进行监听，这些服务再执行本地事务并发布（或不发布）新的事件。当最后一个服务执行本地事务并且不发布任何事件时，意味着分布式事务结束，或者它发布的事件没有被任何Saga参与者听到都意味着事务结束。以电商订单的例子为例：1、事务发起方的主业务逻辑发布开始订单事件2、库存服务监听开始订单事件，扣减库存，并发布库存已扣减事件2、订单服务监听库存已扣减事件，创建订单，并发布订单已创建事件4、支付服务监听订单已创建事件，进行支付，并发布订单已支付事件5、主业务逻辑监听订单已支付事件并处理。方案总结命令协调设计的优点和缺点优点1、服务之间关系简单，避免服务之间的循环依赖关系，因为Saga协调器会调用Saga参与者，但参与者不会调用协调器2、程序开发简单，只需要执行命令/回复(其实回复消息也是一种事件消息)，降低参与者的复杂性。3、易维护扩展，在添加新步骤时，事务复杂性保持线性，回滚更容易管理，更容易实施和测试缺点1、中央协调器容易处理逻辑容易过于复杂，导致难以维护。2、存在协调器单点故障风险。事件/编排设计的优点和缺点优点1、避免中央协调器单点故障风险。2、当涉及的步骤较少服务开发简单，容易实现。缺点1、服务之间存在循环依赖的风险。2、当涉及的步骤较多，服务间关系混乱，难以追踪调测。值得补充的是，由于Saga模型中没有Prepare阶段，因此事务间不能保证隔离性，当多个Saga事务操作同一资源时，就会产生更新丢失、脏数据读取等问题，这时需要在业务层控制并发，例如：在应用层面加锁，或者应用层面预先冻结资源。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.baiyp.ren/tags/分布式事务/"},{"name":"Saga","slug":"Saga","permalink":"http://www.baiyp.ren/tags/Saga/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}]},{"title":"JAVA动态代理源码分析","slug":"JAVA动态代理源码分析","date":"2019-08-15T02:28:05.000Z","updated":"2019-08-22T02:07:51.270Z","comments":true,"path":"JAVA动态代理源码分析.html","link":"","permalink":"http://www.baiyp.ren/JAVA动态代理源码分析.html","excerpt":"","text":"JAVA动态代理源码分析动态代理简介​ Proxy模式是常用的设计模式，其特征是代理类与委托类有同样的接口，代理类主要负责为委托类预处理消息、过滤消息、把消息转发给委托类，以及事后处理消息等。用户可以更加结构图，自己编码完成Proxy模式。这种实现称为静态代理。​ Java提供了java.lang.reflect.Proxy类与InvocationHandler接口，配合反射，可以实现动态代理。静态代理的代理类与代理操作，都是事先编码，运行过程种无法修改代理结构。动态代理的代理与代理操作，都是在运行过程中，动态生成，可以在运行过程中，修改代理结构，符合面向对象的开闭原则。​ 最最最主要的原因就是，在不改变目标对象方法的情况下对方法进行增强，比如，我们希望对方法的调用增加日志记录，或者对方法的调用进行拦截，等等…​ 动态代理用于将在不需要修改原代码的情况下进行代码的增加，spring中的AOP，事务，都是使用动态代理来实现的，我们天天都在使用动态代理只是自己不知道而已。动态代理三大要素需要定义一个接口java动态代理类只能代理接口（不支持抽象类），如果没有接口就要使用cjlib需要一个实现类继承这个接口编写一个增强类实现 InvocationHandler接口代理类都需要实现InvocationHandler接口的invoke方法一个栗子先定义一个接口定义一个海外代购的接口123456/** * 海外代购 */public interface Buying &#123; public String buy();&#125;编写一个实现类实现类实现接口1234567public class BuyingImpl implements Buying &#123; @Override public String buy() &#123; System.out.println(\"开始逻辑处理\"); return \"买了个锤子\"; &#125;&#125;编写一个增将类编写一个增强类，主要要包裹一个需要需要增强的对象也就是我们的BuyingImpl，并实现InvocationHandler接口，在invoke方法中写增强实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 海外代购增强类 * 注意实现 InvocationHandler * 动态代理类只能代理接口（不支持抽象类），代理类都需要实现InvocationHandler类，实现invoke方法。 * 该invoke方法就是调用被代理接口的所有方法时需要调用的 。 */public class BuingHandler implements InvocationHandler &#123; /** * 包裹一个需要增强的目标对象 */ private Object targetObject; public BuingHandler(Object targetObject)&#123; this.targetObject = targetObject; &#125; /** * 获取代理类 * * @return */ public Object getProxy() &#123; /** * 该方法用于为指定类装载器、一组接口及调用处理器生成动态代理类实例 * 第一个参数指定产生代理对象的类加载器，需要将其指定为和目标对象同一个类加载器 * 第二个参数要实现和目标对象一样的接口，所以只需要拿到目标对象的实现接口 * 第三个参数表明这些被拦截的方法在被拦截时需要执行哪个InvocationHandler的invoke方法 * 根据传入的目标返回一个代理对象 */ return Proxy.newProxyInstance(targetObject.getClass().getClassLoader(), targetObject.getClass().getInterfaces(), this); &#125; /** * 关联的这个实现类的方法被调用时将被执行 * InvocationHandler接口的方法 * * @param proxy 表示代理对象 * @param method 示原对象被调用的方法 * @param args 表示方法的参数 * @return 返回的是对象的一个接口 * @throws Throwable */ @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; System.out.println(\"前置增强\"); //反射调用原始的需要增强的方法 Object value = method.invoke(targetObject, args); System.out.println(\"后置增强\"); return value; &#125;&#125;这里面要注意 method 是我们需要增强的方法，args 是我们需要增强的参数数组编写Main方法123456789public static void main(String[] args) &#123; //创建BuingHandler 类 BuingHandler buingHandler = new BuingHandler(new BuyingImpl()); //获取代理对象 Buying buying = (Buying) buingHandler.getProxy(); //调用具体接口 String value = buying.buy(); System.out.println(value); &#125;输出1234前置增强开始逻辑处理后置增强买了个锤子我们就这样实现了动态代理，我们没有修改原有代码的情况下做了增强我们实现了 其那只以及后置增强我们运行下看下接口对象我们看到实际对象是$Proxy0，我们发现动态代理给我们换了一个对象，我们要研究下他是怎么实现的源码实现读源码首先找到入口，没有不得入口就像无头的苍蝇，苍蝇还不叮无缝的蛋呢下面内容有点多，也有点绕，请跟着思路来一点点解析1、首先找到入口我们创建代理对象调用的是12Proxy.newProxyInstance(targetObject.getClass().getClassLoader(), targetObject.getClass().getInterfaces(), this);所以我们先从Proxy.newProxyInstance开始入手2、newProxyInstance方法进入newProxyInstance方法内部1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException &#123; //增强实现不能为空，为空就抛出异常 Objects.requireNonNull(h); //对接口数组进行clone final Class&lt;?&gt;[] intfs = interfaces.clone(); //进项权限检查 final SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; checkProxyAccess(Reflection.getCallerClass(), loader, intfs); &#125; /* * Look up or generate the designated proxy class. * ********核心代码入口*********** * 查找或者是生成一个特定的代理类对象 */ Class&lt;?&gt; cl = getProxyClass0(loader, intfs); /* * Invoke its constructor with the designated invocation handler. * 使用指定的调用处理程序调用其构造函数 */ try &#123; if (sm != null) &#123; checkNewProxyPermission(Reflection.getCallerClass(), cl); &#125; // 从代理类对象中查找参数为InvocationHandler的构造器 final Constructor&lt;?&gt; cons = cl.getConstructor(constructorParams); final InvocationHandler ih = h; // 检测构造器是否是Public修饰，如果不是则强行转换为可以访问的。 if (!Modifier.isPublic(cl.getModifiers())) &#123; AccessController.doPrivileged(new PrivilegedAction&lt;Void&gt;() &#123; public Void run() &#123; cons.setAccessible(true); return null; &#125; &#125;); &#125; //通过反射，将h作为参数，实例化代理类，返回代理类实例。 return cons.newInstance(new Object[]&#123;h&#125;); &#125; catch (IllegalAccessException | InstantiationException e) &#123; throw new InternalError(e.toString(), e); &#125; catch (InvocationTargetException e) &#123; Throwable t = e.getCause(); if (t instanceof RuntimeException) &#123; throw (RuntimeException) t; &#125; else &#123; throw new InternalError(t.toString(), t); &#125; &#125; catch (NoSuchMethodException e) &#123; throw new InternalError(e.toString(), e); &#125; &#125;上面代码的核心方法是1Class&lt;?&gt; cl = getProxyClass0(loader, intfs);找到了核心方法继续深入3、getProxyClass0方法入口生成一个代理对象的方法1234567891011121314151617181920/** * 生成一个代理对象 * Generate a proxy class. Must call the checkProxyAccess method * to perform permission checks before calling this. */ private static Class&lt;?&gt; getProxyClass0(ClassLoader loader, Class&lt;?&gt;... interfaces) &#123; //接口数量不能大于65535 否则报错 具体为什么 不太清楚 if (interfaces.length &gt; 65535) &#123; throw new IllegalArgumentException(\"interface limit exceeded\"); &#125; //根据类加载器生成代理字节码文件 // If the proxy class defined by the given loader implementing //如果接口存在缓存中们就从缓存中获取 // the given interfaces exists, this will simply return the cached copy; //否则，它将通过proxyClassFactory创建代理类 // otherwise, it will create the proxy class via the ProxyClassFactory return proxyClassCache.get(loader, interfaces); &#125;这一段代码是从缓存中获取代理对象，核心的代码还在里面 proxyClassCache.get(loader, interfaces);因为 proxyClassCache 是一个WeakCache 的类，所以我们先来学习下WeakCache4、WeakCache类WeakCache 方法声明在这个方法中，是直接从一个叫proxyClassCache缓存中读取的，来看一下这个缓存的声明：123456/** * a cache of proxy classes * 缓存代理的class字节码文件，如果没有则使用ProxyClassFactory创建 */ private static final WeakCache&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt; proxyClassCache = new WeakCache&lt;&gt;(new KeyFactory(), new ProxyClassFactory());里涉及到三个类：WeakCache,KeyFactory,ProxyClassFactory，其中后面两个类都是Proxy类的静态内部类，从类名可以大概猜测到，keyFactory是用来生产key的，ProxyClassFactory是用来生产代理类对象的，这个稍后会提到。WeakCache类的大概结构12345678910111213141516171819202122final class WeakCache&lt;K, P, V&gt; &#123; private final ReferenceQueue&lt;K&gt; refQueue = new ReferenceQueue&lt;&gt;(); // the key type is Object for supporting null key // key的类型为Object，支持null key,这里的null key并不是真的可以使用null最为key,而是一个new Objdec()对象实例。ConcurrentHashMap,不允许键或值null，而HashMap可以。ConcurrentHashMap是线程安全的，HashMap不是。 private final ConcurrentMap&lt;Object, ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt;&gt; map = new ConcurrentHashMap&lt;&gt;(); private final ConcurrentMap&lt;Supplier&lt;V&gt;, Boolean&gt; reverseMap = new ConcurrentHashMap&lt;&gt;(); private final BiFunction&lt;K, P, ?&gt; subKeyFactory; private final BiFunction&lt;K, P, V&gt; valueFactory; // 构造方法 public WeakCache(BiFunction&lt;K, P, ?&gt; subKeyFactory, BiFunction&lt;K, P, V&gt; valueFactory) &#123; this.subKeyFactory = Objects.requireNonNull(subKeyFactory); this.valueFactory = Objects.requireNonNull(valueFactory); &#125; //核心入口方法 我们接下来介绍这个类 public V get(K key, P parameter) &#123; &#125; ...上面的源代码中写明，代理对象的核心方法是get , 我们结合上下文 发现 key是loader 类加载器，parameter是接口数组interfaces5、proxyClassCache.get这个对象是从缓存中获取字节码对象，key是接口，value是对象的字节码文件，如果给定的接口存在则返回字节码文件，如果不存在则调用proxyClassFactory创建代理类进行创建123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384/** * return proxyClassCache.get(loader, interfaces); * &lt;p&gt; * 获取代理对象的核心方法 * * @param key 类加载器 loader * @param parameter 接口的数组 interfaces * @return */ public V get(K key, P parameter) &#123; //接口数组不能为空，否则抛出异常 Objects.requireNonNull(parameter); // 删除过时的条目 expungeStaleEntries(); // 生成缓存key对象实例，如果key = null，cacheKey = new Object(); Object cacheKey = WeakCache.CacheKey.valueOf(key, refQueue); // lazily install the 2nd level valuesMap for the particular cacheKey // 从缓存map中读取指定cacheKey的缓存数据valuesMap ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap = map.get(cacheKey); if (valuesMap == null) &#123; //如果valuesMap为null,则新增 // putIfAbsent方法解释：如果值存在则返回值，并且不对原来的值做任何更改，如果不存在则新增，并返回null //map.putIfAbsent 是map中新增的一个方法 存在则返回，不存在put然后在返回 ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; oldValuesMap = map.putIfAbsent(cacheKey, valuesMap = new ConcurrentHashMap&lt;&gt;()); //赋值 if (oldValuesMap != null) &#123; valuesMap = oldValuesMap; &#125; &#125; // create subKey and retrieve the possible Supplier&lt;V&gt; stored by that // subKey from valuesMap //获取subKey，这里用到了上面提到的Proxy的静态内部类 KeyFactory:subKeyFactory.apply(ket,parameter) Object subKey = Objects.requireNonNull(subKeyFactory.apply(key, parameter)); // 从valuesMap中获取supplier Supplier&lt;V&gt; supplier = valuesMap.get(subKey); WeakCache.Factory factory = null; while (true) &#123; if (supplier != null) &#123; // supplier might be a Factory or a CacheValue&lt;V&gt; instance // 4、从工厂中获取代理类对象 V value = supplier.get(); if (value != null) &#123; //5、返回 return value; &#125; &#125; // else no supplier in cache // or a supplier that returned null (could be a cleared CacheValue // or a Factory that wasn't successful in installing the CacheValue) // lazily construct a Factory //1、实例化工厂 if (factory == null) &#123; factory = new WeakCache.Factory(key, parameter, subKey, valuesMap); &#125; if (supplier == null) &#123; //2、将supplier保存到valuesMap中 supplier = valuesMap.putIfAbsent(subKey, factory); if (supplier == null) &#123; // successfully installed Factory // 3、赋值 supplier = factory; &#125; // else retry with winning supplier &#125; else &#123; //如果subKey和supplier都匹配则则将supplier替换为新生成的factory if (valuesMap.replace(subKey, supplier, factory)) &#123; // successfully replaced // cleared CacheEntry / unsuccessful Factory // with our Factory //替换成功赋值 supplier = factory; &#125; else &#123; // retry with current supplier //使用当前的supplier进行重试 supplier = valuesMap.get(subKey); &#125; &#125; &#125; &#125;因为程序中Proxy.newProxyInstance是第一次执行，所以while循环开始的时候，supplier，valuesMap都是null。在这个前提下，我为代码的执行顺序做了一个编号，从1-5执行。可以看到第5步，也就是源代码的第47行将结果返回，那么，代理类对象就是在第4步，也就是第43行生成的。而且也可以从第3步，也就是第65行发现supplier就是factory。那么接下来，就分析一下Factory.get方法。6、Factory.get方法Factory类是WeakCache的内部类。这个类中除去构造方法外，就是get方法了，下面是这个代码的实现：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475 /** * Factory 实现类Supplier 接口 */ private final class Factory implements Supplier&lt;V&gt; &#123;//类加载器 loader private final K key; 接口的数组 interfaces private final P parameter; //这里的subkey 就是上面的 KeyFactory 可以会看 WeakCache 方法声明 private final Object subKey; //提供者的MAP key是KeyFactory ，value 是 Factory 本身 private final ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap; //构造方法 Factory(K key, P parameter, Object subKey, ConcurrentMap&lt;Object, Supplier&lt;V&gt;&gt; valuesMap) &#123; this.key = key; this.parameter = parameter; this.subKey = subKey; this.valuesMap = valuesMap; &#125; @Override public synchronized V get() &#123; // serialize access // re-check //检查 如果 supplier不是自己 返回 Supplier&lt;V&gt; supplier = valuesMap.get(subKey); if (supplier != this) &#123; // something changed while we were waiting: // might be that we were replaced by a CacheValue // or were removed because of failure -&gt; // return null to signal WeakCache.get() to retry // the loop return null; &#125; // else still us (supplier == this) // create new value //定义一个新的对象 V value = null; try &#123; /** * valueFactory就是WeakCache的valueFactory属性，因为Factory是WeakCache的内部类，所以可以直接访问WeakCache的valueFactory属性 * 我们可以回去看看第四第五 proxyClassCache.get 以及 WeakCache 的简单结构 注意valueFactory 发现就是 ProxyClassFactory * 就在这一步生成了 代理对象 */ value = Objects.requireNonNull(valueFactory.apply(key, parameter)); &#125; finally &#123; if (value == null) &#123; // remove us on failure valuesMap.remove(subKey, this); &#125; &#125; // the only path to reach here is with non-null value //校验对象不为空 assert value != null; // wrap value with CacheValue (WeakReference) WeakCache.CacheValue&lt;V&gt; cacheValue = new WeakCache.CacheValue&lt;&gt;(value); // put into reverseMap //缓存代理对象 reverseMap.put(cacheValue, Boolean.TRUE); // try replacing us with CacheValue (this should always succeed) //并将valuesMap替换为最新生成的对象 if (!valuesMap.replace(subKey, this, cacheValue)) &#123; throw new AssertionError(\"Should not reach here\"); &#125; // successfully replaced us with new CacheValue -&gt; return the value // wrapped by it //返回对象 return value; &#125; &#125;我们核心注意的是1value = Objects.requireNonNull(valueFactory.apply(key, parameter));这里的valueFactory就是Proxy的静态内部类ProxyClassFactory，上面也提到过，那么就接着分析ProxyClassFactory的apply方法吧。7、ProxyClassFactory.apply方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128/** * 一个利用给定的类加载器和接口类数组生成，定义并返回代理类对象的工厂方法 * A factory function that generates, defines and returns the proxy class given * the ClassLoader and array of interfaces. */private static final class ProxyClassFactory implements BiFunction&lt;ClassLoader, Class&lt;?&gt;[], Class&lt;?&gt;&gt;&#123; // prefix for all proxy class names //所有代理类对象的前缀 这个就回答了为什么代理类都带有$Proxy private static final String proxyClassNamePrefix = \"$Proxy\"; // next number to use for generation of unique proxy class names //用于生成唯一代理类名称的下一个数字 private static final AtomicLong nextUniqueNumber = new AtomicLong(); /** * 开始我们的核心方法apply * @param loader 类加载器 * @param interfaces 接口数组 * @return */ @Override public Class&lt;?&gt; apply(ClassLoader loader, Class&lt;?&gt;[] interfaces) &#123; Map&lt;Class&lt;?&gt;, Boolean&gt; interfaceSet = new IdentityHashMap&lt;&gt;(interfaces.length); //接口校验循环 for (Class&lt;?&gt; intf : interfaces) &#123; /* * Verify that the class loader resolves the name of this * interface to the same Class object. */ Class&lt;?&gt; interfaceClass = null; try &#123; //加载接口类，获得接口类的类对象，第二个参数为false表示不进行实例化 interfaceClass = Class.forName(intf.getName(), false, loader); &#125; catch (ClassNotFoundException e) &#123; &#125; //进行校验 if (interfaceClass != intf) &#123; throw new IllegalArgumentException( intf + \" is not visible from class loader\"); &#125; /* * Verify that the Class object actually represents an * interface. * 验证是否是接口 不是接口报错 */ if (!interfaceClass.isInterface()) &#123; throw new IllegalArgumentException( interfaceClass.getName() + \" is not an interface\"); &#125; /* * Verify that this interface is not a duplicate. * 验证此接口不是重复的，重复的就报错 */ if (interfaceSet.put(interfaceClass, Boolean.TRUE) != null) &#123; throw new IllegalArgumentException( \"repeated interface: \" + interfaceClass.getName()); &#125; &#125; //代理类的包名 String proxyPkg = null; // package to define proxy class in //访问权限 int accessFlags = Modifier.PUBLIC | Modifier.FINAL; /* * Record the package of a non-public proxy interface so that the * proxy class will be defined in the same package. Verify that * all non-public proxy interfaces are in the same package. */ for (Class&lt;?&gt; intf : interfaces) &#123; int flags = intf.getModifiers(); //如果接口是public就跳过 我们的接口基本上不会走这里 if (!Modifier.isPublic(flags)) &#123; accessFlags = Modifier.FINAL; String name = intf.getName(); int n = name.lastIndexOf('.'); String pkg = ((n == -1) ? \"\" : name.substring(0, n + 1)); if (proxyPkg == null) &#123; proxyPkg = pkg; &#125; else if (!pkg.equals(proxyPkg)) &#123; throw new IllegalArgumentException( \"non-public interfaces from different packages\"); &#125; &#125; &#125; if (proxyPkg == null) &#123; // if no non-public proxy interfaces, use com.sun.proxy package //如果没有public的接口 就是用 com.sun.proxy 的包前缀 //类似于com.sun.proxy.$Proxy0 proxyPkg = ReflectUtil.PROXY_PACKAGE + \".\"; &#125; /* * Choose a name for the proxy class to generate. * 生成代理类的类名 */ //生成代理类的序号 long num = nextUniqueNumber.getAndIncrement(); //生成代理类的完全限定名 String proxyName = proxyPkg + proxyClassNamePrefix + num; /* * Generate the specified proxy class. * 生成代理类class文件 * 这个是生成的核心方法 */ byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags); try &#123; //返回代理类对象 return defineClass0(loader, proxyName, proxyClassFile, 0, proxyClassFile.length); &#125; catch (ClassFormatError e) &#123; /* * A ClassFormatError here means that (barring bugs in the * proxy class generation code) there was some other * invalid aspect of the arguments supplied to the proxy * class creation (such as virtual machine limitations * exceeded). */ throw new IllegalArgumentException(e.toString()); &#125; &#125;&#125;在代码的第111行，生成了代理类的class文件，并且在115行返回了我们需要的代理类对象。那么怎么找到这个生成的代理类class文件呢？到这里 我们就跟完了动态代理的核心流程，我们解释了为什么 代理类都带有$Proxy，以及后面的序号是怎么来的。生成代码的核心代码是12byte[] proxyClassFile = ProxyGenerator.generateProxyClass( proxyName, interfaces, accessFlags);ProxyGenerator是根据代理名称接口生成代理类的核心代码，我们就不跟进去了，以后有时间再进去，里面都是字节码操作的知识了，也是在sun.misc包下，一般是不开源的，如果需要可以去下载sun包的源码，1.8之后就不开源了。查看生成的代理类我们上面最终跟到了ProxyGenerator类，ProxyGenerator是生成字节码文件的核心代码，我们想看下生成的字节码怎么办呢，我们自己去生成并且输出出来。看代码1234567//生成代理字节码数组文件 传入一个接口数组byte[] proxyClassFile = ProxyGenerator.generateProxyClass(\"com.sun.proxy\", new Class[]&#123;Buying.class&#125;, 1);//将字节数组转换成class文件并输出到本地 FileOutputStream fos = new FileOutputStream(new File(\"d:/com.sun.proxy.class\")); fos.write(proxyClassFile); fos.flush(); fos.close();我们反编译以下 com.sun.proxy.class12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485//继承了Proxy类，实现了Buying接口public class proxy extends Proxy implements Buying &#123; private static Method m1; private static Method m2; private static Method m3; private static Method m0; //构造方法，直接调用了父类，也就是Proxy的构造方法，参数paramInvocationHandler就是我们的BuingHandler实例化对象handler public proxy(InvocationHandler paramInvocationHandler) &#123; super(paramInvocationHandler); &#125; /** * 实现equals 方法 * @param var1 * @return */ public final boolean equals(Object var1) &#123; try &#123; return (Boolean)super.h.invoke(this, m1, new Object[]&#123;var1&#125;); &#125; catch (RuntimeException | Error var3) &#123; throw var3; &#125; catch (Throwable var4) &#123; throw new UndeclaredThrowableException(var4); &#125; &#125; /** * 实现toString方法 * @return */ public final String toString() &#123; try &#123; return (String)super.h.invoke(this, m2, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; //实现了Buying 接口的 buy public final String buy() &#123; try &#123; /** * 这里的h就是我们的BuingHandler 实例 * 调用 父类 Proxy 里面我们传入的 BuingHandler 对象 */ return (String)super.h.invoke(this, m3, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; /** * 实现了hashCode方法 * @return */ public final int hashCode() &#123; try &#123; return (Integer)super.h.invoke(this, m0, (Object[])null); &#125; catch (RuntimeException | Error var2) &#123; throw var2; &#125; catch (Throwable var3) &#123; throw new UndeclaredThrowableException(var3); &#125; &#125; //静态代码块，做初始化操作 static &#123; try &#123; //通过反射，获取Object对象方法对象的equals 方法 m1 = Class.forName(\"java.lang.Object\").getMethod(\"equals\", Class.forName(\"java.lang.Object\")); //通过反射，获取Object对象方法对象的toString 方法 m2 = Class.forName(\"java.lang.Object\").getMethod(\"toString\"); //通过反射，获取Buying对象方法对象的buy 方法 m3 = Class.forName(\"com.test.proxy.Buying\").getMethod(\"buy\"); //通过反射，获取Object对象方法对象的hashCode 方法 m0 = Class.forName(\"java.lang.Object\").getMethod(\"hashCode\"); &#125; catch (NoSuchMethodException var2) &#123; throw new NoSuchMethodError(var2.getMessage()); &#125; catch (ClassNotFoundException var3) &#123; throw new NoClassDefFoundError(var3.getMessage()); &#125; &#125;&#125;代理类实例化的代码是：cons.newInstance(new Object[]{h})。这里是通过反射调用代理类对象的构造方法，传入了参数h（我们的BuingHandler实例化对象handler）。​ 这个构造方法，就是上述反编译代码里的构造方法，而上述反编译代码里的构造方法调用了Proxy类的构造方法，来看一下Proxy类的构造方法：1234567protected InvocationHandler h;protected Proxy(InvocationHandler h) &#123; Objects.requireNonNull(h); this.h = h;&#125;​ 这里将我们传入的handler直接赋值给了InvocationHandler h。上述反编译代码中的super.h 就是我们传入的handler。所以proxy.buy();方法在执行的时候会去调用BuingHandler类的invoke方法。好了到这里我们的源码解析已经完了。","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"动态代理","slug":"源码/动态代理","permalink":"http://www.baiyp.ren/categories/源码/动态代理/"}],"tags":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"},{"name":"动态代理","slug":"动态代理","permalink":"http://www.baiyp.ren/tags/动态代理/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"动态代理","slug":"源码/动态代理","permalink":"http://www.baiyp.ren/categories/源码/动态代理/"}]},{"title":"java中AQS-03源代码实现","slug":"java中的AQS-03","date":"2019-08-11T09:47:16.000Z","updated":"2019-08-22T02:06:15.698Z","comments":true,"path":"java中的AQS-03.html","link":"","permalink":"http://www.baiyp.ren/java中的AQS-03.html","excerpt":"","text":"java中AQS的源代码实现AQS的源代码实现主要通过独占式同步状态的获取和释放、共享式同步状态的获取和释放来看下AQS是如何实现的。独占式同步状态的获取和释放独占式同步状态调用的方法是acquire，代码如下：12345public final void acquire(long arg) &#123; if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt(); &#125;​ 上述代码主要完成了同步状态获取、节点构造、加入同步队列以及在同步队列中自旋等待的相关工作，其主要逻辑是：首先调用子类实现的tryAcquire方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，则构造独占式同步节点（同一时刻只能有一个线程成功获取同步状态）并通过addWaiter方法将该节点加入到同步队列的尾部，最后调用acquireQueued方法，使得该节点以自旋的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞线程的唤醒主要依靠前驱节点的出队或阻塞线程被中断来实现。下面来首先来看下节点构造和加入同步队列是如何实现的。代码如下：12345678910111213141516171819202122232425262728293031323334353637private Node addWaiter(Node mode) &#123; // 当前线程构造成Node节点 Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure // 尝试快速在尾节点后新增节点 提升算法效率 先将尾节点指向pred Node pred = tail; if (pred != null) &#123; //尾节点不为空 当前线程节点的前驱节点指向尾节点 node.prev = pred; //并发处理 尾节点有可能已经不是之前的节点 所以需要CAS更新 if (compareAndSetTail(pred, node)) &#123; //CAS更新成功 当前线程为尾节点 原先尾节点的后续节点就是当前节点 pred.next = node; return node; &#125; &#125; //第一个入队的节点或者是尾节点后续节点新增失败时进入enq enq(node); return node; &#125;private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize //尾节点为空 第一次入队 设置头尾节点一致 同步队列的初始化 if (compareAndSetHead(new Node())) tail = head; &#125; else &#123; //所有的线程节点在构造完成第一个节点后 依次加入到同步队列中 node.prev = t; if (compareAndSetTail(t, node)) &#123; t.next = node; return t; &#125; &#125; &#125; &#125;​ 节点进入同步队列之后，就进入了一个自旋的过程，每个线程节点都在自省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这个自旋过程中并会阻塞节点的线程，代码如下：12345678910111213141516171819202122232425final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //获取当前线程节点的前驱节点 final Node p = node.predecessor(); //前驱节点为头节点且成功获取同步状态 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //设置当前节点为头节点 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //是否阻塞 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;再来看看shouldParkAfterFailedAcquire和parkAndCheckInterrupt是怎么来阻塞当前线程的，代码如下：123456789101112131415161718192021222324252627282930313233private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; //前驱节点的状态决定后续节点的行为 int ws = pred.waitStatus; if (ws == Node.SIGNAL) /*前驱节点为-1 后续节点可以被阻塞 * This node has already set status asking a release * to signal it, so it can safely park. */ return true; if (ws &gt; 0) &#123; /* * Predecessor was cancelled. Skip over predecessors and * indicate retry. */ do &#123; node.prev = pred = pred.prev; &#125; while (pred.waitStatus &gt; 0); pred.next = node; &#125; else &#123; /*前驱节点是初始或者共享状态就设置为-1 使后续节点阻塞 * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); &#125; return false; &#125;private final boolean parkAndCheckInterrupt() &#123; //阻塞线程 LockSupport.park(this); return Thread.interrupted(); &#125;节点自旋的过程大致示意图如下，其实就是对图二、图三的补充。整个独占式获取同步状态的流程图大致如下：​ 当同步状态获取成功之后，当前线程从acquire方法返回，对于锁这种并发组件而言，就意味着当前线程获取了锁。有获取同步状态的方法，就存在其对应的释放方法，该方法为release，现在来看下这个方法的实现，代码如下：12345678910111213141516171819202122232425262728293031323334353637public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123;//同步状态释放成功 Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) //直接释放头节点 unparkSuccessor(h); return true; &#125; return false; &#125;private void unparkSuccessor(Node node) &#123; /* * If status is negative (i.e., possibly needing signal) try * to clear in anticipation of signalling. It is OK if this * fails or if status is changed by waiting thread. */ int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); /*寻找符合条件的后续节点 * Thread to unpark is held in successor, which is normally * just the next node. But if cancelled or apparently null, * traverse backwards from tail to find the actual * non-cancelled successor. */ Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) //唤醒后续节点 LockSupport.unpark(s.thread); &#125;​ 独占式释放是非常简单而且明确的。总结下独占式同步状态的获取和释放：在获取同步状态时，同步器维护一个同步队列，获取状态失败的线程都会被加入到队列中并在队列中进行自旋；移出队列的条件是前驱节点为头节点且成功获取了同步状态。在释放同步状态时，同步器调用tryRelease方法释放同步状态，然后唤醒头节点的后继节点。共享式同步状态的获取和释放共享式同步状态调用的方法是acquireShared，代码如下：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public final void acquireShared(int arg) &#123; //获取同步状态的返回值大于等于0时表示可以获取同步状态 //小于0时表示可以获取不到同步状态 需要进入队列等待 if (tryAcquireShared(arg) &lt; 0) doAcquireShared(arg); &#125;private void doAcquireShared(int arg) &#123; //和独占式一样的入队操作 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; boolean interrupted = false; //自旋 for (;;) &#123; final Node p = node.predecessor(); if (p == head) &#123; int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //前驱结点为头节点且成功获取同步状态 可退出自旋 setHeadAndPropagate(node, r); p.next = null; // help GC if (interrupted) selfInterrupt(); failed = false; return; &#125; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125; &#125;private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below //退出自旋的节点变成首节点 setHead(node); /* * Try to signal next queued node if: * Propagation was indicated by caller, * or was recorded (as h.waitStatus either before * or after setHead) by a previous operation * (note: this uses sign-check of waitStatus because * PROPAGATE status may transition to SIGNAL.) * and * The next node is waiting in shared mode, * or we don't know, because it appears null * * The conservatism in both of these checks may cause * unnecessary wake-ups, but only when there are multiple * racing acquires/releases, so most need signals now or soon * anyway. */ if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125; &#125;与独占式一样，共享式获取也需要释放同步状态，通过调用releaseShared方法可以释放同步状态，代码如下：1234567891011121314151617181920212223242526272829public final boolean releaseShared(int arg) &#123; //释放同步状态 if (tryReleaseShared(arg)) &#123; //唤醒后续等待的节点 doReleaseShared(); return true; &#125; return false; &#125;private void doReleaseShared() &#123; //自旋 for (;;) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases //唤醒后续节点 unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125; &#125;unparkSuccessor方法和独占式是一样的。","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"并发","slug":"源码/并发","permalink":"http://www.baiyp.ren/categories/源码/并发/"},{"name":"高级","slug":"源码/并发/高级","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/"},{"name":"AQS","slug":"源码/并发/高级/AQS","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/AQS/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"高级","slug":"高级","permalink":"http://www.baiyp.ren/tags/高级/"},{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"},{"name":"AQS","slug":"AQS","permalink":"http://www.baiyp.ren/tags/AQS/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"并发","slug":"源码/并发","permalink":"http://www.baiyp.ren/categories/源码/并发/"},{"name":"高级","slug":"源码/并发/高级","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/"},{"name":"AQS","slug":"源码/并发/高级/AQS","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/AQS/"}]},{"title":"CLH队列锁的原理","slug":"CLH队列锁","date":"2019-08-11T09:24:14.000Z","updated":"2019-08-22T02:04:44.403Z","comments":true,"path":"CLH队列锁.html","link":"","permalink":"http://www.baiyp.ren/CLH队列锁.html","excerpt":"","text":"CLH队列锁的原理什么是CLH队列锁​ CLH锁是有由Craig, Landin, and Hagersten这三个人发明的锁，取了三个人名字的首字母，所以叫 CLH Lock。​ CLH锁是一个自旋锁。能确保无饥饿性。提供先来先服务的公平性。​ CLH队列锁也是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程仅仅在本地变量上自旋，它不断轮询前驱的状态，假设发现前驱释放了锁就结束自旋。就像这样当一个线程需要获取锁时创建一个的QNode，将其中的locked设置为true表示需要获取锁，myPred表示对其前驱结点的引用线程A对tail域调用getAndSet方法，使自己成为队列的尾部，同时获取一个指向其前驱结点的引用myPred线程B需要获得锁，同样的流程再来一遍线程就在前驱结点的locked字段上旋转，直到前驱结点释放锁(前驱节点的锁值 locked ==false)当一个线程需要释放锁时，将当前结点的locked域设置为false，同时回收前驱结点如上图所示，前驱结点释放锁，线程A的myPred所指向的前驱结点的locked字段变为false，线程A就可以获取到锁。CLH队列锁的优点是空间复杂度低（如果有n个线程，L个锁，每个线程每次只获取一个锁，那么需要的存储空间是O（L+n），n个线程有n个myNode，L个锁有L个tail）。CLH队列锁常用在SMP体系结构下。Java中的AQS是CLH队列锁的一种变体实现。扩展知识SMP(Symmetric Multi-Processor)​ 对称多处理器结构，指服务器中多个CPU对称工作，每个CPU访问内存地址所需时间相同。其主要特征是共享，包含对CPU，内存，I/O等进行共享。​ SMP能够保证内存一致性，但这些共享的资源很可能成为性能瓶颈，随着CPU数量的增加，每个CPU都要访问相同的内存资源，可能导致内存访问冲突，​ 可能会导致CPU资源的浪费。常用的PC机就属于这种。NUMA(Non-Uniform Memory Access)​ 非一致存储访问，将CPU分为CPU模块，每个CPU模块由多个CPU组成，并且具有独立的本地内存、I/O槽口等，模块之间可以通过互联模块相互访问，​ 访问本地内存的速度将远远高于访问远地内存(系统内其它节点的内存)的速度，这也是非一致存储访问的由来。NUMA较好地解决SMP的扩展问题，当CPU数量增加时，因为访问远地内存的延时远远超过本地内存，系统性能无法线性增加。CLH 的缺点CLH唯一的缺点是在NUMA系统结构下性能很差，但是在SMP系统结构下该法还是非常有效的。解决NUMA系统结构的思路是MCS队列锁","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"高级","slug":"并发/高级","permalink":"http://www.baiyp.ren/categories/并发/高级/"},{"name":"队列锁","slug":"并发/高级/队列锁","permalink":"http://www.baiyp.ren/categories/并发/高级/队列锁/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"高级","slug":"高级","permalink":"http://www.baiyp.ren/tags/高级/"},{"name":"队列锁","slug":"队列锁","permalink":"http://www.baiyp.ren/tags/队列锁/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"高级","slug":"并发/高级","permalink":"http://www.baiyp.ren/categories/并发/高级/"},{"name":"队列锁","slug":"并发/高级/队列锁","permalink":"http://www.baiyp.ren/categories/并发/高级/队列锁/"}]},{"title":"java中的读写锁","slug":"java中的读写锁","date":"2019-08-11T08:35:32.000Z","updated":"2019-08-22T02:06:51.109Z","comments":true,"path":"java中的读写锁.html","link":"","permalink":"http://www.baiyp.ren/java中的读写锁.html","excerpt":"","text":"java中的读写锁ReentrantReadWriteLock 读写锁​ 之前提到锁（如Mutex和ReentrantLock）基本都是排他锁，这些锁在同一时刻只允许一个线程进行访问，而读写锁在同一时刻可以允许多个读线程访问，但是在写线程访问时，所有的读线程和其他写线程均被阻塞。读写锁维护了一对锁，一个读锁和一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有了很大提升。​ 除了保证写操作对读操作的可见性以及并发性的提升之外，读写锁能够简化读写交互场景的编程方式。假设在程序中定义一个共享的用作缓存数据结构，它大部分时间提供读服务（例如查询和搜索），而写操作占有的时间很少，但是写操作完成之后的更新需要对后续的读服务可见。在没有读写锁支持的（Java 5之前）时候，如果需要完成上述工作就要使用Java的等待通知机制，就是当写操作开始时，所有晚于写操作的读操作均会进入等待状态，只有写操作完成并进行通知之后，所有等待的读操作才能继续执行（写操作之间依靠synchronized关键进行同步），这样做的目的是使读操作能读取到正确的数据，不会出现脏读。改用读写锁实现上述功能，只需要在读操作时获取读锁，写操作时获取写锁即可。当写锁被获取到时，后续（非当前写操作线程）的读写操作都会被阻塞，写锁释放之后，所有操作继续执行，编程方式相对于使用等待通知机制的实现方式而言，变得简单明了。一般情况下，读写锁的性能都会比排它锁好，因为大多数场景读是多于写的。在读多于写的情况下，读写锁能够提供比排它锁更好的并发性和吞吐量ReentrantReadWriteLock其实实现的是ReadWriteLock接口ReadWriteLock接口123456public interface ReadWriteLock &#123; //获取读锁 Lock readLock(); //获取写锁 Lock writeLock();&#125;ReentrantReadWriteLock类构造方法12345//创建一个ReentrantReadWriteLock实例.ReentrantReadWriteLock() //创建一个具有给定公平策略的ReentrantReadWriteLock实例.ReentrantReadWriteLock(boolean fair)常用方法摘要1234567891011121314//返回用于读取操作的锁.Lock ReentrantReadWriteLock.ReadLock.readLock() //返回用于写入操作的锁.Lock ReentrantReadWriteLock.WriteLock.writeLock()//返回等待获取读取或写入锁的线程估计数目.int getQueueLength()//如果此锁的公平设置为 true,则返回 true.boolean isFair()//返回标识此锁及其锁状态的字符串.String toString()ReadLock/WriteLock静态内部类1234567891011121314151617181920//试图获取锁.void lock() //如果当前线程未被中断,则获取锁.void lockInterruptibly() //返回绑定到此 Lock 实例的新 Condition 实例.Condition newCondition() //仅在调用时锁为空闲状态才获取该锁.boolean tryLock() //如果锁在给定的等待时间内空闲,并且当前线程未被中断,则获取锁.boolean tryLock(long time， TimeUnit unit) //试图释放锁.void unlock()//返回标识此锁及其锁状态的字符串.String toString()因为ReadLock不支持条件，因此当调用了ReadLock的newCondition()方法时将会抛出UnsupportedOperationException异常。使用ReentrantReadWriteLock的读锁以及写锁，将会遵循读读共享、写写互斥、读写互斥。使用示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class ReentrantReadWriteLockTest &#123; /** * 创建线程池 */ private static ExecutorService executorService = Executors.newCachedThreadPool(); /** * 创建读写锁 */ private static ReadWriteLock lock = new ReentrantReadWriteLock(); /** * 读锁 */ private static Lock readLock = lock.readLock(); /** * 获取写锁 */ private static Lock writeLock = lock.writeLock(); /** * 读操作 */ public static void reading() &#123; System.out.println(\"尝试获取读锁：\" + Thread.currentThread().getId()); readLock.lock(); System.out.println(\"获取读锁成功：\" + Thread.currentThread().getId()); try &#123; System.out.println(\"开始进行读操作：\" + Thread.currentThread().getId()); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\"释放读锁成功：\" + Thread.currentThread().getId()); readLock.unlock(); &#125; &#125; /** * 读操作 */ public static void writing() &#123; System.out.println(\"尝试获取写锁：\" + Thread.currentThread().getId()); writeLock.lock(); System.out.println(\"获取写锁成功：\" + Thread.currentThread().getId()); try &#123; System.out.println(\"开始进行写操作：\" + Thread.currentThread().getId()); &#125; finally &#123; System.out.println(\"释放写锁成功：\" + Thread.currentThread().getId()); writeLock.unlock(); &#125; &#125;&#125;读读共享1234567public static void main(String[] args) &#123; //读读共享 for (int i = 0; i &lt; 3; i++) &#123; executorService.submit(() -&gt; reading()); &#125; executorService.shutdown(); &#125;输出123456789101112尝试获取读锁：12尝试获取读锁：14尝试获取读锁：13获取读锁成功：14开始进行读操作：14获取读锁成功：12开始进行读操作：12获取读锁成功：13开始进行读操作：13释放读锁成功：12释放读锁成功：14释放读锁成功：13读锁能被多个线程同时获取，能提高读取的效率 (虽然只用读锁时可以不进行释放，但会影响写锁的获取)写写互斥1234567public static void main(String[] args) &#123; //读读共享 for (int i = 0; i &lt; 3; i++) &#123; executorService.submit(() -&gt; writing()); &#125; executorService.shutdown(); &#125;输出123456789101112尝试获取写锁：12尝试获取写锁：13尝试获取写锁：14获取写锁成功：12开始进行写操作：12释放写锁成功：12获取写锁成功：13开始进行写操作：13释放写锁成功：13获取写锁成功：14开始进行写操作：14释放写锁成功：14写锁同一时刻只能被一个线程获取。读写互斥123456789101112 public static void main(String[] args) &#123; //读写互斥 for (int i = 0; i &lt; 3; i++) &#123; executorService.submit(() -&gt; &#123; reading(); &#125;); executorService.submit(() -&gt; &#123; writing(); &#125;); &#125; executorService.shutdown();&#125;输出123456789101112131415161718192021222324尝试获取读锁：12获取读锁成功：12开始进行读操作：12尝试获取写锁：13尝试获取读锁：14尝试获取写锁：15尝试获取读锁：16尝试获取写锁：17释放读锁成功：12获取写锁成功：13开始进行写操作：13释放写锁成功：13获取读锁成功：14开始进行读操作：14释放读锁成功：14获取写锁成功：15开始进行写操作：15释放写锁成功：15获取读锁成功：16开始进行读操作：16释放读锁成功：16获取写锁成功：17开始进行写操作：17释放写锁成功：17​ 读的时候不能写，写的时候不能读，即获取读锁时如果写锁此时被线程持有则将等待写锁被释放，获取写锁时如果读锁此时有被线程持有则将等待读锁被释放且写锁未被持有。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"高级","slug":"并发/高级","permalink":"http://www.baiyp.ren/categories/并发/高级/"},{"name":"读写锁","slug":"并发/高级/读写锁","permalink":"http://www.baiyp.ren/categories/并发/高级/读写锁/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"高级","slug":"高级","permalink":"http://www.baiyp.ren/tags/高级/"},{"name":"读写锁","slug":"读写锁","permalink":"http://www.baiyp.ren/tags/读写锁/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"高级","slug":"并发/高级","permalink":"http://www.baiyp.ren/categories/并发/高级/"},{"name":"读写锁","slug":"并发/高级/读写锁","permalink":"http://www.baiyp.ren/categories/并发/高级/读写锁/"}]},{"title":"java中AQS-02方法结构","slug":"java中的AQS-02","date":"2019-08-10T09:47:16.000Z","updated":"2019-08-22T02:06:07.777Z","comments":true,"path":"java中的AQS-02.html","link":"","permalink":"http://www.baiyp.ren/java中的AQS-02.html","excerpt":"","text":"java中AQS的方法结构AQS的方法结构如果我们理解了上一节的设计思路，我们大致就能知道AQS的主要数据结构了。组件数据结构同步状态volatile int state阻塞LockSupport类队列Node节点条件队列ConditionObject进而再来看下AQS的主要方法及其作用。属性、方法描述、作用int getState()获取当前同步状态void setState(int newState)设置当前同步状态boolean compareAndSetState(int expect, int update)通过CAS设置当前状态，此方法保证状态设置的原子性boolean tryAcquire(int arg)钩子方法，独占式获取同步状态，AQS没有具体实现，具体实现都在子类中，实现此方法需要查询当前同步状态并判断同步状态是否符合预期，然后再CAS设置同步状态boolean tryRelease(int arg)钩子方法，独占式释放同步状态，AQS没有具体实现，具体实现都在子类中，等待获取同步状态的线程将有机会获取同步状态int tryAcquireShared(int arg)钩子方法，共享式获取同步状态，AQS没有具体实现，具体实现都在子类中，返回大于等于0的值表示获取成功，反之失败boolean tryReleaseShared(int arg)钩子方法，共享式释放同步状态，AQS没有具体实现，具体实现都在子类中boolean isHeldExclusively()钩子方法，AQS没有具体实现，具体实现都在子类中，当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占void acquire(int arg)模板方法，独占式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则会进入同步队列等待，此方法会调用子类重写的tryAcquire方法void acquireInterruptibly(int arg)模板方法，与acquire相同，但是此方法可以响应中断，当前线程未获取到同步状态而进入同步队列中，如果当前线程被中断，此方法会抛出InterruptedException并返回boolean tryAcquireNanos(int arg, long nanosTimeout)模板方法，在acquireInterruptibly基础上增加了超时限制，如果当前线程在超时时间内没有获取到同步状态，则会返回false,如果获取到了则会返回trueboolean release(int arg)模板方法，独占式的释放同步状态，该方法会在释放同步状态后，将同步队列中的第一个节点包含的线程唤醒void acquireShared(int arg)模板方法，共享式的获取同步状态，如果当前系统未获取到同步状态，将会进入同步队列等待，与acquire的主要区别在于同一时刻可以有多个线程获取到同步状态void acquireSharedInterruptibly(int arg)模板方法，与acquireShared一致，但是可以响应中断boolean tryAcquireSharedNanos(int arg, long nanosTimeout)模板方法，在acquireSharedInterruptibly基础上增加了超时限制boolean releaseShared(int arg)模板方法，共享式的释放同步状态CollectiongetQueuedThreads()模板方法，获取等待在同步队列上的线程集合Node int waitStatus等待状态1、 CANCELLED，值为1，在同步队列中等待的线程等待超时或者被中断，需要从同步队列中取消等待，节点进入该状态后将不会变化；2、 SIGNAL，值为-1，后续节点的线程处于等待状态，而当前节点的线程如果释放了同步状态或者被取消，将会通知后续节点，使后续节点的线程得以运行；3、 CONDITION，值为-2，节点在条件队列中，节点线程等待在Condition上，当其他线程对Condition调用了signal()方法后，该节点将会从条件队列中转移到同步队列中，加入到对同步状态的获取中；4、 PROPAGATE，值为-3，表示下一次共享式同步状态获取将会无条件地传播下去Node prev前驱节点，当节点加入同步队列时被设置Node next后续节点Thread thread获取同步状态的线程Node nextWaiter条件队列中的后续节点，如果当前节点是共享的，那么这个字段将是一个SHARED变量，也就是说节点类型（独占和共享）和条件队列中的后续节点共用同一个字段LockSupport void park()阻塞当前线程，如果调用unpark方法或者当前线程被中断，才能从park方法返回LockSupport void unpark(Thread thread)唤醒处于阻塞状态的线程ConditionObject Node firstWaiter条件队列首节点ConditionObject Node lastWaiter条件队列尾节点void await()当前线程进入等待状态直到signal或中断，当前线程将进入运行状态且从await方法返回的情况，包括：其他线程调用该Condition的signal或者signalAll方法，且当前线程被选中唤醒；其他线程调用interrupt方法中断当前线程；如果当前线程从await方法返回表明该线程已经获取了Condition对象对应的锁void awaitUninterruptibly()和await方法类似，但是对中断不敏感long awaitNanos(long nanosTimeout)当前线程进入等待状态直到被signal、中断或者超时。返回值表示剩余的时间。boolean awaitUntil(Date deadline)当前线程进入等待状态直到被signal、中断或者某个时间。如果没有到指定时间就被通知，方法返回true，否则表示到了指定时间，返回falsevoid signal()唤醒一个等待在Condition上的线程，该线程从等待方法返回前必须获得与Condition相关联的锁void signalAll()唤醒所有等待在Condition上的线程，能够从等待方法返回的线程必须获得与Condition相关联的锁看到这，我们对AQS的数据结构应该基本上有一个大致的认识，有了这个基本面的认识，我们就可以来看下AQS的源代码。","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"并发","slug":"源码/并发","permalink":"http://www.baiyp.ren/categories/源码/并发/"},{"name":"高级","slug":"源码/并发/高级","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/"},{"name":"AQS","slug":"源码/并发/高级/AQS","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/AQS/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"高级","slug":"高级","permalink":"http://www.baiyp.ren/tags/高级/"},{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"},{"name":"AQS","slug":"AQS","permalink":"http://www.baiyp.ren/tags/AQS/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"并发","slug":"源码/并发","permalink":"http://www.baiyp.ren/categories/源码/并发/"},{"name":"高级","slug":"源码/并发/高级","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/"},{"name":"AQS","slug":"源码/并发/高级/AQS","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/AQS/"}]},{"title":"java中的显示锁Lock","slug":"java中的显示锁","date":"2019-08-10T01:41:11.000Z","updated":"2019-08-22T02:07:25.590Z","comments":true,"path":"java中的显示锁.html","link":"","permalink":"http://www.baiyp.ren/java中的显示锁.html","excerpt":"","text":"java中的显示锁Lock​ 什么是显示锁在Java 1.5之前，协调对共享对象的访问可以使用的机制只有synchronized和volatile两种。Java1.5增加了一种新的机制,Lock,Lock是一个接口，提供了无条件的、可轮询的、定时的、可中断的锁获取操作，所有的加锁和解锁操作方法都是显示的，因而称为显示锁,Lock并不是替代内置加锁的方法，而是当内置加锁机制不适用时，作为一种可选择的高级功能。Lock和synchronized的比较synchronized代码更简洁Lock可以在获取锁可以被中断，超时获取锁，尝试获取锁synchronized在1.8以前是性能低下的，到了1.8之后经过改良，性能基本行和Lock相持平，如果不是特殊场景推荐使用synchronized。Lock 的实现类ReentrantLockReentrantReadWriteLockLock的API1234567891011121314public interface Lock &#123; //获取锁 void lock(); //可中断锁，在获取锁的过程中可以中断线程 void lockInterruptibly() throws InterruptedException; //尝试获取锁，如果成功返回true，否则返回false boolean tryLock(); //超时获取锁， boolean tryLock(long time, TimeUnit unit) throws InterruptedException; //释放锁 void unlock(); //获取Condition 对象 Condition newCondition();Lock 使用的标准范式12345678 //加锁lock.lock();try &#123; //todo 需要加锁的代码&#125; finally &#123; //释放锁 lock.unlock();&#125;Condition接口​ 任意一个Java对象，都拥有一组监视器方法（定义在java.lang.Object上），主要包括wait()、wait(long timeout)、notify()以及notifyAll()方法，这些方法与synchronized同步关键字配合，可以实现等待/通知模式。Condition接口也提供了类似Object的监视器方法，与Lock配合可以实现等待/通知模式。12345678910111213141516171819202122public interface Condition &#123; //使当前线程在接收到信号前或被中断前一直保持等待状态. void await() throws InterruptedException; //使当前线程在接收到信号前或被中断前或达到指定时间前一直保持等待状态(TimeUnit为时间单位). boolean await(long time, TimeUnit unit) throws InterruptedException; //使当前线程在接收到信号前或被中断前或达到指定时间前一直保持等待状态(单位为毫秒). long awaitNanos(long nanosTimeout) throws InterruptedException; //使当前线程在接收到信号前或被中断前或达到最后日期期限前一直保持等待状态. boolean awaitUntil(Date deadline) throws InterruptedException; //是当前线程进入等待状态，对中断不敏感 void awaitUninterruptibly(); //唤醒一个在该Condition实例等待的线程. void signal(); //唤醒所有在该Condition实例等待的线程. void signalAll();Condition 使用的标准范式123456789101112131415161718192021222324252627282930313233343536/** * 创建一个显示锁对象 */private Lock lock = new ReentrantLock();/** * 创建 Condition 对象 */private Condition condition = lock.newCondition();/** * 等待方法 * * @throws InterruptedException */public void conditionWait() throws InterruptedException &#123; lock.lock(); try &#123; condition.await(); &#125; finally &#123; lock.unlock(); &#125;&#125;/** * 唤醒方法 * * @throws InterruptedException */public void conditionSignal() throws InterruptedException &#123; lock.lock(); try &#123; condition.signal(); &#125; finally &#123; lock.unlock(); &#125;&#125;ReentrantLock锁可重入​ 简单地讲就是：“同一个线程对于已经获得到的锁，可以多次继续申请到该锁的使用权”。而synchronized关键字隐式的支持重进入，比如一个synchronized修饰的递归方法，在方法执行时，执行线程在获取了锁之后仍能连续多次地获得该锁。ReentrantLock在调用lock()方法时，已经获取到锁的线程，能够再次调用lock()方法获取锁而不被阻塞。公平和非公平锁​ 如果在时间上，先对锁进行获取的请求一定先被满足，那么这个锁是公平的，反之，是不公平的。公平的获取锁，也就是等待时间最长的线程最优先获取锁，也可以说锁获取是顺序的。 ReentrantLock提供了一个构造函数，能够控制锁是否是公平的。事实上，公平的锁机制往往没有非公平的效率高。​ 在激烈竞争的情况下,非公平锁的性能高于公平锁的性能的一个原因是:在恢复一个被挂起的线程与该线程真正开始运行之间存在着严重的延迟。假设线程A持有一个锁,并且线程B请求这个锁。由于这个锁已被线程A持有,因此B将被挂起。当A释放锁时,B将被唤醒,因此会再次尝试获取锁。与此同时,如果C也请求这个锁,那么C很可能会在B被完全唤醒之前获得、使用以及释放这个锁。这样的情况是一种“双赢”的局面:B获得锁的时刻并没有推迟,C更早地获得了锁,并且吞吐量也获得了提高。使用示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/** * 创建线程池 */private static ExecutorService executorService = Executors.newCachedThreadPool();/** * 创建一个显示锁对象 */private static Lock lock = new ReentrantLock();/** * 创建 Condition 对象 */private static Condition condition = lock.newCondition();/** * 生产者 */private static void handel() &#123; System.out.println(\"尝试获取锁,线程：\" + Thread.currentThread().getId()); lock.lock(); System.out.println(\"获取锁成功,线程：\" + Thread.currentThread().getId()); try &#123; System.out.println(\"使线程进入等待状态,线程：\" + Thread.currentThread().getId()); //进入等待状态并释放所资源 condition.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; lock.unlock(); System.out.println(\"释放锁,线程：\" + Thread.currentThread().getId()); &#125;&#125;/** * 通知全部 */private static void latch() &#123; lock.lock(); try &#123; condition.signalAll(); &#125; finally &#123; lock.unlock(); &#125;&#125;public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 5; i++) &#123; executorService.submit(() -&gt; &#123; handel(); &#125;); &#125; Thread.sleep(5000); latch(); executorService.shutdown();&#125;输出1234567891011121314151617181920尝试获取锁,线程：13尝试获取锁,线程：16尝试获取锁,线程：15尝试获取锁,线程：14尝试获取锁,线程：12获取锁成功,线程：13使线程进入等待状态,线程：13获取锁成功,线程：16使线程进入等待状态,线程：16获取锁成功,线程：15使线程进入等待状态,线程：15获取锁成功,线程：14使线程进入等待状态,线程：14获取锁成功,线程：12使线程进入等待状态,线程：12释放锁,线程：13释放锁,线程：16释放锁,线程：12释放锁,线程：14释放锁,线程：15","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"高级","slug":"并发/高级","permalink":"http://www.baiyp.ren/categories/并发/高级/"},{"name":"显示锁","slug":"并发/高级/显示锁","permalink":"http://www.baiyp.ren/categories/并发/高级/显示锁/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"高级","slug":"高级","permalink":"http://www.baiyp.ren/tags/高级/"},{"name":"显示锁","slug":"显示锁","permalink":"http://www.baiyp.ren/tags/显示锁/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"高级","slug":"并发/高级","permalink":"http://www.baiyp.ren/categories/并发/高级/"},{"name":"显示锁","slug":"并发/高级/显示锁","permalink":"http://www.baiyp.ren/categories/并发/高级/显示锁/"}]},{"title":"java中的AQS-01原理以及使用","slug":"java中的AQS-01","date":"2019-08-09T09:47:16.000Z","updated":"2019-08-22T02:06:00.069Z","comments":true,"path":"java中的AQS-01.html","link":"","permalink":"http://www.baiyp.ren/java中的AQS-01.html","excerpt":"","text":"java中的AQS什么是AQS​ AQS是AbstractQueuedSynchronizer的简称。AQS提供了一种实现阻塞锁和一系列依赖FIFO等待队列的同步器的框架，如下图所示。AQS为一系列同步器依赖于一个单独的原子变量（state）的同步器提供了一个非常有用的基础。子类们必须定义改变state变量的protected方法，这些方法定义了state是如何被获取或释放的。鉴于此，本类中的其他方法执行所有的排队和阻塞机制。子类也可以维护其他的state变量，但是为了保证同步，必须原子地操作这些变量。​ AbstractQueuedSynchronizer中对state的操作是原子的，且不能被继承。所有的同步机制的实现均依赖于对改变量的原子操作。为了实现不同的同步机制，我们需要创建一个非共有的（non-public internal）扩展了AQS类的内部辅助类来实现相应的同步逻辑。AbstractQueuedSynchronizer并不实现任何同步接口，它提供了一些可以被具体实现类直接调用的一些原子操作方法来重写相应的同步逻辑。AQS同时提供了互斥模式（exclusive）和共享模式（shared）两种不同的同步逻辑。一般情况下，子类只需要根据需求实现其中一种模式，当然也有同时实现两种模式的同步类，如ReadWriteLock。接下来将详细介绍AbstractQueuedSynchronizer的提供的一些具体实现方法。AQS的设计和结构设计思想同步器的核心方法是acquire和release操作，其背后的思想也比较简洁明确。acquire操作while (当前同步器的状态不允许获取操作) {​ 如果当前线程不在队列中，则将其插入队列阻塞当前线程}如果线程位于队列中，则将其移出队列release操作更新同步器的状态if (新的状态允许某个被阻塞的线程获取成功){​ 解除队列中一个或多个线程的阻塞状态}三大组件​ 从这两个操作中的思想中我们可以提取出三大关键操作：同步器的状态变更、线程阻塞和释放、插入和移出队列。所以为了实现这两个操作，需要协调三大关键操作引申出来的三个基本组件：同步器状态的原子性管理；线程阻塞与解除阻塞；队列的管理；由这三个基本组件，我们来看j.u.c是怎么设计的。同步状态​ AQS类使用单个int（32位）来保存同步状态，并暴露出getState、setState以及compareAndSet操作来读取和更新这个同步状态。其中属性state被声明为volatile，并且通过使用CAS指令来实现compareAndSetState，使得当且仅当同步状态拥有一个一致的期望值的时候，才会被原子地设置成新值，这样就达到了同步状态的原子性管理，确保了同步状态的原子性、可见性和有序性。1234567891011121314private volatile int state;protected final int getState() &#123; return state;&#125;protected final void setState(int newState) &#123; state = newState;&#125;protected final boolean compareAndSetState(int expect, int update) &#123; // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125;基于AQS的具体实现类（如锁、信号量等）必须根据暴露出的状态相关的方法定义tryAcquire和tryRelease方法，以控制acquire和release操作。当同步状态满足时，tryAcquire方法必须返回true，而当新的同步状态允许后续acquire时，tryRelease方法也必须返回true。这些方法都接受一个int类型的参数用于传递想要的状态。123456789//尝试获取 protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException(); &#125;//尝试释放 protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException(); &#125;阻塞​ 通过JUC包提供了LockSupport类来解决这个问题。方法LockSupport.park阻塞当前线程直到有个LockSupport.unpark方法被调用。unpark的调用是没有被计数的，因此在一个park调用前多次调用unpark方法只会解除一个park操作。另外，它们作用于每个线程而不是每个同步器。一个线程在一个新的同步器上调用park操作可能会立即返回，因为在此之前可以有多余的unpark操作。但是，在缺少一个unpark操作时，下一次调用park就会阻塞。虽然可以显式地取消多余的unpark调用，但并不值得这样做。在需要的时候多次调用park会更高效。park方法同样支持可选的相对或绝对的超时设置，以及与JVM的Thread.interrupt结合 ，可通过中断来unpark一个线程。123456789101112131415public class LockSupport &#123; private LockSupport() &#123;&#125; // Cannot be instantiated. //唤醒指定线程 public static void unpark(Thread thread) &#123; if (thread != null) UNSAFE.unpark(thread); &#125; //阻塞当前线程 public static void park() &#123; UNSAFE.park(false, 0L); &#125;&#125;队列​ 整个框架的核心就是如何管理线程阻塞队列，该队列是严格的FIFO队列，因此不支持线程优先级的同步。同步队列的最佳选择是自身没有使用底层锁来构造的非阻塞数据结构，业界主要有两种选择，一种是MCS锁，另一种是CLH锁。其中CLH一般用于自旋，但是相比MCS，CLH更容易实现取消和超时，所以同步队列选择了CLH作为实现的基础。CLH队列实际并不那么像队列，它的出队和入队与实际的业务使用场景密切相关。它是一个链表队列，通过AQS的两个字段head（头节点）和tail（尾节点）来存取，这两个字段是volatile类型，初始化的时候都指向了一个空节点。​ 入队操作：CLH队列是FIFO队列，故新的节点到来的时候，是要插入到当前队列的尾节点之后。试想一下，当一个线程成功地获取了同步状态，其他线程将无法获取到同步状态，转而被构造成为节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个CAS方法，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。入队操作示意图大致如下：​ 出队操作：因为遵循FIFO规则，所以能成功获取到AQS同步状态的必定是首节点，首节点的线程在释放同步状态时，会唤醒后续节点，而后续节点会在获取AQS同步状态成功的时候将自己设置为首节点。设置首节点是由获取同步成功的线程来完成的，由于只能有一个线程可以获取到同步状态，所以设置首节点的方法不需要像入队这样的CAS操作，只需要将首节点设置为原首节点的后续节点同时断开原节点、后续节点的引用即可。出队操作示意图大致如下：条件队列​ 上一节的队列其实是AQS的同步队列，这一节的队列是条件队列，队列的管理除了有同步队列，还有条件队列。AQS只有一个同步队列，但是可以有多个条件队列。AQS框架提供了一个ConditionObject类，给维护独占同步的类以及实现Lock接口的类使用。​ ConditionObject类实现了Condition接口，Condition接口提供了类似Object管程式的方法，如await、signal和signalAll操作，还扩展了带有超时、检测和监控的方法。ConditionObject类有效地将条件与其它同步操作结合到了一起。该类只支持Java风格的管程访问规则，这些规则中，当且仅当当前线程持有锁且要操作的条件（condition）属于该锁时，条件操作才是合法的。这样，一个ConditionObject关联到一个ReentrantLock上就表现的跟内置的管程（通过Object.wait等）一样了。两者的不同仅仅在于方法的名称、额外的功能以及用户可以为每个锁声明多个条件。ConditionObject类和AQS共用了内部节点，有自己单独的条件队列。signal操作是通过将节点从条件队列转移到同步队列中来实现的，没有必要在需要唤醒的线程重新获取到锁之前将其唤醒。signal操作大致示意图如下：await操作就是当前线程节点从同步队列进入条件队列进行等待，大致示意图如下：​ 实现这些操作主要复杂在，因超时或Thread.interrupt导致取消了条件等待时，该如何处理。await和signal几乎同时发生就会有竞态问题，最终的结果遵照内置管程相关的规范。JSR133修订以后，就要求如果中断发生在signal操作之前，await方法必须在重新获取到锁后，抛出InterruptedException。但是，如果中断发生在signal后，await必须返回且不抛异常，同时设置线程的中断状态。AQS应用AQS被大量的应用在了同步工具上。ReentrantLock：ReentrantLock类使用AQS同步状态来保存锁重复持有的次数。当锁被一个线程获取时，ReentrantLock也会记录下当前获得锁的线程标识，以便检查是否是重复获取，以及当错误的线程试图进行解锁操作时检测是否存在非法状态异常。ReentrantLock也使用了AQS提供的ConditionObject，还向外暴露了其它监控和监测相关的方法。ReentrantReadWriteLock：ReentrantReadWriteLock类使用AQS同步状态中的16位来保存写锁持有的次数，剩下的16位用来保存读锁的持有次数。WriteLock的构建方式同ReentrantLock。ReadLock则通过使用acquireShared方法来支持同时允许多个读线程。Semaphore：Semaphore类（信号量）使用AQS同步状态来保存信号量的当前计数。它里面定义的acquireShared方法会减少计数，或当计数为非正值时阻塞线程；tryRelease方法会增加计数，在计数为正值时还要解除线程的阻塞。CountDownLatch：CountDownLatch类使用AQS同步状态来表示计数。当该计数为0时，所有的acquire操作（对应到CountDownLatch中就是await方法）才能通过。FutureTask：FutureTask类使用AQS同步状态来表示某个异步计算任务的运行状态（初始化、运行中、被取消和完成）。设置（FutureTask的set方法）或取消（FutureTask的cancel方法）一个FutureTask时会调用AQS的release操作，等待计算结果的线程的阻塞解除是通过AQS的acquire操作实现的。SynchronousQueues：SynchronousQueues类使用了内部的等待节点，这些节点可以用于协调生产者和消费者。同时，它使用AQS同步状态来控制当某个消费者消费当前一项时，允许一个生产者继续生产，反之亦然。​ 除了这些JUC提供的工具，还可以基于AQS自定义符合自己需求的同步器。","categories":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"并发","slug":"源码/并发","permalink":"http://www.baiyp.ren/categories/源码/并发/"},{"name":"高级","slug":"源码/并发/高级","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/"},{"name":"AQS","slug":"源码/并发/高级/AQS","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/AQS/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"高级","slug":"高级","permalink":"http://www.baiyp.ren/tags/高级/"},{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/tags/源码/"},{"name":"AQS","slug":"AQS","permalink":"http://www.baiyp.ren/tags/AQS/"}],"keywords":[{"name":"源码","slug":"源码","permalink":"http://www.baiyp.ren/categories/源码/"},{"name":"并发","slug":"源码/并发","permalink":"http://www.baiyp.ren/categories/源码/并发/"},{"name":"高级","slug":"源码/并发/高级","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/"},{"name":"AQS","slug":"源码/并发/高级/AQS","permalink":"http://www.baiyp.ren/categories/源码/并发/高级/AQS/"}]},{"title":"java原子操作CAS","slug":"java原子操作CAS","date":"2019-08-09T00:11:30.000Z","updated":"2019-08-22T02:05:21.307Z","comments":true,"path":"java原子操作CAS.html","link":"","permalink":"http://www.baiyp.ren/java原子操作CAS.html","excerpt":"","text":"java原子操作CAS什么是CASCAS（Compare and Swap），即比较并替换，是用于实现多线程同步的原子指令。​ 假定有两个操作A和B，如果从执行A的线程来看，当另一个线程执行B时，要么将B全部执行完，要么完全不执行B，那么A和B对彼此来说是原子的。​ 实现原子操作可以使用锁，锁机制，满足基本的需求是没有问题的了，但是有的时候我们的需求并非这么简单，我们需要更有效，更加灵活的机制，synchronized关键字是基于阻塞的锁机制，也就是说当一个线程拥有锁的时候，访问同一资源的其它线程需要等待，直到该线程释放锁，​ 这里会有些问题：首先，如果被阻塞的线程优先级很高很重要怎么办？其次，如果获得锁的线程一直不释放锁怎么办？（这种情况是非常糟糕的）。还有一种情况，如果有大量的线程来竞争资源，那CPU将会花费大量的时间和资源来处理这些竞争，同时，还有可能出现一些例如死锁之类的情况，最后，其实锁机制是一种比较粗糙，粒度比较大的机制，相对于像计数器这样的需求有点儿过于笨重。​ 实现原子操作还可以使用当前的处理器基本都支持CAS的指令，只不过每个厂家所实现的算法并不一样，每一个CAS操作过程都包含三个运算符：一个内存地址V，一个期望的值A和一个新值B，操作的时候如果这个地址上存放的值等于这个期望的值A，则将地址上的值赋为新值B，否则不做任何操作。​ CAS的基本思路就是，如果这个地址上的值和期望的值相等，则给其赋予新值，否则不做任何事儿，但是要返回原值是多少。循环CAS就是在一个循环里不断的做cas操作，直到成功为止。​ CAS是怎么实现线程的安全呢？语言层面不做处理，我们将其交给硬件—CPU和内存，利用CPU的多处理能力，实现硬件层面的阻塞，再加上volatile变量的特性即可实现基于原子操作的线程安全。悲观锁，乐观锁说到CAS，不得不提到两个专业词语：悲观锁，乐观锁。我们先来看看什么是悲观锁，什么是乐观锁。悲观锁​ 顾名思义，就是比较悲观的锁，总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。Java中synchronized和ReentrantLock等独占锁就是悲观锁思想的实现。乐观锁​ 反之，总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库提供的类似于write_condition机制，其实都是提供的乐观锁。我们今天讲的CAS就是乐观锁。CAS 的优点​ 非阻塞的轻量级乐观锁, 通过CPU指令实现, 在资源竞争不激烈的情况下性能高, 相比synchronize重量级悲观锁, synchronize有复杂的加锁, 解锁和唤醒线程操作.。CAS实现原子操作的三大问题ABA问题​ 因为CAS需要在操作值的时候，检查值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。​ 就像上图描述的一样，线程A原来的值是10，线程B修改为了20，但是线程C又将值修改为了10，这个时候线程A来读取了，与旧值做判断，发现还是10，没有修改过，就做了更新操作，但是我们知道，值有过变更。循环时间长开销大自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。只能保证一个共享变量的原子操作​ 当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁。​ 还有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如，有两个共享变量i＝2，j=a，合并一下ij=2a，然后用CAS来操作ij。从Java 1.5开始，JDK提供了AtomicReference类来保证引用对象之间的原子性，就可以把多个变量放在一个对象里来进行CAS操作。Jdk中相关原子操作类的使用JDK的CAS原子操作类在JUC包下 我看看下JAVA中如何实现CAS操作先来一波操作123456789101112131415161718192021222324252627282930313233343536373839404142 // private static AtomicInteger count = new AtomicInteger(0); private static AtomicInteger count = new AtomicInteger(0); /** * Cas 自旋操作 */ public static void accumulation() &#123; //自旋 for (; ; ) &#123; //获取旧值 int oldValue = count.get(); //比较并且交换 boolean flag = count.compareAndSet(oldValue, oldValue + 1); //如果成功退出自旋 if (flag) &#123; break; &#125; //失败打印信息再来一次 System.out.println(\"数据已被修改自旋再来一次\"); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; //五个线程再跑 for (int i = 0; i &lt; 5; i++) &#123; new Thread(() -&gt; &#123; try &#123; sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //每个线程让count自增100次 for (int n = 0; n &lt; 100; n++) &#123; accumulation(); &#125; &#125;).start(); &#125; sleep(2000); System.out.println(count); &#125;&#125;返回值12345数据已被修改自旋再来一次数据已被修改自旋再来一次数据已被修改自旋再来一次数据已被修改自旋再来一次500这个是我们自己实现了累加操作，但是实际上JDK给我们提供了累加操作方法将public static void accumulation() 方法替换为下面的方法就可以1count.incrementAndGet();我们进去看看他是怎么操作的123public final int incrementAndGet() &#123; return unsafe.getAndAddInt(this, valueOffset, 1) + 1; &#125;在进入getAndAddInt 方法1234567public final int getAndAddInt(Object o, long offset, int delta) &#123; int v; do &#123; v = getIntVolatile(o, offset); &#125; while (!compareAndSwapInt(o, offset, v, v + delta)); return v; &#125;我们发现，JDK也是通过自旋来实现的，和我们的效果一摸一样，他的核心方法是compareAndSwapInt我们常用的CAS操作类AtomicInteger•int addAndGet（int delta）：以原子方式将输入的数值与实例中的值（AtomicInteger里的value）相加，并返回结果。•boolean compareAndSet（int expect，int update）：如果输入的数值等于预期值，则以原子方式将该值设置为输入的值。•int getAndIncrement()：以原子方式将当前值加1，注意，这里返回的是自增前的值。•int getAndSet（int newValue）：以原子方式设置为newValue的值，并返回旧值。AtomicIntegerArray主要是提供原子的方式更新数组里的整型，其常用方法如下。•int addAndGet（int i，int delta）：以原子方式将输入值与数组中索引i的元素相加。•boolean compareAndSet（int i，int expect，int update）：如果当前值等于预期值，则以原子方式将数组位置i的元素设置成update值。需要注意的是，数组value通过构造方法传递进去，然后AtomicIntegerArray会将当前数组复制一份，所以当AtomicIntegerArray对内部的数组元素进行修改时，不会影响传入的数组。更新引用类型​ 原子更新基本类型的AtomicInteger，只能更新一个变量，如果要原子更新多个变量，就需要使用这个原子更新引用类型提供的类。Atomic包提供了以下3个类。AtomicReference原子更新引用类型。AtomicStampedReference​ 利用版本戳的形式记录了每次改变以后的版本号，这样的话就不会存在ABA问题了。这就是AtomicStampedReference的解决方案。AtomicMarkableReference跟AtomicStampedReference差不多， AtomicStampedReference是使用pair的int stamp作为计数器使用，AtomicMarkableReference的pair使用的是boolean mark。 还是那个水的例子，AtomicStampedReference可能关心的是动过几次，AtomicMarkableReference关心的是有没有被人动过，方法都比较简单。AtomicMarkableReference：​ 原子更新带有标记位的引用类型。可以原子更新一个布尔类型的标记位和引用类型。构造方法是AtomicMarkableReference（V initialRef，booleaninitialMark）。原子更新字段类​ 如果需原子地更新某个类里的某个字段时，就需要使用原子更新字段类，Atomic包提供了以下3个类进行原子字段更新。​ 要想原子地更新字段类需要两步。第一步，因为原子更新字段类都是抽象类，每次使用的时候必须使用静态方法newUpdater()创建一个更新器，并且需要设置想要更新的类和属性。第二步，更新类的字段（属性）必须使用public volatile修饰符。AtomicIntegerFieldUpdater：原子更新整型的字段的更新器。AtomicLongFieldUpdater：原子更新长整型字段的更新器。AtomicReferenceFieldUpdater：原子更新引用类型里的字段。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"高级","slug":"并发/高级","permalink":"http://www.baiyp.ren/categories/并发/高级/"},{"name":"CAS","slug":"并发/高级/CAS","permalink":"http://www.baiyp.ren/categories/并发/高级/CAS/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"高级","slug":"高级","permalink":"http://www.baiyp.ren/tags/高级/"},{"name":"CAS","slug":"CAS","permalink":"http://www.baiyp.ren/tags/CAS/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"高级","slug":"并发/高级","permalink":"http://www.baiyp.ren/categories/并发/高级/"},{"name":"CAS","slug":"并发/高级/CAS","permalink":"http://www.baiyp.ren/categories/并发/高级/CAS/"}]},{"title":"java并发工具类-Exchanger","slug":"java并发工具类-06","date":"2019-08-07T10:04:39.000Z","updated":"2019-08-22T02:04:25.048Z","comments":true,"path":"java并发工具类-06.html","link":"","permalink":"http://www.baiyp.ren/java并发工具类-06.html","excerpt":"","text":"java并发工具类-ExchangerExchanger 简介​ Exchange位于JUC包下面，主要是用于线程之间数据交换的工具类，经常用于管道设计和遗传算法中，Exchanger用于进行线程间的数据交换，它提供一个同步点，在这个同步点，两个线程可以交换彼此的数据。这两个线程通过exchange 方法交换数据，如果第一个线程先执行exchange 方法，它会一直等待第二个线程也执行exchange 方法，当两个线程都到达同步点时，这两个线程就可以交换数据。可以将Exchange看做是一个双向数据传输的SynchronousQueue。此类提供对外的操作是同步的；用于成对出现的线程之间交换数据；可以视作双向的同步队列；可应用于基因算法、流水线设计等场景。Exchanger 提供的方法构造方法123456/** * Creates a new Exchanger. */ public Exchanger() &#123; participant = new Participant(); &#125;创建一个新的Exchange。主要方法这个类提供对外的接口非常简洁，一个无参构造函数，两个重载的范型exchange方法：等待另外一个线程到达此交换点（除非当前线程被中断），将给定的对象x传送给该线程，并且接收该线程的对象。1public V exchange(V x) throws InterruptedException等待另外一个线程到达此交换点（除非当前线程被中断，或者超出了指定的等待时间），将指定的对象x传送给该线程，同时接收该线程的对象。12public V exchange(V x, long timeout, TimeUnit unit) throws InterruptedException, TimeoutExceptionExchanger的应用场景​ Exchanger可以用于遗传算法，遗传算法里需要选出两个人作为交配对象，这时候会交换两人的数据，并使用交叉规则得出2个交配结果。​ 只要用于两个线程之间交换数据。​ 如果两个线程有一个没有到达exchange方法，则会一直等待,如果担心有特殊情况发生，避免一直等待，可以使用exchange(V x, long timeout, TimeUnit unit)设置最大等待时长。案例​ 比如生活中两个人，一个人有零食，另一个人有钱，他们两个想等价交换，对好口号在某个地方相见，一个人先到了之后，必须等另一个人带着需要的东西来了之后，才能开始交换。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class ExchangerTest &#123; public static void main(String[] args) &#123; Exchanger exchanger = new Exchanger(); ExecutorService service = Executors.newCachedThreadPool(); //线程1 拿着零食来交换 service.submit(() -&gt; &#123; String data1 = \"零食\"; System.out.println(\"线程\" + Thread.currentThread().getName() + \"正在把数据 \" + data1 + \" 换出去\"); String data2 = null; try &#123; System.out.println(\"正在交换等待10s\"); Thread.sleep((long) Math.random() * 10000); //开始交换数 data2 = (String) exchanger.exchange(data1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"线程 \" + Thread.currentThread().getName() + \"换回的数据为 \" + data2); &#125;); //线程2 拿着钱来交换 service.submit(() -&gt; &#123; String data1 = \"钱\"; System.out.println(\"线程\" + Thread.currentThread().getName() + \"正在把数据 \" + data1 + \" 交换出去\"); String data2 = null; try &#123; System.out.println(\"正在交换等待10s\"); Thread.sleep((long) (Math.random() * 10000)); //开始交换数 data2 = (String) exchanger.exchange(data1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"线程 \" + Thread.currentThread().getName() + \"交换回来的数据是: \" + data2); &#125;); service.shutdown(); &#125;&#125;输出123456线程pool-1-thread-1正在把数据 零食 换出去正在交换等待10s线程pool-1-thread-2正在把数据 钱 交换出去正在交换等待10s线程 pool-1-thread-2交换回来的数据是: 零食线程 pool-1-thread-1换回的数据为 钱","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"工具类","slug":"工具类","permalink":"http://www.baiyp.ren/tags/工具类/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}]},{"title":"java变得牛逼的方法","slug":"变得牛逼的方法","date":"2019-08-05T13:51:08.000Z","updated":"2019-08-22T02:03:39.580Z","comments":true,"path":"变得牛逼的方法.html","link":"","permalink":"http://www.baiyp.ren/变得牛逼的方法.html","excerpt":"","text":"变得牛逼的方法信息获取习惯使用百度让周围人都认为你习惯于使用百度多关注些大咖的微博让周围人都认为你的知识都是从大咖那里学来的，不要让周围人找到学习的重点知识学习和技能训练混淆认识 知识幻觉给周围人灌输知识很容易获取，通过很简单的方式就可以掌握，把各种不一样的知识混淆视听，让他们找不到重点，感觉自己很牛逼的样子。培养他人学习使用碎片化时间培养周围人在工作期间，多看CSDN，博客等文章，让他们感觉自己在学习，在进步。不断提供各种各样看起来有价值的学习资料大量提供几十个G的学习视频和资料，不要告诉他们重点是什么，让他们看到资料就头大，学几节课就放弃的那种。让他们去看一些枯燥的书，基础知识提供一些JAVA基础书籍，JAVA核心技术上下卷，让他们学完后忘记，忘记后继续学，到怀疑自己是不是学JAVA的料，到怀疑人生。框架只要使用培养周围人框架只用论，不要探究原理，并且嘲讽那些探究原理的人。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"装逼","slug":"架构/装逼","permalink":"http://www.baiyp.ren/categories/架构/装逼/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"装逼","slug":"装逼","permalink":"http://www.baiyp.ren/tags/装逼/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"装逼","slug":"架构/装逼","permalink":"http://www.baiyp.ren/categories/架构/装逼/"}]},{"title":"git生成并添加SSH key","slug":"git生成并添加SSH-key","date":"2019-08-05T12:36:43.000Z","updated":"2019-08-22T02:03:11.902Z","comments":true,"path":"git生成并添加SSH-key.html","link":"","permalink":"http://www.baiyp.ren/git生成并添加SSH-key.html","excerpt":"","text":"git生成并添加SSH key下载安装git下载地址https://git-scm.com/downloads启动git bash执行代码配置你的用户信息12git config --global user.name \"xxx\" //配置你的账户名字 注意用户后面的空格git config --global user.email \"xxx@qq.com\" //配置你的创建github账户的邮箱；查看已经配置好的用户信息12git config user.namegit config user.email生成SSH key1ssh-keygen -t rsa -C \"xxx@qq.com\"获取SSH key1cat ~/.ssh/id_rsa.pub将 SSH key 配置到码云","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"git","slug":"架构/git","permalink":"http://www.baiyp.ren/categories/架构/git/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"ssh key","slug":"ssh-key","permalink":"http://www.baiyp.ren/tags/ssh-key/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"git","slug":"架构/git","permalink":"http://www.baiyp.ren/categories/架构/git/"}]},{"title":"java并发工具类-Callable、Future 和FutureTask","slug":"java并发工具类-05","date":"2019-08-05T10:04:33.000Z","updated":"2019-08-22T02:04:17.438Z","comments":true,"path":"java并发工具类-05.html","link":"","permalink":"http://www.baiyp.ren/java并发工具类-05.html","excerpt":"","text":"java并发工具类-Callable、Future 和FutureTask前言创建线程的2种方式，一种是直接继承Thread，另外一种就是实现Runnable接口。这2种方式都有一个缺陷就是：在执行完任务之后无法获取执行结果。如果需要获取执行结果，就必须通过共享变量或者使用线程通信的方式来达到效果，这样使用起来就比较麻烦。而自从Java 1.5开始，就提供了Callable和Future，通过它们可以在任务执行完毕之后得到任务执行结果Callable接口Callable位于JUC包下，它也是一个接口，在它里面也只声明了一个方法叫做call()：12345678910@FunctionalInterfacepublic interface Callable&lt;V&gt; &#123; /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception;&#125;​ Callable接口代表一段可以调用并返回结果的代码。​ Future接口表示异步任务，是还没有完成的任务给出的未来结果。所以说Callable用于产生结果，Future用于获取结果。​ Callable接口使用泛型去定义它的返回类型。​ Executors类提供了一些有用的方法在线程池中执行Callable内的任务。由于Callable任务是并行的（并行就是整体看上去是并行的，其实在某个时间点只有一个线程在执行），我们必须等待它返回的结果。​ java.util.concurrent.Future对象为我们解决了这个问题。在线程池提交Callable任务后返回了一个Future对象，使用它可以知道Callable任务的状态和得到Callable返回的执行结果。Future提供了get()方法让我们可以等待Callable结束并获取它的执行结果。那么怎么使用Callable呢？一般情况下是配合ExecutorService来使用的，在ExecutorService接口中声明了若干个submit方法的重载版本：123&lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task);&lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result);Future&lt;?&gt; submit(Runnable task);第一个方法：submit提交一个实现Callable接口的任务，并且返回封装了异步计算结果的Future。第二个方法：submit提交一个实现Runnable接口的任务，并且指定了在调用Future的get方法时返回的result对象。第三个方法：submit提交一个实现Runnable接口的任务，并且返回封装了异步计算结果的Future。因此我们只要创建好我们的线程对象（实现Callable接口或者Runnable接口），然后通过上面3个方法提交给线程池去执行即可。Future接口​ Future就是对于具体的Runnable或者Callable任务的执行结果进行取消、查询是否完成、获取结果。必要时可以通过get方法获取执行结果，该方法会阻塞直到任务返回结果。​ Future接口是用来获取异步计算结果的，说白了就是对具体的Runnable或者Callable对象任务执行的结果进行获取(get())，取消(cancel())，判断是否完成等操作。我们看看Future接口的源码：12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;&#125;在Future接口中声明了5个方法，下面依次解释每个方法的作用方法作用cance(boolean mayInterruptIfRunning)试图取消执行的任务，参数为true时直接中断正在执行的任务，否则直到当前任务执行完成，成功取消后返回true，否则返回falseisCancelled()方法表示任务是否被取消成功，如果在任务正常完成前被取消成功，则返回 true。isDone()方法表示任务是否已经完成，若任务完成，则返回true；get()方法用来获取执行结果，这个方法会产生阻塞，会一直等到任务执行完毕才返回；get(long timeout, TimeUnit unit)设定计算结果的返回时间，如果在规定时间内没有返回计算结果则抛出TimeOutExceptionFuture提供了三种功能判断任务是否完成；能够中断任务；能够获取任务执行结果。因为Future只是一个接口，所以是无法直接用来创建对象使用的，因此就有了下面的FutureTask。RunnableFuture接口RunnableFuture实现了Runnable和Future。因此FutureTask可以传递到线程对象Thread或Excutor(线程池)来执行。1234567public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; /** * Sets this Future to the result of its computation * unless it has been cancelled. */ void run();&#125;FutureTask我们先来看一下FutureTask的实现：1public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;FutureTask类实现了RunnableFuture接口，我们看一下RunnableFuture接口的实现1public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt;可以看出RunnableFuture继承了Runnable接口和Future接口，而FutureTask实现了RunnableFuture接口。所以它既可以作为Runnable被线程执行，又可以作为Future得到Callable的返回值。分析FutureTask除了实现了Future接口外还实现了Runnable接口，因此FutureTask也可以直接提交给Executor执行。 当然也可以调用线程直接执行（FutureTask.run()）。接下来我们根据FutureTask.run()的执行时机来分析其所处的3种状态：未启动，FutureTask.run()方法还没有被执行之前，FutureTask处于未启动状态，当创建一个FutureTask，而且没有执行FutureTask.run()方法前，这个FutureTask也处于未启动状态。已启动，FutureTask.run()被执行的过程中，FutureTask处于已启动状态。已完成，FutureTask.run()方法执行完正常结束，或者被取消或者抛出异常而结束，FutureTask都处于完成状态。下面我们再来看看FutureTask的方法执行示意图（方法和Future接口基本是一样的，这里就不过多描述了）当FutureTask处于未启动或已启动状态时，如果此时我们执行FutureTask.get()方法将导致调用线程阻塞；当FutureTask处于已完成状态时，执行FutureTask.get()方法将导致调用线程立即返回结果或者抛出异常。当FutureTask处于未启动状态时，执行FutureTask.cancel()方法将导致此任务永远不会执行。当FutureTask处于已启动状态时，执行cancel(true)方法将以中断执行此任务线程的方式来试图停止任务，如果任务取消成功，cancel(…)返回true；但如果执行cancel(false)方法将不会对正在执行的任务线程产生影响(让线程正常执行到完成)，此时cancel(…)返回false。当任务已经完成，执行cancel(…)方法将返回false。最后我们给出FutureTask的两种构造函数：1234public FutureTask(Callable&lt;V&gt; callable) &#123;&#125;public FutureTask(Runnable runnable, V result) &#123;&#125;事实上，FutureTask是Future接口的一个唯一实现类。使用示例​ 通过上面的介绍，我们对Callable，Future，RunnableFuture，FutureTask都有了比较清晰的了解了，那么它们到底有什么用呢？我们前面说过通过这样的方式去创建线程的话，最大的好处就是能够返回结果，加入有这样的场景，我们现在需要计算一个数据，而这个数据的计算比较耗时，而我们后面的程序也要用到这个数据结果，那么这个时Callable岂不是最好的选择？我们可以开设一个线程去执行计算，而主线程继续做其他事，而后面需要使用到这个数据时，我们再使用Future获取不就可以了吗？下面我们就来编写一个这样的实例。Callable+Future 获取执行结果12345678910111213141516171819202122//创建线程池 long currentTime = System.currentTimeMillis(); ExecutorService executor = Executors.newFixedThreadPool(5); //创建Callable对象任务 Callable&lt;Integer&gt; task = () -&gt; &#123; System.out.println(\"Callable子线程在进行计算\"); Thread.sleep(3000); int sum = 0; for (int i = 0; i &lt; 100; i++) sum += i; return sum; &#125;; //提交任务并获取执行结果 Future&lt;Integer&gt; result = executor.submit(task); //关闭线程池 executor.shutdown(); System.out.println(\"主线程开始走到这里,耗时：\" + (System.currentTimeMillis() - currentTime)); //get方法会阻塞线程执行 Integer value = result.get(); System.out.println(\"获取值：\" + value + \"，共耗时：\" + (System.currentTimeMillis() - currentTime));运行结果123主线程开始走到这里,耗时139Callable子线程在进行计算获取值：4950，共耗时：3169Callable+FutureTask获取执行结果123456789101112131415161718192021222324//创建线程池 long currentTime = System.currentTimeMillis(); ExecutorService executor = Executors.newFixedThreadPool(5); //创建Callable对象任务 Callable&lt;Integer&gt; task = () -&gt; &#123; System.out.println(\"Callable子线程在进行计算\"); Thread.sleep(3000); int sum = 0; for (int i = 0; i &lt; 100; i++) sum += i; return sum; &#125;; //第二种方式，注意这种方式和第一种方式效果是类似的,需要创建FutureTask对象 FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); //提交任务并获取执行结果 // Future future = executor.submit(task); executor.submit(futureTask); //关闭线程池 executor.shutdown(); System.out.println(\"主线程开始走到这里,耗时：\" + (System.currentTimeMillis() - currentTime)); //get方法会阻塞线程执行 Integer value = futureTask.get(); System.out.println(\"获取值：\" + value + \"，共耗时：\" + (System.currentTimeMillis() - currentTime));输出结果123Callable子线程在进行计算主线程开始走到这里,耗时：89获取值：4950，共耗时：3089总结实现Runnable接口和实现Callable接口的区别：Runnable是自从java1.1就有了，而Callable是1.5之后才加上去的。Callable规定的方法是call(),Runnable规定的方法是run()。Callable的任务执行后可返回值，而Runnable的任务是不能返回值(是void)。call方法可以抛出异常，run方法不可以。运行Callable任务可以拿到一个Future对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过Future对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。加入线程池运行，Runnable使用ExecutorService的execute方法，Callable使用submit方法。Callable、Runnable、Future和FutureTask 的区别Callable、Runnable、Future和FutureTask 做为java 线程池运行的重要载体，有必要深入理解。Callable 和 Runnable 都是执行的任务的接口，区别在于Callable有返回值，而Runnable无返回值。Future 表示异步任务返回结果的接口RunnableFuture 继承了Runnable， Future，表示可以带有返回值的run接口FutureTask是一个实现类，实现了RunnableFuture接口，既能接受Runnable类型的任务，也可以接受Callable类型的任务，这个类的作用主要是 有一个protected void done()方法用来扩展使用，作为一个回调方法","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"工具类","slug":"工具类","permalink":"http://www.baiyp.ren/tags/工具类/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}]},{"title":"JAVA中的分布式事务06-MQ事务(最终一致性)","slug":"JAVA中的分布式事务06","date":"2019-08-05T02:05:25.000Z","updated":"2019-08-22T02:09:23.164Z","comments":true,"path":"JAVA中的分布式事务06.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的分布式事务06.html","excerpt":"","text":"JAVA中的分布式事务06-MQ事务(最终一致性)方案简介​ 基于MQ的分布式事务方案其实是对本地消息表的封装，将本地消息表基于MQ 内部，其他方面的协议基本与本地消息表一致。处理流程下面主要基于RocketMQ4.3之后的版本介绍MQ的分布式事务方案。在本地消息表方案中，保证事务主动方发写业务表数据和写消息表数据的一致性是基于数据库事务，RocketMQ的事务消息相对于普通MQ，相对于提供了2PC的提交接口，方案如下：正常情况——事务主动方发消息这种情况下，事务主动方服务正常，没有发生故障，发消息流程如下：1、发送方向 MQ服务端(MQ Server)发送half消息。2、MQ Server 将消息持久化成功之后，向发送方 ACK 确认消息已经发送成功。3、发送方开始执行本地事务逻辑。4、发送方根据本地事务执行结果向 MQ Server 提交二次确认（commit 或是 rollback）。5、MQ Server 收到 commit 状态则将半消息标记为可投递，订阅方最终将收到该消息；MQ Server 收到 rollback 状态则删除半消息，订阅方将不会接受该消息。异常情况——事务主动方消息恢复在断网或者应用重启等异常情况下，图中4提交的二次确认超时未到达 MQ Server，此时处理逻辑如下：5、MQ Server 对该消息发起消息回查。6、发送方收到消息回查后，需要检查对应消息的本地事务执行的最终结果。7、发送方根据检查得到的本地事务的最终状态再次提交二次确认8、MQ Server基于commit / rollback 对消息进行投递或者删除介绍完RocketMQ的事务消息方案后，由于前面已经介绍过本地消息表方案，这里就简单介绍RocketMQ分布式事务：事务主动方基于MQ通信通知事务被动方处理事务，事务被动方基于MQ返回处理结果。如果事务被动方消费消息异常，需要不断重试，业务处理逻辑需要保证幂等。如果是事务被动方业务上的处理失败，可以通过MQ通知事务主动方进行补偿或者事务回滚。方案总结相比本地消息表方案，MQ事务方案优点是：消息数据独立存储 ，降低业务系统与消息系统之间的耦合。吞吐量优于使用本地消息表方案。缺点是：一次消息发送需要两次网络请求(half消息 + commit/rollback消息)业务处理服务需要实现消息状态回查接口","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.baiyp.ren/tags/分布式事务/"},{"name":"MQ","slug":"MQ","permalink":"http://www.baiyp.ren/tags/MQ/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}]},{"title":"友情链接","slug":"friends","date":"2019-08-03T16:00:00.000Z","updated":"2019-08-22T01:42:35.157Z","comments":true,"path":"friends.html","link":"","permalink":"http://www.baiyp.ren/friends.html","excerpt":"","text":"","categories":[],"tags":[],"keywords":[]},{"title":"java并发工具类-Semaphore","slug":"java并发工具类-04","date":"2019-08-03T05:45:13.000Z","updated":"2019-08-22T02:04:08.896Z","comments":true,"path":"java并发工具类-04.html","link":"","permalink":"http://www.baiyp.ren/java并发工具类-04.html","excerpt":"","text":"java并发工具类-SemaphoreSemaphore简介​ Semaphore也叫信号量，在JDK1.5被引入，可以用来控制同时访问特定资源的线程数量，通过协调各个线程，以保证合理的使用资源。Semaphore内部维护了一组虚拟的许可，许可的数量可以通过构造函数的参数指定。访问特定资源前，必须使用acquire方法获得许可，如果许可数量为0，该线程则一直阻塞，直到有可用许可。访问资源后，使用release释放许可。Semaphore和ReentrantLock类似，获取许可有公平策略和非公平许可策略，默认情况下使用非公平策略。通俗的讲Semaphore是一种在多线程环境下使用的设施，该设施负责协调各个线程，以保证它们能够正确、合理的使用公共资源的设施，也是操作系统中用于控制进程同步互斥的量。Semaphore是一种计数信号量，用于管理一组资源，内部是基于AQS的共享模式。它相当于给线程规定一个量从而控制允许活动的线程数。是用来控制同时访问特定资源的线程数量，它通过协调各个线程，以保证合理的使用公共资源应用场景​ Semaphore 是 synchronized 的加强版，作用是控制线程的并发数量。就这一点而言，单纯的synchronized 关键字是实现不了的。​ Semaphore可以用于做流量控制，特别是公用资源有限的应用场景，比如数据库连接。假如有一个需求，要读取几万个文件的数据，因为都是IO密集型任务，我们可以启动几十个线程并发地读取，但是如果读到内存后，还需要存储到数据库中，而数据库的连接数只有10个，这时我们必须控制只有10个线程同时获取数据库连接保存数据，否则会报错无法获取数据库连接。这个时候，就可以使用Semaphore来做流量控制。工作原理​ 以一个停车场是运作为例。为了简单起见，假设停车场只有三个车位，一开始三个车位都是空的。这时如果同时来了五辆车，看门人允许其中三辆不受阻碍的进入，然后放下车拦，剩下的车则必须在入口等待，此后来的车也都不得不在入口处等待。这时，有一辆车离开停车场，看门人得知后，打开车拦，放入一辆，如果又离开两辆，则又可以放入两辆，如此往复。这个停车系统中，每辆车就好比一个线程，看门人就好比一个信号量，看门人限制了可以活动的线程。假如里面依然是三个车位，但是看门人改变了规则，要求每次只能停两辆车，那么一开始进入两辆车，后面得等到有车离开才能有车进入，但是得保证最多停两辆车。对于Semaphore类而言，就如同一个看门人，限制了可活动的线程数。Semaphore主要方法构造方法创建具有给定许可数的计数信号量并设置为非公平信号量1public Semaphore(int permits)当fair等于true时，创建具有给定许可数的计数信号量并设置为公平信号量。1public Semaphore(int permits, boolean fair)其他方法从此信号量获取一个许可前线程将一直阻塞。相当于一辆车占了一个车位1public void acquire() throws InterruptedException从此信号量获取给定数目许可，在提供这些许可前一直将线程阻塞。比如n=2，就相当于一辆车占了两个车位。1public void acquire(int permits) throws InterruptedException释放一个许可，将其返回给信号量。就如同车开走返回一个车位。1public void release()释放n个许可1public void release(int permits)获取当前可用许可数1public int availablePermits()代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465public class SemaphoreTest &#123; private static ExecutorService executorService = Executors.newCachedThreadPool(); private static Random random = new Random(); //阻塞队列 private static BlockingQueue&lt;String&gt; parks = new LinkedBlockingQueue&lt;&gt;(5); public static void execute(Semaphore semaphore) &#123; //获取一个随机数 long sleepTime = random.nextInt(10); long threadId = Thread.currentThread().getId(); String park = null; try &#123; /** * 获取许可，首先判断semaphore内部的数字是否大于0，如果大于0， * 才能获得许可，然后将初始值5减去1，线程才会接着去执行；如果没有 * 获得许可(原因是因为已经有5个线程获得到许可，semaphore内部的数字为0)， * 线程会阻塞直到已经获得到许可的线程，调用release()方法，释放掉许可， * 也就是将semaphore内部的数字加1，该线程才有可能获得许可。 */ semaphore.acquire(); /** * 对应的线程会到阻塞对，对应车辆去获取到车位，如果没有拿到一致阻塞， * 直到其他车辆归还车位。 */ park = parks.take(); System.out.println(\"线程ID\" + threadId + \",开始占用车位:\" + park + \"，当前剩余车位\" + semaphore.availablePermits()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; try &#123; //睡眠随机秒 Thread.sleep(sleepTime * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //归还车位 parks.offer(park); System.out.println(\"线程ID\" + threadId + \",开始归还车位:\" + park + \",共占用\" + sleepTime + \"秒\"); //线程释放掉许可，通俗来将就是将semaphore内部的数字加1 semaphore.release(); &#125; public static void main(String[] args) &#123; //初始化线程数量 int threadNum = 100; parks.offer(\"车位一\"); parks.offer(\"车位二\"); parks.offer(\"车位三\"); parks.offer(\"车位四\"); parks.offer(\"车位五\"); // 初始化5个许可证 Semaphore semaphore = new Semaphore(5); for (int i = 0; i &lt; threadNum; i++) &#123; executorService.submit(() -&gt; &#123; execute(semaphore); &#125;); &#125; &#125;&#125;注意事项我们知道可以通过信号量控制共享资源的访问，底层还是AQS这一套，这没什么难的。但是有一点可能被大家忽略：声明信号量的时候，比如只有3个许可证，但是运行过程中，某个时刻的许可证数量是没有限制的。1234567891011121314151617181920212223public static void main(String[] args) &#123; //初始化线程数量 int threadNum = 100; parks.offer(\"车位一\"); parks.offer(\"车位二\"); parks.offer(\"车位三\"); parks.offer(\"车位四\"); parks.offer(\"车位五\"); // 初始化 0 个许可证 应该是不可以 放行的 Semaphore semaphore = new Semaphore(0); /** * 释放了5个许可证，Semaphore(5) 效果是一样的 * 实际使用中注意不能过多的释放release */ semaphore.release(5); for (int i = 0; i &lt; threadNum; i++) &#123; executorService.submit(() -&gt; &#123; execute(semaphore); &#125;); &#125; &#125;​​ 即使创建信号量的时候，指定了信号量的大小。但是在通过 release()操作释放信号量任然能超过配置的大小。也就有可能同时执行的线程数量比最开始设置的要大。没有任何线程获取信号量的时候，依然能够释放并且释放的有效。​ 推荐的做法是一个线程先 acquire 然后 release。如果释放线程和获取线程不是同一个，那么最好保证这种对应关系。不要释放过多的许可证。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"工具类","slug":"工具类","permalink":"http://www.baiyp.ren/tags/工具类/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}]},{"title":"ThreadLocal引发的内存泄漏分析","slug":"java多线程-ThreadLocal-02","date":"2019-08-03T01:23:46.000Z","updated":"2019-08-22T01:58:42.870Z","comments":true,"path":"java多线程-ThreadLocal-02.html","link":"","permalink":"http://www.baiyp.ren/java多线程-ThreadLocal-02.html","excerpt":"","text":"ThreadLocal引发的内存泄漏分析预备知识引用Object o = new Object();这个o，我们可以称之为对象引用，而new Object()我们可以称之为在内存中产生了一个对象实例。当写下 o=null时，只是表示o不再指向堆中object的对象实例，不代表这个对象实例不存在了。强引用: 就是指在程序代码之中普遍存在的，类似“Object obj=new Object（）”这类的引用，只要强引用还存在，垃圾收集器永远不会回收掉被引用的对象实例。软引用: 是用来描述一些还有用但并非必需的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象实例列进回收范围之中进行第二次回收。如果这次回收还没有足够的内存，才会抛出内存溢出异常。在JDK 1.2之后，提供了SoftReference类来实现软引用。弱引用: 也是用来描述非必需对象的，但是它的强度比软引用更弱一些，被弱引用关联的对象实例只能生存到下一次垃圾收集发生之前。当垃圾收集器工作时，无论当前内存是否足够，都会回收掉只被弱引用关联的对象实例。在JDK 1.2之后，提供了WeakReference类来实现弱引用。虚引用: 也称为幽灵引用或者幻影引用，它是最弱的一种引用关系。一个对象实例是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的就是能在这个对象实例被收集器回收时收到一个系统通知。在之后，提供了类来实现虚引用内存泄漏的现象1234567891011121314151617181920212223242526272829303132333435363738/** * 类说明：ThreadLocal造成的内存泄漏演示 */public class ThreadLocalOOM &#123; private static final int TASK_LOOP_SIZE = 500; final static ThreadPoolExecutor poolExecutor = new ThreadPoolExecutor(5, 5, 1, TimeUnit.MINUTES, new LinkedBlockingQueue&lt;&gt;()); static class LocalVariable &#123; private byte[] a = new byte[1024*1024*5];/*5M大小的数组*/ &#125; final static ThreadLocal&lt;LocalVariable&gt; localVariable = new ThreadLocal&lt;&gt;(); public static void main(String[] args) throws InterruptedException &#123; Object o = new Object(); /*5*5=25*/ for (int i = 0; i &lt; TASK_LOOP_SIZE; ++i) &#123; poolExecutor.execute(new Runnable() &#123; public void run() &#123; //localVariable.set(new LocalVariable()); new LocalVariable(); System.out.println(\"use local varaible\"); //localVariable.remove(); &#125; &#125;); Thread.sleep(100); &#125; System.out.println(\"pool execute over\"); &#125;&#125;首先只简单的在每个任务中new出一个数组可以看到内存的实际使用控制在25M左右：因为每个任务中会不断new出一个5M的数组，5*5=25M，这是很合理的。当我们启用了ThreadLocal以后：内存占用最高升至150M，一般情况下稳定在90M左右，那么加入一个ThreadLocal后，内存的占用真的会这么多？于是，我们加入一行代码：再执行，看看内存情况:可以看见最高峰的内存占用也在25M左右，完全和我们不加ThreadLocal表现一样。这就充分说明，确实发生了内存泄漏。分析根据我们前面对ThreadLocal的分析，我们可以知道每个Thread 维护一个 ThreadLocalMap，这个映射表的 key 是 ThreadLocal实例本身，value 是真正需要存储的 Object，也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。仔细观察ThreadLocalMap，这个map是使用 ThreadLocal 的弱引用作为 Key 的，弱引用的对象在 GC 时会被回收。因此使用了ThreadLocal后，引用链如图所示图中的虚线表示弱引用。​ 这样，当把threadlocal变量置为null以后，没有任何强引用指向threadlocal实例，所以threadlocal将会被gc回收。这样一来，ThreadLocalMap中就会出现key为null的Entry，就没有办法访问这些key为null的Entry的value，如果当前线程再迟迟不结束的话，这些key为null的Entry的value就会一直存在一条强引用链：​ Thread Ref -&gt; Thread -&gt; ThreaLocalMap -&gt; Entry -&gt; value，而这块value永远不会被访问到了，所以存在着内存泄露。​ 只有当前thread结束以后，current thread就不会存在栈中，强引用断开，Current Thread、Map value将全部被GC回收。最好的做法是不在需要使用ThreadLocal变量后，都调用它的remove()方法，清除数据。​ 其实考察ThreadLocal的实现，我们可以看见，无论是get()、set()在某些时候，调用了expungeStaleEntry方法用来清除Entry中Key为null的Value，但是这是不及时的，也不是每次都会执行的，所以一些情况下还是会发生内存泄露。只有remove()方法中显式调用了expungeStaleEntry方法。​ 从表面上看内存泄漏的根源在于使用了弱引用，但是另一个问题也同样值得思考：为什么使用弱引用而不是强引用？下面我们分两种情况讨论：​ key 使用强引用：引用ThreadLocal的对象被回收了，但是ThreadLocalMap还持有ThreadLocal的强引用，如果没有手动删除，ThreadLocal的对象实例不会被回收，导致Entry内存泄漏。​ key 使用弱引用：引用的ThreadLocal的对象被回收了，由于ThreadLocalMap持有ThreadLocal的弱引用，即使没有手动删除，ThreadLocal的对象实例也会被回收。value在下一次ThreadLocalMap调用set，get，remove都有机会被回收。​ 比较两种情况，我们可以发现：由于ThreadLocalMap的生命周期跟Thread一样长，如果都没有手动删除对应key，都会导致内存泄漏，但是使用弱引用可以多一层保障。​ 因此，ThreadLocal内存泄漏的根源是：由于ThreadLocalMap的生命周期跟Thread一样长，如果没有手动删除对应key就会导致内存泄漏，而不是因为弱引用。总结​ JVM利用设置ThreadLocalMap的Key为弱引用，来避免内存泄露。JVM利用调用remove、get、set方法的时候，回收弱引用。当ThreadLocal存储很多Key为null的Entry的时候，而不再去调用remove、get、set方法，那么将导致内存泄漏。使用线程池+ ThreadLocal 时要小心，因为这种情况下，线程是一直在不断的重复运行的，从而也就造成了value可能造成累积的情况。错误使用ThreadLocal导致线程不安全12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/** * 非安全的ThreadLocal 演示 */public class ThreadLocalUnsafe implements Runnable &#123; public static ThreadLocal&lt;Number&gt; numberThreadLocal = new ThreadLocal&lt;Number&gt;(); /** * 使用threadLocal的静态变量 */ public static Number number = new Number(0); public void run() &#123; //每个线程计数加一 number.setNum(number.getNum() + 1); //将其存储到ThreadLocal中 numberThreadLocal.set(number); //延时2ms try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //输出num值 System.out.println(\"内存地址：\"+numberThreadLocal.get() + \"，\" + Thread.currentThread().getName() + \"=\" + numberThreadLocal.get().getNum()); &#125; public static void main(String[] args) &#123; for (int i = 0; i &lt; 5; i++) &#123; new Thread(new ThreadLocalUnsafe()).start(); &#125; &#125; /** * 一个私有的类 Number */ private static class Number &#123; public Number(int num) &#123; this.num = num; &#125; private int num; public int getNum() &#123; return num; &#125; public void setNum(int num) &#123; this.num = num; &#125; &#125;&#125;输出12345内存地址：com.test.thread.ThreadLocalUnsafe$Number@5658172e，Thread-2=5内存地址：com.test.thread.ThreadLocalUnsafe$Number@5658172e，Thread-0=5内存地址：com.test.thread.ThreadLocalUnsafe$Number@5658172e，Thread-4=5内存地址：com.test.thread.ThreadLocalUnsafe$Number@5658172e，Thread-1=5内存地址：com.test.thread.ThreadLocalUnsafe$Number@5658172e，Thread-3=5​ 为什么每个线程都输出5？难道他们没有独自保存自己的Number副本吗？为什么其他线程还是能够修改这个值？仔细考察下我们的代码，我们发现我们的number对象是静态的，所以每个ThreadLoalMap中保存的其实同一个对象的引用，这样的话，当有其他线程对这个引用指向的对象实例做修改时，其实也同时影响了所有的线程持有的对象引用所指向的同一个对象实例。这也就是为什么上面的程序为什么会输出一样的结果：5个线程中保存的是同一Number对象的引用，在线程睡眠的时候，其他线程将num变量进行了修改，而修改的对象Number的实例是同一份，因此它们最终输出的结果是相同的。而上面的程序要正常的工作，应该去掉number的static 修饰，让每个ThreadLoalMap中使用不同的number对象进行操作。总结：ThreadLocal只保证线程隔离，不保证线程安全","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"ThreadLocal","slug":"并发/ThreadLocal","permalink":"http://www.baiyp.ren/categories/并发/ThreadLocal/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://www.baiyp.ren/tags/ThreadLocal/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"ThreadLocal","slug":"并发/ThreadLocal","permalink":"http://www.baiyp.ren/categories/并发/ThreadLocal/"}]},{"title":"java并发工具类 CyclicBarrier","slug":"java并发工具类-03","date":"2019-08-01T05:45:08.000Z","updated":"2019-08-22T02:04:00.893Z","comments":true,"path":"java并发工具类-03.html","link":"","permalink":"http://www.baiyp.ren/java并发工具类-03.html","excerpt":"","text":"java并发工具类 CyclicBarrierCyclicBarrier简介CyclicBarrier，是JDK1.5的java.util.concurrent并发包中提供的一个并发工具类。所谓Cyclic即 循环 的意思，所谓Barrier即 屏障 的意思。所以综合起来，CyclicBarrier指的就是 循环屏障，虽然这个叫法很奇怪，但是确能很好地表示它的作用。它的作用就是会让所有线程都等待完成后才会继续下一步行动。​ 举个例子，就像生活中我们会约朋友们到某个餐厅一起吃饭，有些朋友可能会早到，有些朋友可能会晚到，但是这个餐厅规定必须等到所有人到齐之后才会让我们进去。这里的朋友们就是各个线程，餐厅就是 CyclicBarrier。CyclicBarrier栅栏​ CyclicBarrier和CountDownLatch是非常类似的，CyclicBarrier核心的概念是在于设置一个等待线程的数量边界，到达了此边界之后进行执行。CyclicBarrier类是一个同步辅助类，它允许一组线程互相等待，直到到达某个公共屏障点（Common Barrier Point）。​ CyclicBarrier类是一种同步机制，它能够对处理一些算法的线程实现同。换句话讲，它就是一个所有线程必须等待的一个栅栏，直到所有线程都到达这里，然后所有线程才可以继续做其他事情。​ 通过调用CyclicBarrier对象的await()方法，两个线程可以实现互相等待。一旦N个线程在等待CyclicBarrier达成，所有线程将被释放掉去继续执行。怎么使用 CyclicBarrier12public CyclicBarrier(int parties)public CyclicBarrier(int parties, Runnable barrierAction)parties : 是参与线程的个数​ 其参数表示屏障拦截的线程数量，每个线程调用await方法告诉CyclicBarrier我已经到达了屏障，然后当前线程被阻塞。*barrierAction * : 优先执行线程​ 用于在线程到达屏障时，优先执行barrierAction，方便处理更复杂的业务场景。CyclicBarrier可以用于多线程计算数据，最后合并计算结果的场景。重要方法12public int await() throws InterruptedException, BrokenBarrierExceptionpublic int await(long timeout, TimeUnit unit) throws InterruptedException, BrokenBarrierException, TimeoutException线程调用 await() 表示自己已经到达栅栏BrokenBarrierException 表示栅栏已经被破坏，破坏的原因可能是其中一个线程 await() 时被中断或者超时基本使用代码实现一个线程组的线程需要等待所有线程完成任务后再继续执行下一次任务1234567891011121314151617181920212223242526272829303132333435363738394041public class CyclicBarrierTest &#123; private static Random random = new Random(); public static void execute(CyclicBarrier barrier) &#123; //获取一个随机数 long sleepTime = random.nextInt(10); long threadId = Thread.currentThread().getId(); try &#123; //睡眠随机秒 Thread.sleep(sleepTime * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"线程ID\" + threadId + \",准备任务完成耗时：\" + sleepTime + \"当前时间\" + System.currentTimeMillis()); //线程等待其他任务完成后唤醒 try &#123; barrier.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; System.out.println(\"线程ID\" + threadId + \",开始执行任务，当前时间：\" + System.currentTimeMillis()); &#125; public static void main(String[] args) &#123; //初始化线程数量 int threadNum = 10; //初始化一般的线程 CyclicBarrier barrier = new CyclicBarrier(5, () -&gt; System.out.println(\"整理任务开始...\")); ExecutorService executor = Executors.newFixedThreadPool(threadNum); for (int i = 0; i &lt; threadNum; i++) &#123; executor.submit(() -&gt; &#123; execute(barrier); &#125;); &#125; &#125;&#125;输出12345678910111213141516171819202122线程ID12,准备任务完成耗时：0当前时间1565163947881线程ID17,准备任务完成耗时：0当前时间1565163947881线程ID16,准备任务完成耗时：0当前时间1565163947881线程ID20,准备任务完成耗时：3当前时间1565163950881线程ID14,准备任务完成耗时：3当前时间1565163950881整理任务开始...线程ID14,开始执行任务，当前时间：1565163950881线程ID12,开始执行任务，当前时间：1565163950881线程ID17,开始执行任务，当前时间：1565163950881线程ID16,开始执行任务，当前时间：1565163950881线程ID20,开始执行任务，当前时间：1565163950881线程ID18,准备任务完成耗时：4当前时间1565163951881线程ID13,准备任务完成耗时：5当前时间1565163952881线程ID21,准备任务完成耗时：7当前时间1565163954881线程ID19,准备任务完成耗时：9当前时间1565163956882线程ID15,准备任务完成耗时：9当前时间1565163956882整理任务开始...线程ID15,开始执行任务，当前时间：1565163956882线程ID18,开始执行任务，当前时间：1565163956882线程ID13,开始执行任务，当前时间：1565163956882线程ID21,开始执行任务，当前时间：1565163956882线程ID19,开始执行任务，当前时间：1565163956882​ 从打印结果可以看出，所有线程会等待全部线程到达栅栏之后才会继续执行，并且最后到达的线程会完成 Runnable 的任务。CyclicBarrier 使用场景可以用于多线程计算数据，最后合并计算结果的场景。CyclicBarrier 与 CountDownLatch 区别CountDownLatch 是一次性的，CyclicBarrier 是可循环利用的CountDownLatch.await一般阻塞工作线程，所有的进行预备工作的线程执行countDown，而CyclicBarrier通过工作线程调用await从而自行阻塞，直到所有工作线程达到指定屏障，再大家一起往下走。CountDownLatch 参与的线程的职责是不一样的，有的在倒计时，有的在等待倒计时结束。CyclicBarrier 参与的线程职责是一样的。在控制多个线程同时运行上，CountDownLatch可以不限线程数量，而CyclicBarrier是固定线程数。同时，CyclicBarrier还可以提供一个barrierAction，合并多线程计算结果。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"工具类","slug":"工具类","permalink":"http://www.baiyp.ren/tags/工具类/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}]},{"title":"JAVA中的分布式事务05-本地消息表(最终一致性)","slug":"JAVA中的分布式事务05","date":"2019-08-01T02:05:25.000Z","updated":"2019-08-22T02:09:14.731Z","comments":true,"path":"JAVA中的分布式事务05.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的分布式事务05.html","excerpt":"","text":"JAVA中的分布式事务05-本地消息表(最终一致性)方案简介​ 本地消息表的方案最初是由ebay提出，核心思路是将分布式事务拆分成本地事务进行处理。​ 方案通过在事务主动发起方额外新建事务消息表，事务发起方处理业务和记录事务消息在本地事务中完成，轮询事务消息表的数据发送事务消息，事务被动方基于消息中间件消费事务消息表中的事务。​ 这样设计可以避免”业务处理成功 + 事务消息发送失败“，或”业务处理失败 + 事务消息发送成功“的棘手情况出现，保证2个系统事务的数据一致性。处理流程​ 下面把分布式事务最先开始处理的事务方成为事务主动方，在事务主动方之后处理的业务内的其他事务成为事务被动方。​ 为了方便理解，下面继续以电商下单为例进行方案解析，这里把整个过程简单分为扣减库存，订单创建2个步骤，库存服务和订单服务分别在不同的服务器节点上，其中库存服务是事务主动方，订单服务是事务被动方。事务的主动方需要额外新建事务消息表，用于记录分布式事务的消息的发生、处理状态。整个业务处理流程如下：步骤1 事务主动方处理本地事务。事务主动发在本地事务中处理业务更新操作和写消息表操作。上面例子中库存服务阶段再本地事务中完成扣减库存和写消息表(图中1、2)。步骤2 事务主动方通过消息中间件，通知事务被动方处理事务通知事务待消息。消息中间件可以基于Kafka、RocketMQ消息队列，事务主动方法主动写消息到消息队列，事务消费方消费并处理消息队列中的消息。上面例子中，库存服务把事务待处理消息写到消息中间件，订单服务消费消息中间件的消息，完成新增订单（图中3 - 5）。步骤3 事务被动方通过消息中间件，通知事务主动方事务已处理的消息。上面例子中，订单服务把事务已处理消息写到消息中间件，库存服务消费中间件的消息，并将事务消息的状态更新为已完成(图中6 - 8)​ 为了数据的一致性，当处理错误需要重试，事务发送方和事务接收方相关业务处理需要支持幂等。具体保存一致性的容错处理如下：1、当步骤1处理出错，事务回滚，相当于什么都没发生。2、当步骤2、步骤3处理出错，由于未处理的事务消息还是保存在事务发送方，事务发送方可以定时轮询为超时消息数据，再次发送的消息中间件进行处理。事务被动方消费事务消息重试处理。3、如果是业务上的失败，事务被动方可以发消息给事务主动方进行回滚。4、如果多个事务被动方已经消费消息，事务主动方需要回滚事务时需要通知事务被动方回滚。方案总结方案的优点如下：从应用设计开发的角度实现了消息数据的可靠性，消息数据的可靠性不依赖于消息中间件，弱化了对MQ中间件特性的依赖。方案轻量，容易实现。缺点如下：与具体的业务场景绑定，耦合性强，不可公用。消息数据与业务数据同库，占用业务系统资源。业务系统在使用关系型数据库的情况下，消息服务性能会受到关系型数据库并发性能的局限。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.baiyp.ren/tags/分布式事务/"},{"name":"本地消息表","slug":"本地消息表","permalink":"http://www.baiyp.ren/tags/本地消息表/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}]},{"title":"什么是ThreadLocal","slug":"java多线程-ThreadLocal-01","date":"2019-08-01T01:23:46.000Z","updated":"2019-08-22T01:58:14.580Z","comments":true,"path":"java多线程-ThreadLocal-01.html","link":"","permalink":"http://www.baiyp.ren/java多线程-ThreadLocal-01.html","excerpt":"","text":"什么是ThreadLocal什么是ThreadLocal​ 早在JDK 1.2的版本中就提供java.lang.ThreadLocal，ThreadLocal为解决多线程程序的并发问题提供了一种新的思路。使用这个工具类可以很简洁地编写出优美的多线程程序。当使用ThreadLocal维护变量时，ThreadLocal为每个使用该变量的线程提供独立的变量副本，所以每一个线程都可以独立地改变自己的副本，而不会影响其它线程所对应的副本。从线程的角度看，目标变量就象是线程的本地变量，这也是类名中“Local”所要表达的意思。​ 所以，在Java中编写线程局部变量的代码相对来说要笨拙一些，因此造成线程局部变量没有在Java开发者中得到很好的普及。与Synchonized的比较​ ThreadLocal和Synchonized都用于解决多线程并发訪问。可是ThreadLocal与synchronized有本质的差别。synchronized是利用锁的机制，使变量或代码块在某一时该仅仅能被一个线程访问。而ThreadLocal为每个线程都提供了变量的副本，使得每个线程在某一时间訪问到的并非同一个对象，这样就隔离了多个线程对数据的数据共享。​ Spring的事务就借助了ThreadLocal类。Spring会从数据库连接池中获得一个connection，然会把connection放进ThreadLocal中，也就和线程绑定了，事务需要提交或者回滚，只要从ThreadLocal中拿到connection进行操作。为何Spring的事务要借助ThreadLocal类？以JDBC为例，正常的事务代码可能如下：12345678910111213dbc = new DataBaseConnection();//第1行Connection con = dbc.getConnection();//第2行con.setAutoCommit(false);// //第3行con.executeUpdate(...);//第4行con.executeUpdate(...);//第5行con.executeUpdate(...);//第6行con.commit();////第7行上述代码，可以分成三个部分:事务准备阶段：第1～3行业务处理阶段：第4～6行事务提交阶段：第7行可以很明显的看到，不管我们开启事务还是执行具体的sql都需要一个具体的数据库连接。​ 现在我们开发应用一般都采用三层结构，如果我们控制事务的代码都放在DAO(DataAccessObject)对象中，在DAO对象的每个方法当中去打开事务和关闭事务，当Service对象在调用DAO时，如果只调用一个DAO，那我们这样实现则效果不错，但往往我们的Service会调用一系列的DAO对数据库进行多次操作，那么，这个时候我们就无法控制事务的边界了，因为实际应用当中，我们的Service调用的DAO的个数是不确定的，可根据需求而变化，而且还可能出现Service调用Service的情况。​ 但是需要注意一个问题，如何让三个DAO使用同一个数据源连接呢？我们就必须为每个DAO传递同一个数据库连接，要么就是在DAO实例化的时候作为构造方法的参数传递，要么在每个DAO的实例方法中作为方法的参数传递。这两种方式无疑对我们的Spring框架或者开发人员来说都不合适。为了让这个数据库连接可以跨阶段传递，又不显示的进行参数传递，就必须使用别的办法。​ Web容器中，每个完整的请求周期会由一个线程来处理。因此，如果我们能将一些参数绑定到线程的话，就可以实现在软件架构中跨层次的参数共享（是隐式的共享）。而JAVA中恰好提供了绑定的方法–使用ThreadLocal。结合使用Spring里的IOC和AOP，就可以很好的解决这一点。只要将一个数据库连接放入ThreadLocalThreadLocalThreadLocal的使用ThreadLocal类接口很简单，只有4个方法，我们先来了解一下：void set(Object value)设置当前线程的线程局部变量的值。public Object get()该方法返回当前线程所对应的线程局部变量。public void remove()将当前线程局部变量的值删除，目的是为了减少内存的占用，该方法是JDK 5.0新增的方法。需要指出的是，当线程结束后，对应该线程的局部变量将自动被垃圾回收，所以显式调用该方法清除线程的局部变量并不是必须的操作，但它可以加快内存回收的速度。protected Object initialValue()返回该线程局部变量的初始值，该方法是一个protected的方法，显然是为了让子类覆盖而设计的。这个方法是一个延迟调用方法，在线程第1次调用get()或set(Object)时才执行，并且仅执行1次。ThreadLocal中的缺省实现直接返回一个null。1public final static ThreadLocal&lt;String&gt; RESOURCE = new ThreadLocal&lt;String&gt;();RESOURCE代表一个能够存放String类型的ThreadLocal对象。此时不论什么一个线程能够并发访问这个变量，对它进行写入、读取操作，都是线程安全的。实现解析threadLo1234567891011121314151617public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals; &#125;​ 上面先取到当前线程，然后调用getMap方法获取对应的ThreadLocalMap，ThreadLocalMap是ThreadLocal的静态内部类，然后Thread类中有一个这样类型成员，所以getMap是直接返回Thread的成员。看下ThreadLocal的内部类ThreadLocalMap源码：​ 可以看到有个Entry内部静态类，它继承了WeakReference，总之它记录了两个信息，一个是ThreadLocal&lt;?&gt;类型，一个是Object类型的值。getEntry方法则是获取某个ThreadLocal对应的值，set方法就是更新或赋值相应的ThreadLocal对应的值。​ 回顾我们的get方法，其实就是拿到每个线程独有的ThreadLocalMap然后再用ThreadLocal的当前实例，拿到Map中的相应的Entry，然后就可以拿到相应的值返回出去。当然，如果Map为空，还会先进行map的创建，初始化等工作。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"ThreadLocal","slug":"并发/ThreadLocal","permalink":"http://www.baiyp.ren/categories/并发/ThreadLocal/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"http://www.baiyp.ren/tags/ThreadLocal/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"ThreadLocal","slug":"并发/ThreadLocal","permalink":"http://www.baiyp.ren/categories/并发/ThreadLocal/"}]},{"title":"java并发工具类-CountDownLatch","slug":"java并发工具类-02","date":"2019-07-28T05:45:01.000Z","updated":"2019-08-22T02:03:48.592Z","comments":true,"path":"java并发工具类-02.html","link":"","permalink":"http://www.baiyp.ren/java并发工具类-02.html","excerpt":"","text":"java并发工具类-CountDownLatchCountDownLatch的简介CountDownLatch是一个同步工具类，它允许一个或多个线程一直等待，直到其他线程执行完后再执行。CountDownLatch是在java1.5被引入的，跟它一起被引入的并发工具类还有CyclicBarrier、Semaphore、 ConcurrentHashMap和BlockingQueue，它们都存在于JUC (java.util.concurrent)包下CountDownLatch原理​ CountDownLatch是通过一个计数器来实现的，计数器的初始化值为线程的数量。每当一个线程完成了自己的任务后，计数器的值就相应得减1（CountDownLatch.countDown()方法）。当计数器到达0时，表示所有的线程都已完成任务,，然后在闭锁上等待CountDownLatch.await()方法的线程就可以恢复执行任务。注意：这是一个一次性操作 - 计数无法重置。 如果你需要一个重置的版本计数，考虑使用CyclicBarrier。应用场景​ 实现最大的并行性：有时我们想同时启动多个线程，实现最大程度的并行性。例如，我们想测试一个单例类。如果我们创建一个初始计数为1的CountDownLatch，并让所有线程都在这个锁上等待，那么我们可以很轻松地完成测试。我们只需调用 一次countDown()方法就可以让所有的等待线程同时恢复执行。​ 开始执行前等待n个线程完成各自任务：例如应用程序启动类要确保在处理用户请求前，所有N个外部系统已经启动和运行了，例如处理excel中多个表单。注意：一个线程不一定只能做countDown一次，也可以countDown多次CountDownLatch的示例1234567891011121314151617181920212223242526272829303132333435363738394041424344public class CountDownLatchTest &#123; private static ThreadPoolExecutor threadPool = new ThreadPoolExecutor(5, 10, 100, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;Runnable&gt;(5)); private static Random random = new Random(); public static void execute(CountDownLatch countDownLatch) &#123; //获取一个随机数 long sleepTime = random.nextInt(10); long threadId = Thread.currentThread().getId(); System.out.println(\"线程ID\" + threadId + \",开始执行--countDown\"); try &#123; //睡眠随机秒 Thread.sleep(sleepTime * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; //计数器减1 countDownLatch.countDown(); System.out.println(\"线程ID\" + threadId + \",准备任务完成耗时：\" + sleepTime + \"当前时间\" + System.currentTimeMillis()); try &#123; //线程等待其他任务完成后唤醒 countDownLatch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"线程ID\" + threadId + \",开始执行任务，当前时间：\" + System.currentTimeMillis()); &#125; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch countDownLatch = new CountDownLatch(5); for (int i = 0; i &lt; 5; i++) &#123; threadPool.submit(() -&gt; &#123; execute(countDownLatch); &#125;); &#125; //线程等待其他任务完成后唤醒 countDownLatch.await(); Thread.sleep(1000); threadPool.shutdown(); System.out.println(\"全部任务执行完成\"); &#125;&#125;打印结果线程ID13,开始执行–countDown线程ID16,开始执行–countDown线程ID15,开始执行–countDown线程ID12,开始执行–countDown线程ID14,开始执行–countDown线程ID14,准备任务完成耗时：3当前时间1565159118048线程ID16,准备任务完成耗时：4当前时间1565159119047线程ID12,准备任务完成耗时：4当前时间1565159119048线程ID15,准备任务完成耗时：6当前时间1565159121047线程ID13,准备任务完成耗时：7当前时间1565159122048线程ID13,开始执行任务，当前时间：1565159122048线程ID14,开始执行任务，当前时间：1565159122048线程ID12,开始执行任务，当前时间：1565159122048线程ID16,开始执行任务，当前时间：1565159122048线程ID15,开始执行任务，当前时间：1565159122049全部任务执行完成使用CountDownLatch压测​ 在实战项目中，我们除了使用 jemter 等工具进行压测外，还可以自己动手使用 CountDownLatch 类编写压测代码。可以说 jemter 的并发压测背后也是使用的 CountDownLatch。可见掌握 CountDownLatch 类的使用是有多么的重要。​ CountDownLatch是Java多线程同步器的四大金刚之一，CountDownLatch能够使一个线程等待其他线程完成各自的工作后再执行。1234567891011121314151617181920212223242526272829private void latchTest() throws InterruptedException &#123; //压测线程数 int testThreads = 300; final CountDownLatch start = new CountDownLatch(1); final CountDownLatch end = new CountDownLatch(testThreads); //创建线程池 ExecutorService exce = Executors.newFixedThreadPool(testThreads); for (int i = 0; i &lt; testThreads; i++) &#123; exce.submit(() -&gt; &#123; try &#123; //启动后等待 唤醒 start.await(); //压测具体方法 testLoad(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; //结束CountDownLatch -1 end.countDown(); &#125; &#125;); &#125; //连接池线程初始化完成 开始压测 start.countDown(); //压测完成后结束 end.await(); exce.shutdown(); &#125;简简单单的几行代码就可以实现300的压测。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"工具类","slug":"工具类","permalink":"http://www.baiyp.ren/tags/工具类/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}]},{"title":"线程间的协作","slug":"java多线程基础-05","date":"2019-07-24T23:23:07.000Z","updated":"2019-08-22T05:55:02.066Z","comments":true,"path":"java多线程基础-05.html","link":"","permalink":"http://www.baiyp.ren/java多线程基础-05.html","excerpt":"","text":"线程间的协作线程间的协作​ 线程之间相互配合，完成某项工作，比如：一个线程修改了一个对象的值，而另一个线程感知到了变化，然后进行相应的操作，整个过程开始于一个线程，而最终执行又是另一个线程。前者是生产者，后者就是消费者，这种模式隔离了“做什么”（what）和“怎么做”（How），简单的办法是让消费者线程不断地循环检查变量是否符合预期在while循环中设置不满足的条件，如果条件满足则退出while循环，从而完成消费者的工作。却存在如下问题：1） 难以确保及时性。2）难以降低开销。如果降低睡眠的时间，比如休眠1毫秒，这样消费者能更加迅速地发现条件变化，但是却可能消耗更多的处理器资源，造成了无端的浪费。等待/通知机制​ 是指一个线程A调用了对象O的wait()方法进入等待状态，而另一个线程B调用了对象O的notify()或者notifyAll()方法，线程A收到通知后从对象O的wait()方法返回，进而执行后续操作。上述两个线程通过对象O来完成交互，而对象上的wait()和notify/notifyAll()的关系就如同开关信号一样，用来完成等待方和通知方之间的交互工作。notify()：​ 通知一个在对象上等待的线程,使其从wait方法返回,而返回的前提是该线程获取到了对象的锁，没有获得锁的线程重新进入WAITING状态。notifyAll()：​ 通知所有等待在该对象上的线程wait()​ 调用该方法的线程进入 WAITING状态,只有等待另外线程的通知或被中断才会返回.需要注意,调用wait()方法后,会释放对象的锁wait(long)​ 超时等待一段时间,这里的参数时间是毫秒,也就是等待长达n毫秒,如果没有通知就超时返回wait (long,int)​ 对于超时时间更细粒度的控制,可以达到纳秒等待和通知的标准范式等待方遵循如下原则。1）获取对象的锁。2）如果条件不满足，那么调用对象的wait()方法，被通知后仍要检查条件。3）条件满足则执行对应的逻辑。123456synchronized (对象)&#123; while(条件不满足)&#123; 对象.wait(); &#125; 对应的处理逻辑 &#125;通知方遵循如下原则。1）获得对象的锁。2）改变条件。3）通知所有等待在对象上的线程1234synchronized (对象)&#123; 改变条件 对象.notifyAll();&#125;​ 在调用wait()、notify()系列方法之前，线程必须要获得该对象的对象级别锁，即只能在同步方法或同步块中调用wait()方法、notify()系列方法，进入wait()方法后，当前线程释放锁，在从wait()返回前，线程与其他线程竞争重新获得锁， 执行notify()系列方法的线程退出调用了notifyAll的synchronized代码块的时候后，他们就会去竞争。如果其中一个线程获得了该对象锁，它就会继续往下执行，在它退出synchronized代码块，释放锁后，其他的已经被唤醒的线程将会继续竞争获取该锁，一直进行下去，直到所有被唤醒的线程都执行完毕。notify和notifyAll应该用谁​ 尽可能用notifyall()，谨慎使用notify()，因为notify()只会唤醒一个线程，我们无法确保被唤醒的这个线程一定就是我们需要唤醒的线程，具体表现参见代码。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"多线程基础","slug":"多线程基础","permalink":"http://www.baiyp.ren/tags/多线程基础/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}]},{"title":"JAVA中的分布式事务04-TCC(最终一致性)","slug":"JAVA中的分布式事务04","date":"2019-07-21T02:05:25.000Z","updated":"2019-08-22T02:09:06.246Z","comments":true,"path":"JAVA中的分布式事务04.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的分布式事务04.html","excerpt":"","text":"JAVA中的分布式事务04-TCC(最终一致性)方案简介​ TCC（Try-Confirm-Cancel）的概念，最早是由Pat Helland于2007年发表的一篇名为《Life beyond Distributed Transactions:an Apostate’s Opinion》的论文提出。TCC是服务化的二阶段编程模型，其Try、Confirm、Cancel 3个方法均由业务编码实现；Try操作作为一阶段，负责资源的检查和预留。Confirm操作作为二阶段提交操作，执行真正的业务。Cancel是预留资源的取消。TCC事务的Try、Confirm、Cancel可以理解为SQL事务中的Lock、Commit、Rollback。处理流程为了方便理解，下面以电商下单为例进行方案解析，这里把整个过程简单分为扣减库存，订单创建2个步骤，库存服务和订单服务分别在不同的服务器节点上。阶段1：Try 阶段​ 从执行阶段来看，与传统事务机制中业务逻辑相同。但从业务角度来看，却不一样。TCC机制中的Try仅是一个初步操作，它和后续的确认一起才能真正构成一个完整的业务逻辑，这个阶段主要完成：完成所有业务检查( 一致性 )预留必须业务资源( 准隔离性 )Try 尝试执行业务TCC事务机制以初步操作（Try）为中心的，确认操作（Confirm）和取消操作（Cancel）都是围绕初步操作（Try）而展开。因此，Try阶段中的操作，其保障性是最好的，即使失败，仍然有取消操作（Cancel）可以将其执行结果撤销。假设商品库存为100，购买数量为2，这里检查和更新库存的同时，冻结用户购买数量的库存，同时创建订单，订单状态为待确认。阶段2：Confirm / Cancel 阶段根据Try阶段服务是否全部正常执行，继续执行确认操作（Confirm）或取消操作（Cancel）。Confirm和Cancel操作满足幂等性，如果Confirm或Cancel操作执行失败，将会不断重试直到执行完成。Confirm：确认当Try阶段服务全部正常执行， 执行确认业务逻辑操作这里使用的资源一定是Try阶段预留的业务资源。在TCC事务机制中认为，如果在Try阶段能正常的预留资源，那Confirm一定能完整正确的提交。Confirm阶段也可以看成是对Try阶段的一个补充，Try+Confirm一起组成了一个完整的业务逻辑。Cancel：取消当Try阶段存在服务执行失败， 进入Cancel阶段Cancel取消执行，释放Try阶段预留的业务资源，上面的例子中，Cancel操作会把冻结的库存释放，并更新订单状态为取消。方案总结TCC事务机制相对于传统事务机制（X/Open XA），TCC事务机制相比于上面介绍的XA事务机制，有以下优点:性能提升具体业务来实现控制资源锁的粒度变小，不会锁定整个资源。数据最终一致性基于Confirm和Cancel的幂等性，保证事务最终完成确认或者取消，保证数据的一致性。可靠性解决了XA协议的协调者单点故障问题，由主业务方发起并控制整个业务活动，业务活动管理器也变成多点，引入集群。缺点：TCC的Try、Confirm和Cancel操作功能要按具体业务来实现，业务耦合度较高，提高了开发成本。实现方案","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.baiyp.ren/tags/分布式事务/"},{"name":"TCC","slug":"TCC","permalink":"http://www.baiyp.ren/tags/TCC/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}]},{"title":"Java多线程的同步","slug":"java多线程基础-04","date":"2019-07-19T23:23:07.000Z","updated":"2019-08-22T02:02:03.497Z","comments":true,"path":"java多线程基础-04.html","link":"","permalink":"http://www.baiyp.ren/java多线程基础-04.html","excerpt":"","text":"Java多线程的同步使用线程锁synchronized内置锁​ 线程开始运行，拥有自己的栈空间，就如同一个脚本一样，按照既定的代码一步一步地执行，直到终止。但是，每个运行中的线程，如果仅仅是孤立地运行，那么没有一点儿价值，或者说价值很少，如果多个线程能够相互配合完成工作，包括数据之间的共享，协同处理事情。这将会带来巨大的价值。​ Java支持多个线程同时访问一个对象或者对象的成员变量，关键字synchronized可以修饰方法或者以同步块的形式来进行使用，它主要确保多个线程在同一个时刻，只能有一个线程处于方法或者同步块中，它保证了线程对变量访问的可见性和排他性，又称为内置锁机制。对象锁和类锁​ 当一个对象中有synchronized method或synchronized block的时候调用此对象的同步方法或进入其同步区域时，就必须先获得对象锁。如果此对象的对象锁已被其他调用者占用，则需要等待此锁被释放，对象锁是用于对象实例方法，或者一个对象实例上的。同步静态方法/静态变量互斥体由于一个class不论被实例化多少次，其中的静态方法和静态变量在内存中都只由一份。所以，一旦一个静态的方法被申明为synchronized。此类所有的实例化对象在调用此方法，共用同一把锁，我们称之为类锁。一旦一个静态变量被作为synchronized block的mutex。进入此同步区域时，都要先获得此静态变量的对象锁​ 用于类的静态方法或者一个类的class对象上的。我们知道，类的对象实例可以有很多个，但是每个类只有一个class对象，所以不同对象实例的对象锁是互不干扰的，但是每个类只有一个类锁。​ 但是有一点必须注意的是，其实类锁只是一个概念上的东西，并不是真实存在的，类锁其实锁的是每个类的对应的class对象。类锁和对象锁之间也是互不干扰的。对象锁实例1123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * 方法锁 不同的方法可以并行的 */public class RunableTest &#123; public synchronized void test1() &#123; System.out.println(\"test111\"); &#125; public synchronized void test2() &#123; System.out.println(\"test222\"); &#125; public synchronized void test3() &#123; System.out.println(\"test333\"); &#125; public static void main(String[] args) &#123; RunableTest RunableTest = new RunableTest(); new Thread(() -&gt; &#123; while (true) &#123; sleep(1); RunableTest.test1(); &#125; &#125;).start(); new Thread(() -&gt; &#123; while (true) &#123; sleep(1); RunableTest.test2(); &#125; &#125;).start(); new Thread(() -&gt; &#123; while (true) &#123; sleep(1); RunableTest.test3(); &#125; &#125;).start(); &#125; public static void sleep(int sec) &#123; try &#123; Thread.sleep(sec * 1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;对象锁实例2123456789101112131415161718192021222324252627282930/** * 对象锁 用一个对象锁的话 先获取锁在执行 * 如果是多个对象可以并行的 */ private Object lock = new Object(); public void test1() &#123; synchronized (lock) &#123; sleep(1); System.out.println(\"test111\"); &#125; &#125; public void test2() &#123; synchronized (lock) &#123; sleep(1); System.out.println(\"test222\"); &#125; &#125; public void test3() &#123; synchronized (lock) &#123; sleep(1); System.out.println(\"test333\"); &#125; &#125;类锁1234567891011121314151617181920212223242526/** *类锁 用一个对象锁的话 先获取锁在执行 */public void test1() &#123; synchronized (RunableTest.class) &#123; sleep(1); System.out.println(\"test111\"); &#125; &#125; public void test2() &#123; synchronized (RunableTest.class) &#123; sleep(1); System.out.println(\"test222\"); &#125; &#125; public void test3() &#123; synchronized (RunableTest.class) &#123; sleep(1); System.out.println(\"test333\"); &#125; &#125;错误的加锁和原因分析​ 我们常常在程序中使用多线程来处理任务，这个时候是否正确使用加锁就很重要了，有时候看着代码没啥问题，但是执行起来发现结果并不是看到的那样，比如我们看下面的代码12345678910private Integer num = 0; public void test1() &#123; synchronized (num) &#123; sleep(1); num++; System.out.println(\"test111\"+Thread.currentThread().getId()); &#125; &#125;​ 这个时候我们再去看代码，我们对Integer对象num进行加锁，这个时候就有个一个Java基础知识在里面，Integer是不可变对象，是实例对象，对象一但被创建就不能被修改，比如赋值是1，就是1，如果让它变成2，需要重新创建一个Integer对象。12345678public void test1() &#123; synchronized(this.num) &#123; sleep(1); Integer var2 = this.num; Integer var3 = this.num = this.num + 1; System.out.println(\"test111\" + Thread.currentThread().getId()); &#125;&#125;​​ 然后下面循环中进行num++,其实这里Java对这个进行了内部转换（ Java封箱拆箱） ，其实是执行的这个语句java Integer var3 = this.num = this.num + 1;，我们看反编译后的代码，它会返回一个Integer实例，因此num ++本质是创建一个Integer对象，并将它的引用赋值给num 。本质上是返回了一个新的Integer对象。也就是每个线程实际加锁的是不同的Integer对象。volatile，最轻量的同步机制​ volatile保证了不同线程对这个变量进行操作时的可见性，即一个线程修改了某个变量的值，这新值对其他线程来说是立即可见的​ 不加volatile时，子线程无法感知主线程修改了ready的值，从而不会退出循环，而加了volatile后，子线程可以感知主线程修改了ready的值，迅速退出循环。但是volatile不能保证数据在多个线程下同时写时的线程安全volatile最适用的场景：一个线程写，多个线程读。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"多线程基础","slug":"多线程基础","permalink":"http://www.baiyp.ren/tags/多线程基础/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}]},{"title":"Java多线程更多了解","slug":"java多线程基础-03","date":"2019-07-17T23:23:07.000Z","updated":"2019-08-22T01:59:23.559Z","comments":true,"path":"java多线程基础-03.html","link":"","permalink":"http://www.baiyp.ren/java多线程基础-03.html","excerpt":"","text":"对Java里的线程再多一点点认识深入理解run()和start()​ Thread类是Java里对线程概念的抽象，可以这样理解：我们通过new Thread()其实只是new出一个Thread的实例，还没有操作系统中真正的线程挂起钩来。只有执行了start()方法后，才实现了真正意义上的启动线程。​ start()方法让一个线程进入就绪队列等待分配cpu，分到cpu后才调用实现的run()方法，start()方法不能重复调用，如果重复调用会抛出异常。​ 而run方法是业务逻辑实现的地方，本质上和任意一个类的任意一个成员方法并没有任何区别，可以重复执行，也可以被单独调用。其他的线程相关方法​ yield()方法：使当前线程让出CPU占有权，但让出的时间是不可设定的。也不会释放锁资源。注意：并不是每个线程都需要这个锁的，而且执行yield( )的线程不一定就会持有锁，我们完全可以在释放锁后再调用yield方法。所有执行yield()的线程有可能在进入到就绪状态后会被操作系统再次选中马上又被执行。wait()/notify()/notifyAll()：后面会单独讲述join方法​ 把指定的线程加入到当前线程，可以将两个交替执行的线程合并为顺序执行。比如在线程B中调用了线程A的Join()方法，直到线程A执行完毕后，才会继续执行线程B。(此处为常见面试考点)看个栗子12345678910111213141516171819202122232425Thread thread1 = new Thread(() -&gt; &#123; while(!Thread.currentThread().isInterrupted()) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"11111111111\"); &#125; &#125;); Thread thread2 = new Thread(() -&gt; &#123; while(!Thread.currentThread().isInterrupted()) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"222222222222\"); &#125; &#125;); thread1.start(); //在此处join 其他线程会等待thread1 执行完成后在执行thread2 thread1.join(); thread2.start();执行结果12345678910111213141516171111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111第二种情况12345... thread1.start(); thread2.start(); //在此处join 因为下面没有等待启动的线程，所以和不加thread1.join();一样，是交替执行的 thread1.join();执行结果1234567891011121311111111111111111111112222222222221111111111122222222222211111111111222222222222111111111112222222222222222222222221111111111111111111111222222222222线程的优先级​ 在Java线程中，通过一个整型成员变量priority来控制优先级，优先级的范围从1~10，在线程构建的时候可以通过setPriority(int)方法来修改优先级，默认优先级是5，优先级高的线程分配时间片的数量要多于优先级低的线程。​ 设置线程优先级时，针对频繁阻塞（休眠或者I/O操作）的线程需要设置较高优先级，而偏重计算（需要较多CPU时间或者偏运算）的线程则设置较低的优先级，确保处理器不会被独占。在不同的JVM以及操作系统上，线程规划会存在差异，有些操作系统甚至会忽略对线程优先级的设定。守护线程​ Daemon（守护）线程是一种支持型线程，因为它主要被用作程序中后台调度以及支持性工作。这意味着，当一个Java虚拟机中不存在非Daemon线程的时候，Java虚拟机将会退出。可以通过调用Thread.setDaemon(true)将线程设置为Daemon线程。我们一般用不上，比如垃圾回收线程就是Daemon线程。​ Daemon线程被用作完成支持性工作，但是在Java虚拟机退出时Daemon线程中的finally块并不一定会执行。在构建Daemon线程时，不能依靠finally块中的内容来确保执行关闭或清理资源的逻辑。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"多线程基础","slug":"多线程基础","permalink":"http://www.baiyp.ren/tags/多线程基础/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}]},{"title":"java流式计算Stream详解","slug":"java流式计算Stream详解","date":"2019-07-17T09:57:36.000Z","updated":"2019-08-22T02:02:29.923Z","comments":true,"path":"java流式计算Stream详解.html","link":"","permalink":"http://www.baiyp.ren/java流式计算Stream详解.html","excerpt":"","text":"java流式计算Stream详解Stream 是什么​ Stream是Java 8新增的重要特性, 它提供函数式编程支持并允许以管道方式操作集合. 流操作会遍历数据源, 使用管道式操作处理数据后生成结果集合, 这个过程通常不会对数据源造成影响.函数对象​ 使用Stream进行函数式编程时经常需要将操作作为参数传入流方法中, 函数对象即将方法或lambda表达式作为对象。1List&lt;String&gt; strArray = Arrays.asList(stringArrays).stream().filter(x&gt;x.contains(\"Tomas\")).collect(Collectors.toList());上述示例中filter的参数x&gt;x.contains(&quot;Tomas&quot;)即为一个lambda表达式.流的创建可以使用集合类的stream()或者parallelStream()方法创建流:12Stream&lt;Integer&gt; stream1 = Arrays.asList(1,2,3,4).stream();Stream&lt;Integer&gt; stream2 = Arrays.asList(1,2,3,4).parallelStream();java.util.stream.Stream是一个interface, 各种管道中间操作的返回值都是它的实现类, 这允许我们方便地进行参数传递。Stream的静态方法of()也可以用来创建流:1Stream&lt;String&gt; stream3 = Stream.of(new String[]&#123;\"1\",\"2\",\"3\",\"4\"&#125;);`Arrays也提供了创建流的静态方法stream()`:1Arrays.stream(new int[]&#123;1,2,3&#125;)一些类也提供了创建流的方法:123IntStream.range(start, stop);BufferedReader.lines();Random.ints();中间操作​ 流操作是惰性执行的, 中间操作会返回一个新的流对象, 当执行终点操作时才会真正进行计算，下面介绍流的中间操作，除非传入的操作函数有副作用, 函数本身不会对数据源进行任何修改。distinctdistinct保证数据源中的重复元素在结果中只出现一次, 它使用equals()方法判断两个元素是否相等.12Stream&lt;String&gt; stream3 = Stream.of(new String[]&#123;\"1\", \"2\", \"3\", \"4\", \"1\", \"2\", \"3\", \"4\"&#125;);System.out.println(stream3.distinct().collect(Collectors.toList()));输出[1, 2, 3, 4]filterfilter根据传入的断言函数对所有元素进行检查, 只有使断言函数返回真的元素才会出现在结果中. filter不会对数据源进行修改.123Stream&lt;String&gt; stream3 = Stream.of(new String[]&#123;\"1\", \"2\", \"3\", \"4\", \"6\", \"7\", \"8\", \"9\"&#125;);List&lt;String&gt; stringList = stream3.filter(x-&gt; Integer.parseInt(x)%2==0).collect(Collectors.toList());System.out.println(stringList);输出[2, 4, 6, 8]map​ map方法根据传入的mapper函数对元素进行一对一映射, 即数据源中的每一个元素都会在结果中被替换(映射)为mapper函数的返回值，也可以根据处理返回不同的数据类型。123Stream&lt;String&gt; stream3 = Stream.of(new String[]&#123;\"1\", \"2\", \"3\", \"4\", \"6\", \"7\", \"8\", \"9\"&#125;);List&lt;Integer&gt; integerList = stream3.map(x -&gt; Integer.parseInt(x)).collect(Collectors.toList());System.out.println(integerList);输出[1, 2, 3, 4, 6, 7, 8, 9]peek​ peek方法会对数据源中所有元素进行给定操作, 但在结果中仍然是数据源中的元素. 通常我们利用操作的副作用, 修改其它数据或进行输入输出.​ peek接收一个没有返回值的λ表达式，可以做一些输出，外部处理等。map接收一个有返回值的λ表达式，之后Stream的泛型类型将转换为map参数λ表达式返回的类型123Stream&lt;Integer&gt; stream3 = Stream.of(1,2,3,4,5,6,7,8,9);List&lt;Integer&gt; integerList = stream3.peek(x-&gt; System.out.println(x)).collect(Collectors.toList());System.out.println(integerList);输出1 …[1, 2, 3, 4, 5, 6, 7, 8, 9]flatMap与map不同flatMap进行多对一映射, 它要求若数据源的元素类型为R, 则mapper函数的返回值必须为Stream&lt;R&gt;.flatMap会使用mapper函数将数据源中的元素一一映射为Stream对象, 然后把这些Stream拼装成一个流.因此我们可以使用flatMap进行合并列表之类的操作:123Stream&lt;List&lt;Integer&gt;&gt; stream3 = Stream.of(Arrays.asList(1), Arrays.asList(2, 3), Arrays.asList(4, 5, 6));List&lt;Integer&gt; integerList = stream3.flatMap(x-&gt;x.stream()).collect(Collectors.toList());System.out.println(integerList);输出[1, 2, 3, 4, 5, 6]sortedsorted方法用于对数据源进行排序:123Stream&lt;Integer&gt; stream3 = Stream.of(4, 5, 2, 6, 9, 0, 1, 3, 6, 8); List&lt;Integer&gt; integerList = stream3.sorted((x, y) -&gt; x - y).collect(Collectors.toList());System.out.println(integerList);输出[0, 1, 2, 3, 4, 5, 6, 6, 8, 9]使用java.util.Comparator是更方便的方法, 默认进行升序排序:12345678910111213141516class Item &#123; public Item(int value) &#123; this.value = value; &#125; private int value; public int getValue() &#123; return value; &#125; public void setValue(int value) &#123; this.value = value; &#125; &#125;Stream&lt;Item&gt; stream3 = Stream.of(new Item(4), new Item(3), new Item(6), new Item(9));List&lt;Item&gt; itemList = stream3.sorted(Comparator.comparingInt(Item::getValue)).collect(Collectors.toList());itemList.forEach(x -&gt; System.out.print(x.getValue()+\",\"));输出3,4,6,9,使用reversed()方法进行降序排序:123Stream&lt;Item&gt; stream3 = Stream.of(new Item(4), new Item(3), new Item(6), new Item(9));List&lt;Item&gt; itemList = stream3.sorted(Comparator.comparingInt(Item::getValue).reversed()).collect(Collectors.toList());itemList.forEach(x -&gt; System.out.print(x.getValue()+\",\"));输出9,6,4,3,limitlimit(int n)当流中元素数大于n时丢弃超出的元素, 否则不进行处理, 达到限制流长度的目的.123Stream&lt;Integer&gt; stream3 = Stream.of(3,5,1,4,2,6,8,7);List&lt;Integer&gt; integerList = stream3.limit(3).collect(Collectors.toList());System.out.println(integerList);输出[3, 5, 1]skipskip(int)返回丢弃了前n个元素的流. 如果流中的元素小于或者等于n，则返回空的流123Stream&lt;Integer&gt; stream3 = Stream.of(3,5,1,4,2,6,8,7);List&lt;Integer&gt; integerList = stream3.skip(3).collect(Collectors.toList());System.out.println(integerList);输出[4, 2, 6, 8, 7]终点操作reducereduce(accumulator)是最基本的终点操作之一, 操作函数accumulator接受两个参数x,y返回r.reduce首先将数据源中的两个元素x1和x2传给accumulator得到r1, 然后将r1和x3传入得到r2. 如此进行直到处理完整个数据流.reduce方法还可以接受一个参数代替x1作为起始值:collectcollect是使用最广泛的终点操作, 也上文中多次出现:123List&lt;String&gt; list = Stream.of(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;,&quot;b&quot;) .distinct() .collect(Collectors.toList())toList()将流转换为List实例, 是最常见的用法, java.util.Collectors类中还有求和, 计算均值, 取最值, 字符串连接等多种收集方法.forEachforEach方法对流中所有元素执行给定操作, 没有返回值.1Stream.of(1,2,3,4,5).forEach(System.out::println);其它count() 返回流中的元素数toArray(): 转换为数组并发问题除非显式地创建并行流, 否则默认创建的都是串行流.Collection.stream()为集合创建串行流,而Collection.parallelStream()创建并行流.stream.parallel()方法可以将串行流转换成并行流,stream.sequential()方法将流转换成串行流.12Stream&lt;Integer&gt; stream3 = Stream.of(1,2,3,4,5,6,7,8,9);stream3.forEach(x-&gt; System.out.print(x+\",\"));输出1,2,3,4,5,6,7,8,9,流可以在非线程安全的集合上创建, 流操作不应该对非线程安全的数据源产生任何副作用, 否则将发生java.util.ConcurrentModificationException异常.12List&lt;String&gt; list = new ArrayList(Arrays.asList(&quot;x&quot;, &quot;y&quot;));list.stream().forEach(x-&gt; list.add(&quot;z&quot;));输出1234Exception in thread \"main\" java.util.ConcurrentModificationException at java.util.ArrayList$ArrayListSpliterator.forEachRemaining(ArrayList.java:1388) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at com.test.lambda.LambdaTest.main(LambdaTest.java:15)对于线程安全的容器不会存在这个问题:12345List&lt;String&gt; list = new CopyOnWriteArrayList(Arrays.asList(\"x\", \"y\"));list.stream().forEach(x-&gt;&#123; list.add(\"z\"); System.out.println(list);&#125;);输出[x, y, z][x, y, z, z]当然作者建议Stream操作不要对数据源进行任何修改. 当然, 修改其它数据或者输入输出是允许的:12345Set&lt;String&gt; set = new HashSet&lt;String&gt;();List&lt;String&gt; list = new CopyOnWriteArrayList(Arrays.asList(\"x\", \"y\"));list.stream().forEach(x-&gt;&#123; set.add(x);&#125;);理想的管道操作应该是无状态且与访问顺序无关的. 无状态是指操作的结果只与输入有关, 下面即是一个有状态的操作示例:12345678910State state = getState();List&lt;String&gt; list = new ArrayList(Arrays.asList(\"a\", \"b\"));list = list.stream().map(s -&gt; &#123; if (state.isReady()) &#123; return s; &#125; else &#123; return null; &#125;&#125;);无状态的操作保证无论系统状态如何管道的行为不变, 与顺序无关则有利于进行并行计算.函数式接口函数式接口会将签名匹配的函数对象(lambda表达式或方法)视作接口的实现。12345@FunctionalInterfaceinterface Greeter&#123; void hello(String message);&#125;函数式接口中有且只有一个非抽象方法。1Greeter greeter = message -&gt; System.out.println(\"Hello \" + message);这在 Java 8 之前通常使用匿名内部类实现的:123456Greeter greeter = new Greeter() &#123; @Override public void hello(String message) &#123; System.out.println(\"Hello \" + message); &#125; &#125;;Java 8 将已有的一些接口实现为函数式接口:java.lang.Runnablejava.util.concurrent.Callablejava.util.Comparatorjava.lang.reflect.InvocationHandlerjava.io.FileFilterjava.nio.file.PathMatcherjava.util.function中定义了一些常用的函数式接口:Consumer: 接受参数无返回Consumer&lt;T&gt; -&gt; void accept(T t);BiConsumer&lt;T,U&gt; -&gt; void accept(T t, U u);DoubleConsumer -&gt; void accept(double value);Supplier: 不接受参数有返回Supplier&lt;T&gt; -&gt; T get();DoubleSupplier -&gt; double getAsDouble();Function: 接受参数并返回Function&lt;T, R&gt; -&gt; R apply(T t);BiFunction&lt;T, U, R&gt; -&gt; R apply(T t, U u);DoubleFunction&lt;R&gt; -&gt; R apply(double value);DoubleToIntFunction -&gt; int applyAsInt(double value);BinaryOperator&lt;T&gt; extends BiFunction&lt;T,T,T&gt;Predicate: 接受参数返回booleanPredicate&lt;T&gt; -&gt; boolean test(T t);BiPredicate&lt;T, U&gt; -&gt; boolean test(T t, U u);DoublePredicate -&gt; boolean test(double value);默认构造器可以作为supplier: Supplier&lt;Item&gt; supplier = Item::new;","categories":[{"name":"流式计算","slug":"流式计算","permalink":"http://www.baiyp.ren/categories/流式计算/"},{"name":"stream","slug":"流式计算/stream","permalink":"http://www.baiyp.ren/categories/流式计算/stream/"}],"tags":[{"name":"流式计算","slug":"流式计算","permalink":"http://www.baiyp.ren/tags/流式计算/"},{"name":"stream","slug":"stream","permalink":"http://www.baiyp.ren/tags/stream/"}],"keywords":[{"name":"流式计算","slug":"流式计算","permalink":"http://www.baiyp.ren/categories/流式计算/"},{"name":"stream","slug":"流式计算/stream","permalink":"http://www.baiyp.ren/categories/流式计算/stream/"}]},{"title":"JAVA中的分布式事务02-2PC(二阶段提交)","slug":"JAVA中的分布式事务02","date":"2019-07-17T02:05:25.000Z","updated":"2019-08-22T02:08:35.193Z","comments":true,"path":"JAVA中的分布式事务02.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的分布式事务02.html","excerpt":"","text":"JAVA中的分布式事务02-2PC(二阶段提交)方案简介​ 二阶段提交协议（Two-phase Commit，即2PC）是常用的分布式事务解决方案，即将事务的提交过程分为两个阶段来进行处理：准备阶段和提交阶段。事务的发起者称协调者，事务的执行者称参与者。​ 在分布式系统里，每个节点都可以知晓自己操作的成功或者失败，却无法知道其他节点操作的成功或失败。当一个事务跨多个节点时，为了保持事务的原子性与一致性，而引入一个协调者来统一掌控所有参与者的操作结果，并指示它们是否要把操作结果进行真正的提交或者回滚（rollback）。​ 二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。​ 核心思想就是对每一个事务都采用先尝试后提交的处理方式，处理后所有的读操作都要能获得最新的数据，因此也可以将二阶段提交看作是一个强一致性算法。处理流程简单一点理解，可以把协调者节点比喻为带头大哥，参与者理解比喻为跟班小弟，带头大哥统一协调跟班小弟的任务执行。阶段1：准备阶段1、协调者向所有参与者发送事务内容，询问是否可以提交事务，并等待所有参与者答复。2、各参与者执行事务操作，将undo和redo信息记入事务日志中（但不提交事务）。3、如参与者执行成功，给协调者反馈yes，即可以提交；如执行失败，给协调者反馈no，即不可提交。阶段2：提交阶段​ 如果协调者收到了参与者的失败消息或者超时，直接给每个参与者发送回滚(rollback)消息；否则，发送提交(commit)消息；参与者根据协调者的指令执行提交或者回滚操作，释放所有事务处理过程中使用的锁资源。(注意:必须在最后阶段释放锁资源)接下来分两种情况分别讨论提交阶段的过程。情况1，当所有参与者均反馈yes，提交事务：1、协调者向所有参与者发出正式提交事务的请求（即commit请求）。2、参与者执行commit请求，并释放整个事务期间占用的资源。3、各参与者向协调者反馈ack(应答)完成的消息。4、协调者收到所有参与者反馈的ack消息后，即完成事务提交。情况2，当任何阶段1一个参与者反馈no，中断事务：1、协调者向所有参与者发出回滚请求（即rollback请求）。2、参与者使用阶段1中的undo信息执行回滚操作，并释放整个事务期间占用的资源。3、各参与者向协调者反馈ack完成的消息。4、协调者收到所有参与者反馈的ack消息后，即完成事务中断。方案总结2PC方案实现起来简单，实际项目中使用比较少，主要因为以下问题：性能问题所有参与者在事务提交阶段处于同步阻塞状态，占用系统资源，容易导致性能瓶颈。可靠性问题如果协调者存在单点故障问题，如果协调者出现故障，参与者将一直处于锁定状态。数据一致性问题在阶段2中，如果发生局部网络问题，一部分事务参与者收到了提交消息，另一部分事务参与者没收到提交消息，那么就导致了节点之间数据的不一致。只适用于单个服务中因为使用了XA规范，只支持单体服务的跨库分布式事务，不支持跨服务间的分布式事务。实现方案","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.baiyp.ren/tags/分布式事务/"},{"name":"2PC","slug":"2PC","permalink":"http://www.baiyp.ren/tags/2PC/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}]},{"title":"JAVA中的分布式事务03-3PC(三阶段提交)","slug":"JAVA中的分布式事务03","date":"2019-07-17T02:05:25.000Z","updated":"2019-08-22T02:08:58.320Z","comments":true,"path":"JAVA中的分布式事务03.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的分布式事务03.html","excerpt":"","text":"JAVA中的分布式事务03-3PC(三阶段提交)方案简介​ 三阶段提交协议，是二阶段提交协议的改进版本，与二阶段提交不同的是，引入超时机制。同时在协调者和参与者中都引入超时机制。​ 三阶段提交将二阶段的准备阶段拆分为2个阶段，插入了一个preCommit阶段，使得原先在二阶段提交中，参与者在准备之后，由于协调者发生崩溃或错误，而导致参与者处于无法知晓是否提交或者中止的“不确定状态”所产生的可能相当长的延时的问题得以解决。处理流程阶段1：canCommit​ 协调者向参与者发送commit请求，参与者如果可以提交就返回yes响应(参与者不执行事务操作)，否则返回no响应：1、协调者向所有参与者发出包含事务内容的canCommit请求，询问是否可以提交事务，并等待所有参与者答复。2、参与者收到canCommit请求后，如果认为可以执行事务操作，则反馈yes并进入预备状态，否则反馈no。阶段2：preCommit​ 协调者根据阶段1 canCommit参与者的反应情况来决定是否可以基于事务的preCommit操作。根据响应情况，有以下两种可能。情况1，阶段1所有参与者均反馈yes，参与者预执行事务：1、协调者向所有参与者发出preCommit请求，进入准备阶段。2、参与者收到preCommit请求后，执行事务操作，将undo和redo信息记入事务日志中（但不提交事务）。3、各参与者向协调者反馈ack响应或no响应，并等待最终指令。情况2，阶段1任何一个参与者反馈no，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务:1、协调者向所有参与者发出abort请求。2、无论收到协调者发出的abort请求，或者在等待协调者请求过程中出现超时，参与者均会中断事务。阶段3：do Commit该阶段进行真正的事务提交，也可以分为以下两种情况：情况1：阶段2所有参与者均反馈ack响应，执行真正的事务提交：1、如果协调者处于工作状态，则向所有参与者发出do Commit请求。2、参与者收到do Commit请求后，会正式执行事务提交，并释放整个事务期间占用的资源。3、各参与者向协调者反馈ack完成的消息。4、协调者收到所有参与者反馈的ack消息后，即完成事务提交。阶段2任何一个参与者反馈no，或者等待超时后协调者尚无法收到所有参与者的反馈，即中断事务：1、如果协调者处于工作状态，向所有参与者发出abort请求。2、参与者使用阶段1中的undo信息执行回滚操作，并释放整个事务期间占用的资源。3、各参与者向协调者反馈ack完成的消息。4、协调者收到所有参与者反馈的ack消息后，即完成事务中断注意：进入阶段3后，无论协调者出现问题，或者协调者与参与者网络出现问题，都会导致参与者无法接收到协调者发出的do Commit请求或abort请求。此时，参与者都会在等待超时之后，继续执行事务提交。阶段三 只允许成功不允许失败，如果服务器宕机或者停电，因为记录的阶段二的数据，重启服务后在提交事务，所以，到了阶段三，失败了也不进行回滚，只允许成功，死也要活过来之后再执行。方案总结优点相比二阶段提交，三阶段贴近降低了阻塞范围，在等待超时后协调者或参与者会中断事务。避免了协调者单点问题，阶段3中协调者出现问题时，参与者会继续提交事务。缺点数据不一致问题依然存在，当在参与者收到preCommit请求后等待do commite指令时，此时如果协调者请求中断事务，而协调者无法与参与者正常通信，会导致参与者继续提交事务，造成数据不一致。实现方案","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.baiyp.ren/tags/分布式事务/"},{"name":"3PC","slug":"3PC","permalink":"http://www.baiyp.ren/tags/3PC/"},{"name":"三阶段提交","slug":"三阶段提交","permalink":"http://www.baiyp.ren/tags/三阶段提交/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}]},{"title":"认识Java里的线程","slug":"java多线程基础-02","date":"2019-07-14T23:23:07.000Z","updated":"2019-08-22T05:02:38.325Z","comments":true,"path":"java多线程基础-02.html","link":"","permalink":"http://www.baiyp.ren/java多线程基础-02.html","excerpt":"","text":"认识Java里的线程Java程序天生就是多线程的​ 一个Java程序从main()方法开始执行，然后按照既定的代码逻辑执行，看似没有其他线程参与，但实际上Java程序天生就是多线程程序，因为执行main()方法的是一个名称为main的线程。[6] Monitor Ctrl-Break //监控Ctrl-Break中断信号的[5] Attach Listener //内存dump，线程dump，类信息统计，获取系统属性等[4] Signal Dispatcher // 分发处理发送给JVM信号的线程[3] Finalizer // 调用对象finalize方法的线程[2] Reference Handler//清除Reference的线程[1] main //main线程，用户程序入口线程的启动与中止启动启动线程的方式有：1、X extends Thread;，然后X.start123456789101112public class ThreadTest extends Thread &#123; @Override public void run() &#123; //todo 处理业务 System.out.println(\"xxxxxxxxxxxxx\"); &#125; public static void main(String[] args) &#123; new ThreadTest().start(); &#125;&#125;2、X implements Runnable；然后交给Thread运行12345678910111213public class RunableTest implements Runnable &#123; @Override public void run() &#123; //todo 处理业务 System.out.println(\"xxxxxxxxxxxxx\"); &#125; public static void main(String[] args) &#123; RunableTest runableTest = new RunableTest(); new Thread(runableTest).start(); &#125;&#125;Thread和Runnable的区别​ Thread才是Java里对线程的唯一抽象，Runnable只是对任务（业务逻辑）的抽象。Thread可以接受任意一个Runnable的实例并执行。中止线程自然终止要么是run执行完成了，要么是抛出了一个未处理的异常导致线程提前结束。stop​ 暂停、恢复和停止操作对应在线程Thread的API就是suspend()、resume()和stop()。但是这些API是过期的，也就是不建议使用的。不建议使用的原因主要有：以suspend()方法为例，在调用后，线程不会释放已经占有的资源（比如锁），而是占有着资源进入睡眠状态，这样容易引发死锁问题。同样，stop()方法在终结一个线程时不会保证线程的资源正常释放，通常是没有给予线程完成资源释放工作的机会，因此会导致程序可能工作在不确定状态下。正因为suspend()、resume()和stop()方法带来的副作用，这些方法才被标注为不建议使用的过期方法。中断​ 安全的中止则是其他线程通过调用某个线程A的interrupt()方法对其进行中断操作, 中断好比其他线程对该线程打了个招呼，“A，你要中断了”，不代表线程A会立即停止自己的工作，同样的A线程完全可以不理会这种中断请求。因为java里的线程是协作式的，不是抢占式的。线程通过检查自身的中断标志位是否被置为true来进行响应，​ 线程通过方法isInterrupted()来进行判断是否被中断，也可以调用静态方法Thread.interrupted()来进行判断当前线程是否被中断，不过Thread.interrupted()会同时将中断标识位改写为false。​ 如果一个线程处于了阻塞状态（如线程调用了thread.sleep、thread.join、thread.wait等），则在线程在检查中断标示时如果发现中断标示为true，则会在这些阻塞方法调用处抛出InterruptedException异常，并且在抛出异常后会立即将线程的中断标示位清除，即重新设置为false。​ 不建议自定义一个取消标志位来中止线程的运行。因为run方法里有阻塞调用时会无法很快检测到取消标志，线程必须从阻塞调用返回后，才会检查这个取消标志。这种情况下，使用中断会更好，因为，一般的阻塞方法，如sleep等本身就支持中断的检查，检查中断位的状态和检查取消标志位没什么区别，用中断位的状态还可以避免声明取消标志位，减少资源的消耗。注意：处于死锁状态的线程无法被中断样例代码1234567891011121314151617181920212223242526public class RunableTest implements Runnable &#123; private int i = 0; @Override public void run() &#123; while (!Thread.currentThread().isInterrupted()) &#123; i++; //todo 处理业务 System.out.println(\"xxxxxxxxxxxxx\"); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (i &gt; 10) &#123; Thread.currentThread().interrupt(); &#125; &#125; &#125; public static void main(String[] args) &#123; RunableTest runableTest = new RunableTest(); new Thread(runableTest).start(); &#125;&#125;","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"多线程基础","slug":"多线程基础","permalink":"http://www.baiyp.ren/tags/多线程基础/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}]},{"title":"JAVA中的分布式事务01-简介","slug":"JAVA中的分布式事务01","date":"2019-07-13T02:05:25.000Z","updated":"2019-08-22T02:08:46.182Z","comments":true,"path":"JAVA中的分布式事务01.html","link":"","permalink":"http://www.baiyp.ren/JAVA中的分布式事务01.html","excerpt":"","text":"JAVA中的分布式事务01-简介事务的具体定义​ 事务提供一种机制将一个活动涉及的所有操作纳入到一个不可分割的执行单元，组成事务的所有操作只有在所有操作均能正常执行的情况下方能提交，只要其中任一操作执行失败，都将导致整个事务的回滚。简单地说，事务提供一种“要么什么都不做，要么做全套（All or Nothing）”机制数据库本地事务说到数据库事务就不得不说，数据库事务中的四大特性，ACIDA:原子性(Atomicity)​ 一个事务(transaction)中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。​ 就像你买东西要么交钱收货一起都执行，要么要是发不出货，就退钱。C:一致性(Consistency)​ 事务的一致性指的是在一个事务执行之前和执行之后数据库都必须处于一致性状态。如果事务成功地完成，那么系统中所有变化将正确地应用，系统处于有效状态。如果在事务中出现错误，那么系统中的所有变化将自动地回滚，系统返回到原始状态。I:隔离性(Isolation)​ 指的是在并发环境中，当不同的事务同时操纵相同的数据时，每个事务都有各自的完整数据空间。由并发事务所做的修改必须与任何其他并发事务所做的修改隔离。事务查看数据更新时，数据所处的状态要么是另一事务修改它之前的状态，要么是另一事务修改它之后的状态，事务不会查看到中间状态的数据。打个比方，你买东西这个事情，是不影响其他人的D:持久性(Durability)​ 指的是只要事务成功结束，它对数据库所做的更新就必须永久保存下来。即使发生系统崩溃，重新启动数据库系统后，数据库还能恢复到事务成功结束时的状态。打个比方，你买东西的时候需要记录在账本上，即使老板忘记了那也有据可查。简单而言，ACID是从不同维度描述事务的特性：原子性 —— 事务操作的整体性一致性 —— 事务操作下数据的正确性隔离性 —— 事务并发操作下数据的正确性持久性 —— 事务对数据修改的可靠性一个支持事务（Transaction）的数据库，需要具有这4种特性，否则在事务过程当中无法保证数据的正确性，处理结果极可能达不到请求方的要求。什么时候使用数据库事务​ 在介绍完事务基本概念之后，什么时候该使用数据库事务？简单而言，就是业务上有一组数据操作，需要如果其中有任何一个操作执行失败，整组操作全部不执行并恢复到未执行状态，要么全部成功，要么全部失败。​ 在使用数据库事务时需要注意，尽可能短的保持事务，修改多个不同表的数据的冗长事务会严重妨碍系统中的所有其他用户，这很有可能导致一些性能问题。什么是分布式事务分布式产生背景与概念​ 随着互联网快速发展，微服务，SOA等服务架构模式正在被大规模的使用，现在分布式系统一般由多个独立的子系统组成，多个子系统通过网络通信互相协作配合完成各个功能。​ 有很多用例会跨多个子系统才能完成，比较典型的是电子商务网站的下单支付流程，至少会涉及交易系统和支付系统，而且这个过程中会涉及到事务的概念，即保证交易系统和支付系统的数据一致性，此处我们称这种跨系统的事务为分布式事务，具体一点而言，分布式事务是指事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。举个互联网常用的交易业务为例：​ 上图中包含了库存和订单两个独立的微服务，每个微服务维护了自己的数据库。在交易系统的业务逻辑中，一个商品在下单之前需要先调用库存服务，进行扣除库存，再调用订单服务，创建订单记录。可以看到，如果多个数据库之间的数据更新没有保证事务，将会导致出现子系统数据不一致，业务出现问题。分布式事务的难点事务的原子性事务操作跨不同节点，当多个节点某一节点操作失败时，需要保证多节点操作的**要么什么都不做，要么做全套（All or Nothing）**的原子性。事务的一致性​ 当发生网络传输故障或者节点故障，节点间数据复制通道中断，在进行事务操作时需要保证数据一致性，保证事务的任何操作都不会使得数据违反数据库定义的约束、触发器等规则。事务的隔离性​ 事务隔离性的本质就是如何正确多个并发事务的处理的读写冲突和写写冲突，因为在分布式事务控制中，可能会出现提交不同步的现象，这个时候就有可能出现“部分已经提交”的事务。此时并发应用访问数据如果没有加以控制，有可能出现“脏读”问题。分布式系统的一致性​ 前面介绍到的分布式事务的难点涉及的问题，最终影响是导致数据出现不一致，下面对分布式系统的一致性问题进行理论分析，后面将基于这些理论进行分布式方案的介绍。可用性和一致性的冲突 —— CAP理论​ CAP 定理又被称作布鲁尔定理，是加州大学的计算机科学家布鲁尔在 2000 年提出的一个猜想。2002 年，麻省理工学院的赛斯·吉尔伯特和南希·林奇发表了布鲁尔猜想的证明，使之成为分布式计算领域公认的一个定理。​ 布鲁尔在提出CAP猜想时并没有具体定义 Consistency、Availability、Partition Tolerance 这3个词的含义，不同资料的具体定义也有差别，为了更好地解释，下面选择Robert Greiner的文章《CAP Theorem》作为参考基础。CAP理论的定义在一个分布式系统（指互相连接并共享数据的节点的集合）中，当涉及读写操作时，只能保证一致性（Consistence）、可用性（Availability）、分区容错性（PartitionTolerance）三者中的两个，另外一个必须被牺牲。Consistency、Availability、Partition Tolerance具体解释如下：C - Consistency 一致性A read is guaranteed to return the most recent write for a given client.对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。​ 这里并不是强调同一时刻拥有相同的数据，对于系统执行事务来说，在事务执行过程中，系统其实处于一个不一致的状态，不同的节点的数据并不完全一致。​ 一致性强调客户端读操作能够获取最新的写操作结果，是因为事务在执行过程中，客户端是无法读取到未提交的数据的，只有等到事务提交后，客户端才能读取到事务写入的数据，而如果事务失败则会进行回滚，客户端也不会读取到事务中间写入的数据。A - Availability 可用性A non-failing node will return a reasonable response within a reasonable amount of time (no error or timeout).非故障的节点在合理的时间内返回合理的响应（不是错误和超时的响应）。​ 这里强调的是合理的响应，不能超时，不能出错。注意并没有说“正确”的结果，例如，应该返回 100 但实际上返回了 90，肯定是不正确的结果，但可以是一个合理的结果。P - Partition Tolerance 分区容忍性The system will continue to function when network partitions occur.当出现网络分区后，系统能够继续“履行职责”。这里网络分区是指：一个分布式系统里面，节点组成的网络本来应该是连通的。然而可能因为一些故障（节点间网络连接断开、节点宕机），使得有些节点之间不连通了，整个网络就分成了几块区域，数据就散布在了这些不连通的区域中。一致性、可用性、分区容忍性的选择​ 虽然 CAP 理论定义是三个要素中只能取两个，但放到分布式环境下来思考，我们会发现必须选择 P（分区容忍）要素，因为网络本身无法做到 100% 可靠，有可能出故障，所以分区是一个必然的现象。​ 如果我们选择了 CA（一致性 + 可用性） 而放弃了 P（分区容忍性），那么当发生分区现象时，为了保证 C（一致性），系统需要禁止写入，当有写入请求时，系统返回 error（例如，当前系统不允许写入），这又和 A(可用性) 冲突了，因为 A（可用性）要求返回 no error 和 no timeout。因此，分布式系统理论上不可能选择 CA （一致性 + 可用性）架构，只能选择 CP（一致性 + 分区容忍性） 或者 AP （可用性 + 分区容忍性）架构，在一致性和可用性做折中选择。CP - Consistency + Partition Tolerance （一致性 + 分区容忍性）​ 如上图所示，因为Node1节点和Node2节点连接中断导致分区现象，Node1节点的数据已经更新到y，但是Node1 和 Node2 之间的复制通道中断，数据 y 无法同步到 Node2，Node2 节点上的数据还是旧数据x。​ 这时客户端C 访问 Node2 时，Node2 需要返回 Error，提示客户端 “系统现在发生了错误”，这种处理方式违背了可用性（Availability）的要求，因此 CAP 三者只能满足 CP。AP - Availability + Partition Tolerance （可用性 + 分区容忍性）​ 同样是Node2 节点上的数据还是旧数据x，这时客户端C 访问 Node2 时，Node2 将当前自己拥有的数据 x 返回给客户端 了，而实际上当前最新的数据已经是 y 了，这就不满足一致性（Consistency）的要求了，因此 CAP 三者只能满足 AP。​ 注意：这里 Node2 节点返回 x，虽然不是一个“正确”的结果，但是一个“合理”的结果，因为 x 是旧的数据，并不是一个错乱的值，只是不是最新的数据。​ 值得补充的是，CAP理论告诉我们分布式系统只能选择AP或者CP，但实际上并不是说整个系统只能选择AP或者CP，在 CAP 理论落地实践时，我们需要将系统内的数据按照不同的应用场景和要求进行分类，每类数据选择不同的策略（CP 还是 AP），而不是直接限定整个系统所有数据都是同一策略。​ 另外，只能选择CP或者AP是指系统发生分区现象时无法同时保证C（一致性）和A（可用性），但不是意味着什么都不做，当分区故障解决后，系统还是要保持保证CA。CAP理论的延伸——BASE理论​ BASE 是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency），核心思想是即使无法做到强一致性（CAP 的一致性就是强一致性），但应用可以采用适合的方式达到最终一致性。BA - Basically Available 基本可用分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。​ 这里的关键词是“部分”和“核心”，实际实践上，哪些是核心需要根据具体业务来权衡。例如登录功能相对注册功能更加核心，注册不了最多影响流失一部分用户，如果用户已经注册但无法登录，那就意味用户无法使用系统，造成的影响范围更大。S - Soft State 软状态​ 允许系统存在中间状态，而该中间状态不会影响系统整体可用性。这里的中间状态就是 CAP 理论中的数据不一致。E - Eventual Consistency 最终一致性系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。​ 这里的关键词是“一定时间” 和 “最终”，“一定时间”和数据的特性是强关联的，不同业务不同数据能够容忍的不一致时间是不同的。例如支付类业务是要求秒级别内达到一致，因为用户时时关注；用户发的最新微博，可以容忍30分钟内达到一致的状态，因为用户短时间看不到明星发的微博是无感知的。而“最终”的含义就是不管多长时间，最终还是要达到一致性的状态。BASE 理论本质上是对 CAP 的延伸和补充，更具体地说，是对 CAP 中 AP 方案的一个补充：CP 理论是忽略延时的，而实际应用中延时是无法避免的。这一点就意味着完美的 CP 场景是不存在的，即使是几毫秒的数据复制延迟，在这几毫秒时间间隔内，系统是不符合 CP 要求的。因此 CAP 中的 CP 方案，实际上也是实现了最终一致性，只是“一定时间”是指几毫秒而已。AP 方案中牺牲一致性只是指发生分区故障期间，而不是永远放弃一致性。这一点其实就是 BASE 理论延伸的地方，分区期间牺牲一致性，但分区故障恢复后，系统应该达到最终一致性。数据一致性模型前面介绍的BASE模型提过“强一致性”和“最终一致性”，下面对这些一致性模型展开介绍。​ 分布式系统通过复制数据来提高系统的可靠性和容错性，并且将数据的不同的副本存放在不同的机器上，由于维护数据副本的一致性代价很高，因此许多系统采用弱一致性来提高性能，下面介绍常见的一致性模型：强一致性要求无论更新操作是在哪个数据副本上执行，之后所有的读操作都要能获得最新的数据。对于单副本数据来说，读写操作是在同一数据上执行的，容易保证强一致性。对多副本数据来说，则需要使用分布式事务协议。弱一致性在这种一致性下，用户读到某一操作对系统特定数据的更新需要一段时间，我们将这段时间称为&quot;不一致性窗口&quot;。最终一致性​ 是弱一致性的一种特例，在这种一致性下系统保证用户最终能够读取到某操作对系统特定数据的更新（读取操作之前没有该数据的其他更新操作）。”不一致性窗口”的大小依赖于交互延迟、系统的负载，以及数据的副本数等。总结​ 系统选择哪种一致性模型取决于应用对一致性的需求，所选取的一致性模型还会影响到系统如何处理用户的请求以及对副本维护技术的选择等。后面将基于上面介绍的一致性模型分别介绍分布式事务的解决方案。柔性事务柔性事务的概念​ 在电商等互联网场景下，传统的事务在数据库性能和处理能力上都暴露出了瓶颈。在分布式领域基于CAP理论以及BASE理论，有人就提出了柔性事务的概念。​ 基于BASE理论的设计思想，柔性事务下，在不影响系统整体可用性的情况下(Basically Available 基本可用)，允许系统存在数据不一致的中间状态(Soft State 软状态)，在经过数据同步的延时之后，最终数据能够达到一致。并不是完全放弃了ACID，而是通过放宽一致性要求，借助本地事务来实现最终分布式事务一致性的同时也保证系统的吞吐。实现柔性事务的一些特性下面介绍的是实现柔性事务的一些常见特性，这些特性在具体的方案中不一定都要满足，因为不同的方案要求不一样。可见性(对外可查询)​ 在分布式事务执行过程中，如果某一个步骤执行出错，就需要明确的知道其他几个操作的处理情况，这就需要其他的服务都能够提供查询接口，保证可以通过查询来判断操作的处理情况。​ 为了保证操作的可查询，需要对于每一个服务的每一次调用都有一个全局唯一的标识，可以是业务单据号（如订单号）、也可以是系统分配的操作流水号（如支付记录流水号）。除此之外，操作的时间信息也要有完整的记录。操作幂等性​ 幂等性，其实是一个数学概念。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。幂等操作的特点是其任意多次执行所产生的影响均与一次执行的影响相同。也就是说，同一个方法，使用同样的参数，调用多次产生的业务结果与调用一次产生的业务结果相同。​ 之所以需要操作幂等性，是因为为了保证数据的最终一致性，很多事务协议都会有很多重试的操作，如果一个方法不保证幂等，那么将无法被重试。幂等操作的实现方式有多种，如在系统中缓存所有的请求与处理结果、检测到重复操作后，直接返回上一次的处理结果等。常见分布式事务解决方案​ 介绍完分布式系统的一致性相关理论，下面基于不同的一致性模型介绍分布式事务的常见解决方案，后面会再介绍各个方案的使用场景。​ 分布式事务的实现有许多种，其中较经典是由Tuxedo提出的XA分布式事务协议，XA协议包含二阶段提交（2PC）和三阶段提交（3PC）两种实现。","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"分布式事务","slug":"分布式事务","permalink":"http://www.baiyp.ren/tags/分布式事务/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"分布式事务","slug":"架构/分布式事务","permalink":"http://www.baiyp.ren/categories/架构/分布式事务/"}]},{"title":"java多线程概述","slug":"java多线程基础-01","date":"2019-07-10T08:05:00.000Z","updated":"2019-08-22T02:01:45.258Z","comments":true,"path":"java多线程基础-01.html","link":"","permalink":"http://www.baiyp.ren/java多线程基础-01.html","excerpt":"","text":"多线程概述基础概念进程和线程进程是程序运行资源分配的最小单位​ 进程是操作系统进行资源分配的最小单位,其中资源包括:CPU、内存空间、磁盘IO等,同一进程中的多条线程共享该进程中的全部系统资源,而进程和进程之间是相互独立的。进程是具有一定独立功能的程序关于某个数据集合上的一次运行活动,进程是系统进行资源分配和调度的一个独立单位。​ 进程是程序在计算机上的一次执行活动。当你运行一个程序,你就启动了一个进程。显然,程序是死的、静态的,进程是活的、动态的。进程可以分为系统进程和用户进程。凡是用于完成操作系统的各种功能的进程就是系统进程,它们就是处于运行状态下的操作系统本身,用户进程就是所有由你启动的进程。线程是CPU调度的最小单位,必须依赖于进程而存在​ 线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的、能独立运行的基本单位。线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源。线程无处不在​ 任何一个程序都必须要创建线程,特别是Java不管任何程序都必须启动一个main函数的主线程; Java Web开发里面的定时任务、定时器、JSP和 Servlet、异步消息处理机制,远程访问接口RM等,任何一个监听事件, onclick的触发事件等都离不开线程和并发的知识。CPU核心数和线程数的关系​ 多核心:也指单芯片多处理器( Chip Multiprocessors,简称CMP),CMP是由美国斯坦福大学提出的,其思想是将大规模并行处理器中的SMP(对称多处理器)集成到同一芯片内,各个处理器并行执行不同的进程。这种依靠多个CPU同时并行地运行程序是实现超高速计算的一个重要方向,称为并行处理多线程: Simultaneous Multithreading.简称SMT.让同一个处理器上的多个线程同步执行并共享处理器的执行资源。核心数、线程数:目前主流CPU都是多核的。增加核心数目就是为了增加线程数,因为操作系统是通过线程来执行任务的,一般情况下它们是1:1对应关系,也就是说四核CPU一般拥有四个线程。但 Intel引入超线程技术后,使核心数与线程数形成1:2的关系CPU时间片轮转机制​ 我们平时在开发的时候，感觉并没有受cpu核心数的限制，想启动线程就启动线程，哪怕是在单核CPU上，为什么？这是因为操作系统提供了一种CPU时间片轮转机制。​ 时间片轮转调度是一种最古老、最简单、最公平且使用最广的算法,又称RR调度。每个进程被分配一个时间段,称作它的时间片,即该进程允许运行的时间。百度百科对CPU时间片轮转机制原理解释如下:​ 如果在时间片结束时进程还在运行,则CPU将被剥夺并分配给另一个进程。如果进程在时间片结束前阻塞或结来,则CPU当即进行切换。调度程序所要做的就是维护一张就绪进程列表,当进程用完它的时间片后,它被移到队列的末尾​ 时间片轮转调度中唯一有趣的一点是时间片的长度。从一个进程切换到另一个进程是需要定时间的,包括保存和装入寄存器值及内存映像,更新各种表格和队列等。假如进程切( processwitch),有时称为上下文切换( context switch),需要5ms,再假设时间片设为20ms,则在做完20ms有用的工作之后,CPU将花费5ms来进行进程切换。CPU时间的20%被浪费在了管理开销上了。​ 为了提高CPU效率,我们可以将时间片设为5000ms。这时浪费的时间只有0.1%。但考虑到在一个分时系统中,如果有10个交互用户几乎同时按下回车键,将发生什么情况?假设所有其他进程都用足它们的时间片的话,最后一个不幸的进程不得不等待5s才获得运行机会。多数用户无法忍受一条简短命令要5才能做出响应,同样的问题在一台支持多道程序的个人计算机上也会发​ 结论可以归结如下:时间片设得太短会导致过多的进程切换,降低了CPU效率:而设得太长又可能引起对短的交互请求的响应变差。将时间片设为100ms通常是一个比较合理的折衷。​ 在CPU死机的情况下,其实大家不难发现当运行一个程序的时候把CPU给弄到了100%再不重启电脑的情况下,其实我们还是有机会把它KILL掉的,我想也正是因为这种机制的缘故。澄清并行和并发​ 我们举个例子,如果有条高速公路A上面并排有8条车道,那么最大的并行车辆就是8辆此条高速公路A同时并排行走的车辆小于等于8辆的时候,车辆就可以并行运行。CPU也是这个原理,一个CPU相当于一个高速公路A,核心数或者线程数就相当于并排可以通行的车道;而多个CPU就相当于并排有多条高速公路,而每个高速公路并排有多个车道。当谈论并发的时候一定要加个单位时间,也就是说单位时间内并发量是多少?离开了单位时间其实是没有意义的。​ 俗话说,一心不能二用,这对计算机也一样,原则上一个CPU只能分配给一个进程,以便运行这个进程。我们通常使用的计算机中只有一个CPU,也就是说只有一颗心,要让它一心多用同时运行多个进程,就必须使用并发技术。实现并发技术相当复杂,最容易理解的是“时间片轮转进程调度算法”。综合来说：​ 并发:指应用能够交替执行不同的任务,比如单CPU核心下执行多线程并非是同时执行多个任务,如果你开两个线程执行,就是在你几乎不可能察觉到的速度不断去切换这两个任务,已达到”同时执行效果”,其实并不是的,只是计算机的速度太快,我们无法察觉到而已.​ 并行:指应用能够同时执行不同的任务,例:吃饭的时候可以边吃饭边打电话,这两件事情可以同时执行两者区别:一个是交替执行,一个是同时执行.高并发编程的意义、好处和注意事项​ 由于多核多线程的CPU的诞生,多线程、高并发的编程越来越受重视和关注。多线程可以给程序带来如下好处。1. 充分利用CPU的资源​ 从上面的CPU的介绍,可以看的出来,现在市面上没有CPU的内核不使用多线程并发机制的,特别是服务器还不止一个CPU,如果还是使用单线程的技术做思路,明显就out了。因为程序的基本调度单元是线程,并且一个线程也只能在一个CPU的一个核的一个线程跑,如果你是个i3的CPU的话,最差也是双核心4线程的运算能力:如果是一个线程的程序的话,那是要浪费3/4的CPU性能:如果设计一个多线程的程序的话,那它就可以同时在多个CPU的多个核的多个线程上跑,可以充分地利用CPU,减少CPU的空闲时间,发挥它的运算能力,提高并发量。​ 就像我们平时坐地铁一样,很多人坐长线地铁的时候都在认真看书,而不是为了坐地铁而坐地铁,到家了再去看书,这样你的时间就相当于有了两倍。这就是为什么有些人时间很充裕,而有些人老是说没时间的一个原因,工作也是这样,有的时候可以并发地去做几件事情,充分利用我们的时间,CPU也是一样,也要充分利用。2. 加快响应用户的时间​ 比如我们经常用的迅雷下载,都喜欢多开几个线程去下载,谁都不愿意用一个线程去下载,为什么呢?答案很简单,就是多个线程下载快啊。​ 我们在做程序开发的时候更应该如此,特别是我们做互联网项目,网页的响应时间若提升1s,如果流量大的话,就能增加不少转换量。做过高性能web前端调优的都知道,要将静态资源地址用两三个子域名去加载,为什么?因为每多一个子域名,浏览器在加载你的页面的时候就会多开几个线程去加载你的页面资源,提升网站的响应速度。多线程,高并发真的是无处不在。3. 可以使你的代码模块化,异步化,简单化​ 例如我们实现电商系统，下订单和给用户发送短信、邮件就可以进行拆分，将给用户发送短信、邮件这两个步骤独立为单独的模块，并交给其他线程去执行。这样既增加了异步的操作，提升了系统性能，又使程序模块化,清晰化和简单化。多线程应用开发的好处还有很多,大家在日后的代码编写过程中可以慢慢体会它的魅力。多线程程序需要注意事项1. 线程之间的安全性​ 从前面的章节中我们都知道,在同一个进程里面的多线程是资源共享的,也就是都可以访问同一个内存地址当中的一个变量。例如:若每个线程中对全局变量、静态变量只有读操作,而无写操作,一般来说,这个全局变量是线程安全的:若有多个线程同时执行写操作,一般都需要考虑线程同步,否则就可能影响线程安全。2. 线程之间的死锁​ 为了解决线程之间的安全性引入了Java的锁机制,而一不小心就会产生Java线程死锁的多线程问题,因为不同的线程都在等待那些根本不可能被释放的锁,从而导致所有的工作都无法完成。假设有两个线程,分别代表两个饥饿的人,他们必须共享刀叉并轮流吃饭。他们都需要获得两个锁:共享刀和共享叉的锁。假如线程A获得了刀,而线程B获得了叉。线程A就会进入阻塞状态来等待获得叉,而线程B则阻塞来等待线程A所拥有的刀。这只是人为设计的例子,但尽管在运行时很难探测到,这类情况却时常发生3. 线程太多了会将服务器资源耗尽形成死机当机​ 线程数太多有可能造成系统创建大量线程而导致消耗完系统内存以及CPU的“过渡切换”,造成系统的死机,那么我们该如何解决这类问题呢?​ 某些系统资源是有限的,如文件描述符。多线程程序可能耗尽资源,因为每个线程都可能希望有一个这样的资源。如果线程数相当大,或者某个资源的侯选线程数远远超过了可用的资源数则最好使用资源池。一个最好的示例是数据库连接池。只要线程需要使用一个数据库连接,它就从池中取出一个,使用以后再将它返回池中。资源池也称为资源库。多线程应用开发的注意事项很多,希望大家在日后的工作中可以慢慢体会它的危险所在。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"多线程基础","slug":"多线程基础","permalink":"http://www.baiyp.ren/tags/多线程基础/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"多线程基础","slug":"并发/多线程基础","permalink":"http://www.baiyp.ren/categories/并发/多线程基础/"}]},{"title":"java并发工具类-Fork-Join","slug":"java并发工具类-01","date":"2019-07-05T23:10:45.000Z","updated":"2019-08-22T02:03:22.543Z","comments":true,"path":"java并发工具类-01.html","link":"","permalink":"http://www.baiyp.ren/java并发工具类-01.html","excerpt":"","text":"java并发工具类-Fork-JoinFork-Join​ java下多线程的开发可以我们自己启用多线程，线程池，还可以使用forkjoin，forkjoin可以让我们不去了解诸如Thread,Runnable等相关的知识，只要遵循forkjoin的开发模式，就可以写出很好的多线程并发程序，Fork-Join 是什么​ Fork/Join框架是Java7提供了的一个用于并行执行任务的框架， 是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。分而治之​ “分而治之” 一直是一个有效的处理大量数据的方法。著名的 MapReduce 也是采取了分而治之的思想。简单来说，就是如果你要处理1000个数据，但是你并不具备处理1000个数据的能力，那么你可以只处理其中的10个，然后，分阶段处理100次，将100次的结果进行合成，那就是最终想要的对原始的1000个数据的处理结果。​ 同时forkjoin在处理某一类问题时非常的有用，哪一类问题？分而治之的问题。十大计算机经典算法：快速排序、堆排序、归并排序、二分查找、线性查找、深度优先、广度优先、Dijkstra、动态规划、朴素贝叶斯分类，有几个属于分而治之？3个，快速排序、归并排序、二分查找，还有大数据中M/R都是。分治法的设计思想是：将一个难以直接解决的大问题，分割成一些规模较小的相同问题，以便各个击破，分而治之。分治策略是：对于一个规模为n的问题，若该问题可以容易地解决（比如说规模n较小）则直接解决，否则将其分解为k个规模较小的子问题，这些子问题互相独立且与原问题形式相同(子问题相互之间有联系就会变为动态规范算法)，递归地解这些子问题，然后将各子问题的解合并得到原问题的解。这种算法设计策略叫做分治法。归并排序​ 归并排序是建立在归并操作上的一种有效的排序算法。该算法是采用分治法的一个非常典型的应用。将已有序的子序列合并，得到完全有序的序列；即先使每个子序列有序，再使子序列段间有序。若将两个有序表合并成一个有序表，称为2-路归并，与之对应的还有多路归并。​ 对于给定的一组数据，利用递归与分治技术将数据序列划分成为越来越小的半子表，在对半子表排序后，再用递归方法将排好序的半子表合并成为越来越大的有序序列。​ 为了提升性能，有时我们在半子表的个数小于某个数（比如15）的情况下，对半子表的排序采用其他排序算法，比如插入排序。Fork-Join原理Fork/Join框架要完成两件事情：任务分割​ Fork/Join框架的基本思想就是将一个大任务分解（Fork）成一系列子任务，子任务可以继续往下分解，当多个不同的子任务都执行完成后，可以将它们各自的结果合并（Join）成一个大结果，最终合并成大任务的结果：ForkJoinTask基本任务，使用forkjoin框架必须创建的对象，提供fork,join操作，常用的两个子类RecursiveAction : 无结果返回的任务RecursiveTask : 有返回结果的任务说明：fork : 让task异步执行join : 让task同步执行，可以获取返回值ForkJoinTask 在不显示使用ForkJoinPool.execute/invoke/submit()方法进行执行的情况下，也可以使用自己的fork/invoke方法进行执行结果合并ForkJoinPool 执行 ForkJoinTask任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务三中提交方式：execute： 异步，无返回结果submit ：异步，有返回结果 （返回Future&lt;T&gt;）invoke ：同步，有返回结果 （会阻塞）工作密取​ 即当前线程的Task已经全被执行完毕，则自动取到其他线程的Task池中取出Task继续执行。ForkJoinPool中维护着多个线程（一般为CPU核数）在不断地执行Task，每个线程除了执行自己职务内的Task之外，还会根据自己工作线程的闲置情况去获取其他繁忙的工作线程的Task，如此一来就能能够减少线程阻塞或是闲置的时间，提高CPU利用率。Fork/Join使用​ 我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork和join的操作机制，通常我们不直接继承ForkjoinTask类，只需要直接继承其子类。RecursiveAction，用于没有返回结果的任务RecursiveTask，用于有返回值的任务task要通过ForkJoinPool来执行，使用submit 或 invoke 提交，两者的区别是：invoke是同步执行，调用之后需要等待任务完成，才能执行后面的代码；submit是异步执行。join()和get方法当任务完成的时候返回计算结果。​ 在我们自己实现的compute方法里，首先需要判断任务是否足够小，如果足够小就直接执行任务。如果不足够小，就必须分割成两个子任务，每个子任务在调用invokeAll方法时，又会进入compute方法，看看当前子任务是否需要继续分割成孙任务，如果不需要继续分割，则执行当前子任务并返回结果。使用join方法会等待子任务执行完并得到其结果。Fork/Join的使用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121public class SubmitTask extends RecursiveTask&lt;Long&gt; &#123; /** * 起始值 */ private long start; /** * 结束值 */ private long end; /** * 阈值 */ private long threshold = 10L; public SubmitTask(long start, long end) &#123; this.start = start; this.end = end; &#125; /** * 计算逻辑 * * @return */ @Override protected Long compute() &#123; //校验是否达到了阈值 if (isLessThanThreshold()) &#123; //处理并返回结果 return handle(); &#125; else &#123; //没有达到阈值 计算一个中间值 long mid = (start + end) / 2; //拆分 左边的 SubmitTask left = new SubmitTask(start, mid); //拆分右边的 SubmitTask right = new SubmitTask(mid + 1, end); //添加到任务列表 invokeAll(left, right); //合并结果并返回 return left.join() + right.join(); &#125; &#125; /** * 处理的任务 * * @return */ public Long handle() &#123; long sum = 0; for (long i = start; i &lt;= end; i++) &#123; sum += i; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; return sum; &#125; /*是否达到了阈值*/ private boolean isLessThanThreshold() &#123; return end - start &lt;= threshold; &#125; /** * forkJoin 方式调用 * * @param start * @param end */ public static void forkJoinInvok(long start, long end) &#123; long sum = 0; long currentTime = System.currentTimeMillis(); //创建ForkJoinPool 连接池 ForkJoinPool forkJoinPool = new ForkJoinPool(); //创建初始化任务 SubmitTask submitTask = new SubmitTask(start, end); //讲初始任务扔进连接池中执行 forkJoinPool.invoke(submitTask); //等待返回结果 sum = submitTask.join(); System.out.println(\"forkJoin调用：result:\" + sum); System.out.println(\"forkJoin调用耗时：\" + (System.currentTimeMillis() - currentTime)); &#125; /** * 普通方式调用 * * @param start * @param end */ public static void normalInvok(long start, long end) &#123; long sum = 0; long currentTime = System.currentTimeMillis(); for (long i = start; i &lt;= end; i++) &#123; sum += i; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"普通调用：result:\" + sum); System.out.println(\"普通调用耗时：\" + (System.currentTimeMillis() - currentTime)); &#125; public static void main(String[] args) &#123; //起始值的大小 long start = 0; //结束值的大小 long end = 10000; //forkJoin 调用 forkJoinInvok(start, end); System.out.println(\"========================\"); //普通调用 normalInvok(start, end); &#125;&#125;运行结果forkJoin调用：result:50005000forkJoin调用耗时：2286普通调用：result:50005000普通调用耗时：17038Fork/Join 同步用法同步用法就是将初始化的任务扔进连接池，如果没有执行完成会阻塞forkJoinPool.invoke(submitTask);12345678910111213141516171819202122 /** * forkJoin 方式调用 * * @param start * @param end */public static void forkJoinInvok(long start, long end) &#123; long sum = 0; long currentTime = System.currentTimeMillis(); //创建ForkJoinPool 连接池 ForkJoinPool forkJoinPool = new ForkJoinPool(); //创建初始化任务 SubmitTask submitTask = new SubmitTask(start, end); //讲初始任务扔进连接池中执行 同步用法 forkJoinPool.invoke(submitTask); System.out.println(\"同步方式，任务结束才会调用该方法,当前耗时\"+(System.currentTimeMillis() - currentTime)); //等待返回结果 sum = submitTask.join(); System.out.println(\"任务执行完成，当前耗时：\"+(System.currentTimeMillis() - currentTime)); System.out.println(\"forkJoin调用：result:\" + sum); System.out.println(\"forkJoin调用耗时：\" + (System.currentTimeMillis() - currentTime));&#125;打进结果同步方式，任务结束才会调用该方法,当前耗时2367任务执行完成，当前耗时：2368forkJoin调用：result:50005000forkJoin调用耗时：2368Fork/Join 异步用法异步用法就是将初始化的任务扔进连接池，然后继续其他任务forkJoinPool.submit(submitTask);12345678910111213141516171819202122/** * forkJoin 方式调用 * * @param start * @param end */public static void forkJoinInvok(long start, long end) &#123; long sum = 0; long currentTime = System.currentTimeMillis(); //创建ForkJoinPool 连接池 ForkJoinPool forkJoinPool = new ForkJoinPool(); //创建初始化任务 SubmitTask submitTask = new SubmitTask(start, end); //讲初始任务扔进连接池中执行 异步方式 forkJoinPool.submit(submitTask); System.out.println(\"异步方式，任务结束才会调用该方法,当前耗时\"+(System.currentTimeMillis() - currentTime)); //等待返回结果 sum = submitTask.join(); System.out.println(\"任务执行完成，当前耗时：\"+(System.currentTimeMillis() - currentTime)); System.out.println(\"forkJoin调用：result:\" + sum); System.out.println(\"forkJoin调用耗时：\" + (System.currentTimeMillis() - currentTime));&#125;打印结果异步方式，任务结束才会调用该方法,当前耗时3任务执行完成，当前耗时：2315forkJoin调用：result:50005000forkJoin调用耗时：2315总结关于ForkJoinPool可以使用ForkJoinPool.execute(异步，不返回结果)/invoke(同步，返回结果)/submit(异步，返回结果)方法，来执行ForkJoinTask。ForkJoinPool有一个方法commonPool()，这个方法返回一个ForkJoinPool内部声明的静态ForkJoinPool实例。文档上说，这个方法适用于大多数的应用。这个静态实例的初始线程数，为“CPU核数-1 ”，（Runtime.getRuntime().availableProcessors() - 1）ForkJoinTask自己启动时，使用的就是这个静态实例。关于ForkJoinTask可以使用invokeAll(task)方法，主动执行其它的ForkJoinTask，并等待Task完成。（是同步的）还可以使用fork方法，让一个task执行（这个方法是异步的）还可以使用join方法，让一个task执行（这个方法是同步的，它和fork不同点是同步或者异步的区别）可以使用join来取得ForkJoinTask的返回值。由于RecursiveTask类实现了Future接口，所以也可以使用get()取得返回值。get()和join()有两个主要的区别：join()方法不能被中断。如果你中断调用join()方法的线程，这个方法将抛出InterruptedException异常。如果任务抛出任何未受检异常，get()方法将返回一个ExecutionException异常，而join()方法将返回一个RuntimeException异常。ForkJoinTask在不显示使用ForkJoinPool.execute/invoke/submit()方法进行执行的情况下，也可以使用自己的fork/invoke方法进行执行。使用fork/invoke方法执行时，其实原理也是在ForkJoinPool里执行，只不过使用的是一个“在ForkJoinPool内部生成的静态的”ForkJoinPool。ForkJoinTask有两个子类，RecursiveAction和RecursiveTask。他们之间的区别是，RecursiveAction没有返回值，RecursiveTask有返回值。看看ForkjoinTask的Complete方法的使用场景这个方法好要是用来使一个任务结束。这个方法被用在结束异步任务上，或者为那些能不正常结束的任务，提供一个选择。Task的completeExceptionally方法是怎么回事。这个方法被用来，在异步的Task中产生一个exception，或者强制结束那些“不会结束”的任务这个方法是在Task想要“自己结束自己”时，可以被使用。而cancel方法，被设计成被其它TASK调用。当你在一个任务中抛出一个未检查异常时，它也影响到它的父任务（把它提交到ForkJoinPool类的任务）和父任务的父任务，以此类推。","categories":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}],"tags":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/tags/并发/"},{"name":"工具类","slug":"工具类","permalink":"http://www.baiyp.ren/tags/工具类/"}],"keywords":[{"name":"并发","slug":"并发","permalink":"http://www.baiyp.ren/categories/并发/"},{"name":"工具类","slug":"并发/工具类","permalink":"http://www.baiyp.ren/categories/并发/工具类/"}]},{"title":"使用lambda表达式简化开发","slug":"用lambda表达式简化开发","date":"2019-06-15T09:57:36.000Z","updated":"2019-08-22T02:03:01.599Z","comments":true,"path":"用lambda表达式简化开发.html","link":"","permalink":"http://www.baiyp.ren/用lambda表达式简化开发.html","excerpt":"","text":"使用lambda表达式简化开发什么是lambda表达式​ “Lambda 表达式”(lambda expression)是一个匿名函数，Lambda表达式基于数学中的λ演算得名，直接对应于其中的lambda抽象(lambda abstraction)，是一个匿名函数，即没有函数名的函数。Lambda表达式可以表示闭包（注意和数学传统意义上的不同）。​ 将一个变量传入一个匿名函数然后对传入函数进行操作。由于java中并没有脱离类而存在的函数，所以通常独立函数是以一个匿名内部类+一个方法构成的。lambda表达式代替的函数既没有方法名也没有访问修饰符、明确的返回类型声明。Lambda 表达式的语法Lambda 表达式需要“函数式接口”的支持函数式接口​ 接口中只有一个抽象方法的接口，称为函数式接口。 可以使用注解 @FunctionalInterface 修饰 可以检查是否是函数式接口Lambda 表达式的基础语法Java8中引入了一个新的操作符 “-&gt;” 该操作符称为箭头操作符或 Lambda 操作符。箭头操作符将 Lambda 表达式拆分成两部分左侧：Lambda 表达式的参数列表右侧：Lambda 表达式中所需执行的功能， 即 Lambda 体语法格式一无参数，无返回值1() -&gt; System.out.println(&quot;Hello Lambda!&quot;);语法格式二有一个参数，并且无返回值1(x) -&gt; System.out.println(x)语法格式三若只有一个参数，小括号可以省略不写1x -&gt; System.out.println(x)语法格式四有两个以上的参数，有返回值，并且 Lambda 体中有多条语句1234Comparator&lt;Integer&gt; comparator = (x, y) -&gt; &#123; System.out.println(\"函数式接口\"); return Integer.compare(x, y); &#125;;语法格式五若 Lambda 体中只有一条语句， return 和 大括号都可以省略不写1Comparator&lt;Integer&gt; com = (x, y) -&gt; Integer.compare(x, y);语法格式六Lambda 表达式的参数列表的数据类型可以省略不写，因为JVM编译器通过上下文推断出，数据类型，即“类型推断”1Comparator&lt;Integer&gt; comparator = (Integer x, Integer y) -&gt; Integer.compare(x, y);Lambda 表达式的语法的使用遍历LIST原始的代码1234List&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList(\"a\", \"b\", \"c\", \"d\", \"e\"));for (String str : list) &#123; System.out.println(str);&#125;Lambda 表达式123 List&lt;String&gt; list = new ArrayList&lt;String&gt;(Arrays.asList(\"a\", \"b\", \"c\", \"d\", \"e\"));//使用Lambda 表达式 list.forEach(str-&gt; System.out.println(str));MAP原始代码12345678910Map&lt;String, String&gt; map = new HashMap&lt;String, String&gt;() &#123;&#123; put(\"11\", \":11\"); put(\"22\", \":22\"); put(\"33\", \":33\"); put(\"44\", \":44\"); &#125;&#125;;//打印 key+value for(Map.Entry&lt;String,String&gt; m:map.entrySet())&#123; System.out.println(m.getKey()+m.getValue()); &#125;Lambda 表达式12//使用Lambda 更简单 map.forEach((k, v) -&gt; System.out.println(k + v));匿名内部类12345678910111213141516171819202122232425262728293031323334353637public class LambdaTest &#123; public static void main(String[] args) &#123; LambdaTest lambdaTest = new LambdaTest(); //原始关键代码进行回调并返回值 /*int num = lambdaTest.invok(new CallBack() &#123; @Override public int call(int x, int y) &#123; return x + y; &#125; &#125;);*/ // ------------------------------ //使用Lambda 更简单更简洁 int num = lambdaTest.invok((x, y) -&gt; x + y); System.out.println(num); &#125; /** * 调用方法 * * @param callBack * @return */ public int invok(CallBack callBack) &#123; System.out.println(\"方法执行前\"); int num = callBack.call(1, 2); System.out.println(\"方法执行后\"); return num; &#125; /** * 匿名内部类 */ interface CallBack &#123; public int call(int x, int y); &#125;&#125;Java 线程创建12345678910111213//普通方式创建线程 Thread thread1 = new Thread(new Runnable() &#123; @Override public void run() &#123; System.out.println(\"我是普通线程\"); &#125; &#125;); // Lambda表达式创建线程 Thread thread2 = new Thread(() -&gt; System.out.println(\"我是Lambda线程\"));thread1.start(); thread2.start();排序12345678910111213141516String[] stringArrays = &#123;\"Rafael Nadal\", \"Novak Djokovic\", \"Stanislas Wawrinka\", \"David Ferrer\", \"Roger Federer\", \"Andy Murray\", \"Tomas Berdych\", \"Juan Martin Del Potro\", \"Richard Gasquet\", \"John Isner\"&#125;; // 使用匿名内部类根据 name 排序 stringArrays Arrays.sort(stringArrays, new Comparator&lt;String&gt;() &#123; @Override public int compare(String s1, String s2) &#123; return (s1.compareTo(s2)); &#125; &#125;); //使用Lambda 表达式进行排序 Arrays.sort(stringArrays,(x,y)-&gt;x.compareTo(y));就是这样,简洁又直观。 在下一节中我们将探索更多lambdas的能力,并将其与 stream 结合起来使用。","categories":[{"name":"lambda","slug":"lambda","permalink":"http://www.baiyp.ren/categories/lambda/"}],"tags":[{"name":"lambda","slug":"lambda","permalink":"http://www.baiyp.ren/tags/lambda/"}],"keywords":[{"name":"lambda","slug":"lambda","permalink":"http://www.baiyp.ren/categories/lambda/"}]},{"title":"JsonValidator工具类","slug":"JsonValidator工具类","date":"2018-05-19T23:08:50.000Z","updated":"2019-08-22T05:02:13.646Z","comments":true,"path":"JsonValidator工具类.html","link":"","permalink":"http://www.baiyp.ren/JsonValidator工具类.html","excerpt":"","text":"JsonValidator工具类JsonValidator 是用来校验字符串是否是JSON格式​ 是我用来加前后端段解密时候用到的，前端加密成JSON格式后端需要解密，所以需要对JSON格式做一个校验，网上找到了这个工具类，比较好用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246/** * 用于校验一个字符串是否是合法的JSON格式 */import com.google.common.cache.Cache;import com.google.common.cache.CacheBuilder;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.text.CharacterIterator;import java.text.StringCharacterIterator;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;public class JsonValidator &#123; private static final Logger logger = LoggerFactory.getLogger(JsonValidator.class); private final static Cache&lt;String, JsonValidator&gt; jsonValidatorCache = CacheBuilder.newBuilder() //设置cache的初始大小为10，要合理设置该值 .initialCapacity(10) //设置并发数为5，即同一时间最多只能有5个线程往cache执行写入操作 .concurrencyLevel(10) //构建cache实例 .build(); private CharacterIterator it; private char c; private int col; private JsonValidator() &#123; &#125; public static JsonValidator getJsonValidator() throws ExecutionException &#123; return getJsonValidator(\"JsonValidator\"); &#125; public static JsonValidator getJsonValidator(final String key) throws ExecutionException &#123; return jsonValidatorCache.get(key, new Callable&lt;JsonValidator&gt;() &#123; @Override public JsonValidator call() throws Exception &#123; logger.info(\"[RBRequestParameter] - [getJsonValidator] - key:&#123;&#125; - 创建对象\", key); return new JsonValidator(); &#125; &#125;); &#125; private static boolean error(String type, int col) &#123; System.out.printf(\"type: %s, col: %s%s\", type, col, System.getProperty(\"line.separator\")); return false; &#125; public static void main(String[] args) throws ExecutionException &#123; boolean n = JsonValidator.getJsonValidator().validate(\"[\\\"703502\\\",\\\"703502\\\",\\\"703502\\\",\\\"703502\\\",\\\"703502\\\",\\\"703502\\\",\\\"703502\\\",\\\"703502\\\"]\"); System.out.println(n); n = JsonValidator.getJsonValidator().validate(\"[\\\"906102\\\",\\\"906102\\\",\\\"906102\\\",\\\"906102\\\",\\\"906101\\\",\\\"906101\\\",\\\"906101\\\",\\\"906101\\\",\\\"906101\\\",\\\"906101\\\"]\"); System.out.println(n); &#125; /** * 验证一个字符串是否是合法的JSON串 * * @param input 要验证的字符串 * @return true-合法 ，false-非法 */ public boolean validate(String input) &#123; input = input.trim(); boolean ret = valid(input); return ret; &#125; private boolean valid(String input) &#123; if (\"\".equals(input)) return true; boolean ret = true; it = new StringCharacterIterator(input); c = it.first(); col = 1; if (!value()) &#123; ret = error(\"value\", 1); &#125; else &#123; skipWhiteSpace(); if (c != CharacterIterator.DONE) &#123; ret = error(\"end\", col); &#125; &#125; return ret; &#125; private boolean value() &#123; return literal(\"true\") || literal(\"false\") || literal(\"null\") || string() || number() || object() || array(); &#125; private boolean literal(String text) &#123; CharacterIterator ci = new StringCharacterIterator(text); char t = ci.first(); if (c != t) return false; int start = col; boolean ret = true; for (t = ci.next(); t != CharacterIterator.DONE; t = ci.next()) &#123; if (t != nextCharacter()) &#123; ret = false; break; &#125; &#125; nextCharacter(); if (!ret) error(\"literal \" + text, start); return ret; &#125; private boolean array() &#123; return aggregate('[', ']', false); &#125; private boolean object() &#123; return aggregate('&#123;', '&#125;', true); &#125; private boolean aggregate(char entryCharacter, char exitCharacter, boolean prefix) &#123; if (c != entryCharacter) return false; nextCharacter(); skipWhiteSpace(); if (c == exitCharacter) &#123; nextCharacter(); return true; &#125; for (; ; ) &#123; if (prefix) &#123; int start = col; if (!string()) return error(\"string\", start); skipWhiteSpace(); if (c != ':') return error(\"colon\", col); nextCharacter(); skipWhiteSpace(); &#125; if (value()) &#123; skipWhiteSpace(); if (c == ',') &#123; nextCharacter(); &#125; else if (c == exitCharacter) &#123; break; &#125; else &#123; return error(\"comma or \" + exitCharacter, col); &#125; &#125; else &#123; return error(\"value\", col); &#125; skipWhiteSpace(); &#125; nextCharacter(); return true; &#125; private boolean number() &#123; if (!Character.isDigit(c) &amp;&amp; c != '-') return false; int start = col; if (c == '-') nextCharacter(); if (c == '0') &#123; nextCharacter(); &#125; else if (Character.isDigit(c)) &#123; while (Character.isDigit(c)) nextCharacter(); &#125; else &#123; return error(\"number\", start); &#125; if (c == '.') &#123; nextCharacter(); if (Character.isDigit(c)) &#123; while (Character.isDigit(c)) nextCharacter(); &#125; else &#123; return error(\"number\", start); &#125; &#125; if (c == 'e' || c == 'E') &#123; nextCharacter(); if (c == '+' || c == '-') &#123; nextCharacter(); &#125; if (Character.isDigit(c)) &#123; while (Character.isDigit(c)) nextCharacter(); &#125; else &#123; return error(\"number\", start); &#125; &#125; return true; &#125; private boolean string() &#123; if (c != '\"') return false; int start = col; boolean escaped = false; for (nextCharacter(); c != CharacterIterator.DONE; nextCharacter()) &#123; if (!escaped &amp;&amp; c == '\\\\') &#123; escaped = true; &#125; else if (escaped) &#123; if (!escape()) &#123; return false; &#125; escaped = false; &#125; else if (c == '\"') &#123; nextCharacter(); return true; &#125; &#125; return error(\"quoted string\", start); &#125; private boolean escape() &#123; int start = col - 1; if (\" \\\\\\\"/bfnrtu\".indexOf(c) &lt; 0) &#123; return error(\"escape sequence \\\\\\\",\\\\\\\\,\\\\/,\\\\b,\\\\f,\\\\n,\\\\r,\\\\t or \\\\uxxxx \", start); &#125; if (c == 'u') &#123; if (!ishex(nextCharacter()) || !ishex(nextCharacter()) || !ishex(nextCharacter()) || !ishex(nextCharacter())) &#123; return error(\"unicode escape sequence \\\\uxxxx \", start); &#125; &#125; return true; &#125; private boolean ishex(char d) &#123; return \"0123456789abcdefABCDEF\".indexOf(c) &gt;= 0; &#125; private char nextCharacter() &#123; c = it.next(); ++col; return c; &#125; private void skipWhiteSpace() &#123; while (Character.isWhitespace(c)) &#123; nextCharacter(); &#125; &#125;&#125;","categories":[{"name":"代码片段","slug":"代码片段","permalink":"http://www.baiyp.ren/categories/代码片段/"}],"tags":[{"name":"代码片段","slug":"代码片段","permalink":"http://www.baiyp.ren/tags/代码片段/"},{"name":"json","slug":"json","permalink":"http://www.baiyp.ren/tags/json/"},{"name":"JsonValidator","slug":"JsonValidator","permalink":"http://www.baiyp.ren/tags/JsonValidator/"}],"keywords":[{"name":"代码片段","slug":"代码片段","permalink":"http://www.baiyp.ren/categories/代码片段/"}]},{"title":"HttpClient工具类","slug":"HttpClient工具类","date":"2018-05-03T23:00:42.000Z","updated":"2019-08-22T05:02:04.324Z","comments":true,"path":"HttpClient工具类.html","link":"","permalink":"http://www.baiyp.ren/HttpClient工具类.html","excerpt":"","text":"HttpClient工具类HttpClient 是用来远程访问页面或者调用Http接口的，可以用来调用接口喝着爬虫都可以​收藏好久的工具类展示以下，用了很长时间，也是从其他地方收集过来的123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308import java.io.IOException;import java.io.UnsupportedEncodingException;import java.net.URISyntaxException;import java.util.ArrayList;import java.util.List;import java.util.Map;import com.alibaba.fastjson.JSON;import org.apache.commons.httpclient.HttpStatus;import org.apache.http.HttpEntity;import org.apache.http.HttpException;import org.apache.http.HttpResponse;import org.apache.http.NameValuePair;import org.apache.http.client.ClientProtocolException;import org.apache.http.client.HttpClient;import org.apache.http.client.config.RequestConfig;import org.apache.http.client.entity.UrlEncodedFormEntity;import org.apache.http.client.methods.HttpGet;import org.apache.http.client.methods.HttpPost;import org.apache.http.client.methods.HttpRequestBase;import org.apache.http.client.utils.URLEncodedUtils;import org.apache.http.entity.StringEntity;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.DefaultHttpRequestRetryHandler;import org.apache.http.impl.client.HttpClientBuilder;import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;import org.apache.http.message.BasicHeader;import org.apache.http.message.BasicNameValuePair;import org.apache.http.protocol.HTTP;import org.apache.http.util.EntityUtils;import org.springframework.util.Assert;public class HttpClientUtils &#123; private HttpClientUtils()&#123;&#125; /** * 连接超时时间 */ public static final int CONNECTION_TIMEOUT_MS = 5000; /** * 读取数据超时时间 */ public static final int SO_TIMEOUT_MS = 5000; public static final String utf8 = \"UTF-8\"; public static final String application_json = \"application/json\"; public static final String gbk = \"GBK\"; /** * 简单get调用 * * @param url * @param params * @return * @throws ClientProtocolException * @throws IOException * @throws URISyntaxException */ public static String get(String url, Map&lt;String, String&gt; params) throws IOException, URISyntaxException &#123; return get(url, params, utf8); &#125; /** * 简单get调用 * * @param url * @param params * @return * @throws ClientProtocolException * @throws IOException * @throws URISyntaxException */ public static String get(String url, Map&lt;String, String&gt; params, String charset) throws IOException, URISyntaxException &#123; HttpClient client = buildHttpClient(true); HttpGet get = buildHttpGet(url, params, charset); HttpResponse response = client.execute(get); assertStatus(response); HttpEntity entity = response.getEntity(); if (entity != null) &#123; return EntityUtils.toString(entity, charset); &#125; return null; &#125; /** * 简单post调用 * * @param url * @param params * @return * @throws URISyntaxException * @throws ClientProtocolException * @throws IOException */ public static String post(String url, Map&lt;String, String&gt; params) throws URISyntaxException, IOException &#123; return post(url, params, utf8); &#125; public static String postJSON(String url, Map&lt;String, String&gt; params) throws IOException, URISyntaxException &#123; return postJSON(url, params, utf8); &#125; /** * 简单post调用 * * @param url * @param params * @return * @throws URISyntaxException * @throws ClientProtocolException * @throws IOException */ public static String post(String url, Map&lt;String, String&gt; params, String charset) throws URISyntaxException, IOException &#123; HttpClient client = buildHttpClient(true); HttpPost postMethod = buildHttpPost(url, params, charset); HttpResponse response = client.execute(postMethod); assertStatus(response); HttpEntity entity = response.getEntity(); if (entity != null) &#123; return EntityUtils.toString(entity, charset); &#125; return null; &#125; public static String postJSON(String url, Map params, String charset) throws URISyntaxException, IOException &#123; HttpClient client = buildHttpClient(true); HttpPost postMethod = buildHttpJSONPost(url, params, charset); HttpResponse response = client.execute(postMethod); assertStatus(response); HttpEntity entity = response.getEntity(); if (entity != null) &#123; return EntityUtils.toString(entity, charset); &#125; return null; &#125; /** * 创建HttpClient * * @param isMultiThread * @return */ public static HttpClient buildHttpClient(boolean isMultiThread) &#123; CloseableHttpClient client; if (isMultiThread) client = HttpClientBuilder .create().setDefaultRequestConfig(buildRequestConfig()) .setRetryHandler(new DefaultHttpRequestRetryHandler()) .setConnectionManager( new PoolingHttpClientConnectionManager()).build(); else client = HttpClientBuilder.create().build(); return client; &#125; /** * 构建httpPost对象 * * @param url * @return * @throws UnsupportedEncodingException * @throws URISyntaxException */ public static HttpPost buildHttpPost(String url, Map&lt;String, String&gt; params, String charset) throws UnsupportedEncodingException, URISyntaxException &#123; Assert.notNull(url, \"构建HttpPost时,url不能为null\"); HttpPost post = new HttpPost(url); setCommonHttpMethod(post); if (params != null) &#123; List&lt;NameValuePair&gt; formparams = new ArrayList&lt;NameValuePair&gt;(); for (Map.Entry&lt;String, String&gt; entry : params.entrySet()) &#123; formparams.add(new BasicNameValuePair(entry.getKey(), entry.getValue())); &#125; HttpEntity he = new UrlEncodedFormEntity(formparams, charset); post.setEntity(he); &#125; return post; &#125; public static HttpPost buildHttpJSONPost(String url, Map&lt;String, String&gt; params, String charset) throws UnsupportedEncodingException, URISyntaxException &#123; Assert.notNull(url, \"构建HttpPost时,url不能为null\"); HttpPost post = new HttpPost(url); setJSONHttpMethod(post); if (params != null) &#123; String json = JSON.toJSONString(params); System.out.println(json); StringEntity stringEntity = new StringEntity(json, utf8); stringEntity.setContentEncoding(new BasicHeader(HTTP.CONTENT_TYPE, application_json)); post.setEntity(stringEntity); &#125; return post; &#125; /** * 构建httpGet对象 * * @param url * @return * @throws URISyntaxException */ public static HttpGet buildHttpGet(String url, Map&lt;String, String&gt; params, String chatset) throws URISyntaxException &#123; Assert.notNull(url, \"构建HttpGet时,url不能为null\"); return new HttpGet(buildGetUrl(url, params, chatset)); &#125; /** * build getUrl str * * @param url * @param params * @return */ private static String buildGetUrl(String url, Map&lt;String, String&gt; params, String charset) &#123; StringBuilder uriStr = new StringBuilder(url); if (params != null) &#123; List&lt;NameValuePair&gt; ps = new ArrayList&lt;NameValuePair&gt;(); for (Map.Entry&lt;String, String&gt; entry : params.entrySet()) &#123; ps.add(new BasicNameValuePair(entry.getKey(), entry.getValue())); &#125; uriStr.append(\"?\"); uriStr.append(URLEncodedUtils.format(ps, charset)); &#125; return uriStr.toString(); &#125; /** * 设置HttpMethod通用配置 * * @param httpMethod */ public static void setCommonHttpMethod(HttpRequestBase httpMethod) &#123; httpMethod.setHeader(HTTP.CONTENT_ENCODING, utf8);// setting &#125; /* 设置HttpMethod通用配置 * * @param httpMethod */ public static void setJSONHttpMethod(HttpRequestBase httpMethod) &#123; httpMethod.setHeader(HTTP.CONTENT_ENCODING, utf8);// setting httpMethod.setHeader(HTTP.CONTENT_TYPE, application_json);// setting &#125; /** * 设置成消息体的长度 setting MessageBody length * * @param httpMethod * @param he */ public static void setContentLength(HttpRequestBase httpMethod, HttpEntity he) &#123; if (he == null) &#123; return; &#125; httpMethod.setHeader(HTTP.CONTENT_LEN, String.valueOf(he.getContentLength())); &#125; /** * 构建公用RequestConfig * * @return */ public static RequestConfig buildRequestConfig() &#123; // 设置请求和传输超时时间 return RequestConfig.custom() .setSocketTimeout(SO_TIMEOUT_MS) .setConnectTimeout(CONNECTION_TIMEOUT_MS).build(); &#125; /** * 强验证必须是200状态否则报异常 * * @param res * @throws HttpException */ static void assertStatus(HttpResponse res) throws IOException &#123; Assert.notNull(res, \"http响应对象为null\"); Assert.notNull(res.getStatusLine(), \"http响应对象的状态为null\"); switch (res.getStatusLine().getStatusCode()) &#123; case HttpStatus.SC_OK: break; default: throw new IOException(\"服务器响应状态异常,失败.\"); &#125; &#125; public static void main(String[] args) throws ClientProtocolException, IOException, URISyntaxException &#123; System.out.println(get(\"http://www.baidu.com\", new HashMap&lt;String, String&gt;())); &#125;&#125;","categories":[{"name":"代码片段","slug":"代码片段","permalink":"http://www.baiyp.ren/categories/代码片段/"}],"tags":[{"name":"代码片段","slug":"代码片段","permalink":"http://www.baiyp.ren/tags/代码片段/"},{"name":"httpClient","slug":"httpClient","permalink":"http://www.baiyp.ren/tags/httpClient/"}],"keywords":[{"name":"代码片段","slug":"代码片段","permalink":"http://www.baiyp.ren/categories/代码片段/"}]},{"title":"携程Apollo(阿波罗)安装部署以及java整合","slug":"携程Apollo-阿波罗-安装部署以及java整合","date":"2018-04-02T21:48:53.000Z","updated":"2019-08-22T02:00:47.571Z","comments":true,"path":"携程Apollo-阿波罗-安装部署以及java整合.html","link":"","permalink":"http://www.baiyp.ren/携程Apollo-阿波罗-安装部署以及java整合.html","excerpt":"","text":"携程Apollo（阿波罗）安装部署以及java整合服务器部署可以按照apollo wiki 进行部署https://github.com/ctripcorp/apollo/wiki/Quick-Start安装 Java 环境java创建数据库Apollo服务端共需要两个数据库：ApolloPortalDB和ApolloConfigDB，我们把数据库、表的创建和样例数据都分别准备了sql文件，只需要导入数据库即可。执行两个sql文件sql/apolloportaldb.sqlsql/apolloconfigdb.sql会创建两个数据库下载安装包https://github.com/nobodyiam/apollo-build-scripts服务器部署将快速部署包apollo-quick-start放进服务器解压文件服务器配置Apollo服务端需要知道如何连接到你前面创建的数据库，所以需要编辑demo.sh，修改ApolloPortalDB和ApolloConfigDB相关的数据库连接串信息。123456789#apollo config db infoapollo_config_db_url=jdbc:mysql://localhost:3306/ApolloConfigDB?characterEncoding=utf8apollo_config_db_username=用户名apollo_config_db_password=密码（如果没有密码，留空即可）# apollo portal db infoapollo_portal_db_url=jdbc:mysql://localhost:3306/ApolloPortalDB?characterEncoding=utf8apollo_portal_db_username=用户名apollo_portal_db_password=密码（如果没有密码，留空即可）修改服务器端口地址信息meta server url123config_server_url=http://10.168.16.125:8080admin_server_url=http://10.168.16.125:8090portal_url=http://10.168.16.125:8070如果部署在linux服务器上需要将地址改为服务器IP地址注意：不要修改demo.sh的其它部分确保端口未被占用Quick Start脚本会在本地启动3个服务，分别使用8070, 8080, 8090端口，请确保这3个端口当前没有被使用。例如，在Linux/Mac下，可以通过如下命令检查：lsof -i:8080执行启动脚本./demo.sh start当看到如下输出后，就说明启动成功了！123456789101112==== starting service ====Service logging file is ./service/apollo-service.logStarted [10768]Waiting for config service startup.......Config service started. You may visit http://localhost:8080 for service status now!Waiting for admin service startup....Admin service started==== starting portal ====Portal logging file is ./portal/apollo-portal.logStarted [10846]Waiting for portal startup......Portal started. You can visit http://localhost:8070 now!使用Apollo配置中心访问 服务器的IP:8070 可以进行访问例如 ：http://10.168.16.125:8070默认 用户名密码是 apollo admin登陆后如下界面可以创建自己的项目添加namespacenamespace 相当于配置文件名称在namespace中添加属性，可以以文本形式添加可以自己研究琢磨下java服务整合pom整合官方提供的maven12345&lt;dependency&gt; &lt;groupId&gt;com.ctrip.framework.apollo&lt;/groupId&gt; &lt;artifactId&gt;apollo-client&lt;/artifactId&gt; &lt;version&gt;0.9.1&lt;/version&gt;&lt;/dependency&gt;发现拉不下来jar包解决方案下载源代码https://github.com/ctripcorp/apollo.git编译其中的 apollo-client 包并安装到本地引入编译后的jar包即可12345&lt;dependency&gt; &lt;groupId&gt;com.ctrip.framework.apollo&lt;/groupId&gt; &lt;artifactId&gt;apollo-client&lt;/artifactId&gt; &lt;version&gt;0.10.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt;现有应用接入在应用接入Apollo之后，这些配置是可以非常方便的迁移到Apollo的，具体步骤如下：在Apollo为应用新建项目在应用中配置好META-INF/app.properties把原先配置（必须是properties格式）复制一下，然后通过Apollo提供的文本编辑模式全部粘帖到应用的application namespace，发布配置如果原来是其它格式，如yml，请先转成properties格式把原先的配置文件如bootstrap.properties, application.properties从项目中删除app.properties 内容是创建项目的APPID（应用ID）如前面创建的1234512# testapp.id=12345并在resources 下加入apollo-env.properties 各环境的服务器地址123456local.meta=http://10.168.16.125:8080dev.meta=http://10.168.16.125:8080fat.meta=$&#123;fat_meta&#125;uat.meta=$&#123;uat_meta&#125;lpt.meta=$&#123;lpt_meta&#125;pro.meta=$&#123;pro_meta&#125;修改环境修改/opt/settings/server.properties（Mac/Linux）或C:\\opt\\settings\\server.properties（Windows）文件，设置env为DEV：1env=DEVSpring 整合apollo启动配置1&lt;apollo:config/&gt;apollo加载namespace配置1&lt;apollo:config namespaces=&quot;dubbo&quot; order=&quot;1&quot;/&gt;####官方配置如下Apollo也支持和Spring整合（Spring 3.1.1+），只需要做一些简单的配置就可以了。Apollo目前既支持比较传统的基于XML的配置，也支持目前比较流行的基于Java（推荐）的配置。需要注意的是，如果之前有使用org.springframework.beans.factory.config.PropertyPlaceholderConfigurer的，请替换成org.springframework.context.support.PropertySourcesPlaceholderConfigurer。Spring 3.1以后就不建议使用PropertyPlaceholderConfigurer了，要改用PropertySourcesPlaceholderConfigurer。基于XML的配置注：需要把apollo相关的xml namespace加到配置文件头上，不然会报xml语法错误。1.注入默认namespace的配置到Spring中12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:apollo=\"http://www.ctrip.com/schema/apollo\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.ctrip.com/schema/apollo http://www.ctrip.com/schema/apollo.xsd\"&gt; &lt;!-- 这个是最简单的配置形式，一般应用用这种形式就可以了，用来指示Apollo注入application namespace的配置到Spring环境中 --&gt; &lt;apollo:config/&gt; &lt;bean class=\"com.ctrip.framework.apollo.spring.TestXmlBean\"&gt; &lt;property name=\"timeout\" value=\"$&#123;timeout:100&#125;\"/&gt; &lt;property name=\"batch\" value=\"$&#123;batch:200&#125;\"/&gt; &lt;/bean&gt;&lt;/beans&gt;2.注入多个namespace的配置到Spring中123456789101112131415&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;beans xmlns=&quot;http://www.springframework.org/schema/beans&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xmlns:apollo=&quot;http://www.ctrip.com/schema/apollo&quot; xsi:schemaLocation=&quot;http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.ctrip.com/schema/apollo http://www.ctrip.com/schema/apollo.xsd&quot;&gt; &lt;!-- 这个是最简单的配置形式，一般应用用这种形式就可以了，用来指示Apollo注入application namespace的配置到Spring环境中 --&gt; &lt;apollo:config/&gt; &lt;!-- 这个是稍微复杂一些的配置形式，指示Apollo注入FX.apollo和FX.soa namespace的配置到Spring环境中 --&gt; &lt;apollo:config namespaces=&quot;FX.apollo,FX.soa&quot;/&gt; &lt;bean class=&quot;com.ctrip.framework.apollo.spring.TestXmlBean&quot;&gt; &lt;property name=&quot;timeout&quot; value=&quot;$&#123;timeout:100&#125;&quot;/&gt; &lt;property name=&quot;batch&quot; value=&quot;$&#123;batch:200&#125;&quot;/&gt; &lt;/bean&gt;&lt;/beans&gt;dubbo服务整合123456789101112 &lt;apollo:config/&gt;&lt;apollo:config namespaces=\"dubbo\" order=\"1\"/&gt; &lt;!-- 公共信息，也可以用dubbo.properties配置 --&gt; &lt;dubbo:application name=\"$&#123;dubbo.application.name&#125;\" /&gt; &lt;!-- 需要强制指定地址，配置文件默认可以不配置 --&gt; &lt;dubbo:registry address=\"$&#123;dubbo.registry.address&#125;\"/&gt; &lt;bean id=\"xxxService\" class=\"com.xxx.cache.service.impl.RedisServiceImpl\"/&gt; &lt;dubbo:service interface=\"com.xxx.xxx.service.RedisService\" ref=\"redisService\" version=\"$&#123;dubbo.version&#125;\"/&gt;dubbo 默认没有不需要配置，但使用apollo后没有自动注入dubbo注册地址，需要手动声明,原因待定1&lt;dubbo:registry address=&quot;$&#123;dubbo.registry.address&#125;&quot;/&gt;","categories":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"apollo","slug":"架构/apollo","permalink":"http://www.baiyp.ren/categories/架构/apollo/"}],"tags":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/tags/架构/"},{"name":"apollo","slug":"apollo","permalink":"http://www.baiyp.ren/tags/apollo/"}],"keywords":[{"name":"架构","slug":"架构","permalink":"http://www.baiyp.ren/categories/架构/"},{"name":"apollo","slug":"架构/apollo","permalink":"http://www.baiyp.ren/categories/架构/apollo/"}]},{"title":"系统加密服务-04","slug":"系统加密服务-04","date":"2018-03-02T23:07:18.000Z","updated":"2019-08-22T05:53:56.265Z","comments":true,"path":"系统加密服务-04.html","link":"","permalink":"http://www.baiyp.ren/系统加密服务-04.html","excerpt":"","text":"系统加密服务-后记开发中遇到的问题虽然说用起来直接引入js就能解决进行加密但是在使用过程中还是有很多问题的,这里面列出几个因为使用第三方校验框架，使得jquery监听form表单失效或者数据没有加密我们通过改写校验框架源码来实现，就是在校验中我们设置$.setSubmit(false)不进行提交，在校验通过后进行加密后再提交，设计的框架有jquery.validate,bootstrapValidate,validform 等form 表单中的重复的name值以“，”分割原来是这样来写的，以直没有问题，后来有一个很老的系统使用 request.getParameterValues() 方式来获取数组参数，因为解密后是“,”分割的字符串分不开数组和字符串所以对系统进行了重构js全部以数据的形式接收，因为数据形式数据量太大很多都是不重复的，所以就先生成一个JSON数组，然后检查如果是一个的话就将数据去掉，使用原始的JSON形式，如果有重复的name就保留数组，这样加密后就节省了很大的数据传输量pyload处理原来只有参数的解密后来发现对于ajax contentType为GBK的获取步到参数，发现是流的形式接收的，就增加了pyload形式，后来又发现上传文件失效了，原来将文件上传解密了，文件上传失败，就判断contentType不能包含multipart/form-data空对象处理因采用了JSON的压缩方式，如果一个参数值为空就不将这个参数传递过去了，因后台没有做任何处理，没有加密前是得到的是空字符串加密后得到的是null，造成了空指针，解决方法是加入了自定义配置默认不将空对象传过去，如果是指定一个配置，就将所以的参数传过去，如果对象为空的也传过去，但这样会造成很大的数据量增加，默认不传递空值的。其他的各种小问题也很多这里面不列举了系统响应情况因为引入了前端加密后端解密系统的响应速度肯定会下降，测试人员测试的是否发现系统明显慢了一些数据量越大的页面提交也越慢最慢的页面数据量特别大，提交约2分钟左右，加密的参数达到了恐怖了5万个各种各样的参数和值有些电脑甚至浏览器直接卡死崩溃但一般都能够接受，正常页面能够再1秒内提交响应总结安全问题解决了，积累了经验，特别累，涉及到十几个服务，三四个月以来几乎天天加班，处理各种各样的问题，后两个月几乎天天上线，回滚，测试人员一遍一遍的测试，线上还是问题不断，被骂了不知道多少遍，总算再规定的期限完成了，来检查的时候也是战战兢兢的，生怕出现问题，总算是完美完成，不辜负几个月的辛苦，拿到了安全证书，这几个月也学到很多知识。感谢各位查看和评阅第一次系列的写一些博客，感觉写的很乱，不能很系统的写出来，有什么问题欢迎指正。","categories":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/categories/加密/"}],"tags":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/tags/加密/"}],"keywords":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/categories/加密/"}]},{"title":"系统加密服务-03","slug":"系统加密服务-03","date":"2018-03-02T23:06:35.000Z","updated":"2019-08-22T05:53:47.331Z","comments":true,"path":"系统加密服务-03.html","link":"","permalink":"http://www.baiyp.ren/系统加密服务-03.html","excerpt":"","text":"系统加密服务-后台解密涉及的问题要知道解密是否成功对于AJAX传过来的PYLOAD 载荷的流的形式的数据解密并重构可重复读取的流要对后端透明后端不需要改动任何代码解密通过重写HttpServletRequestWrapper 实现构建可重复读取的的request流需要 spring-test jar支持使用DelegatingServletInputStream 实现构建ParameterRequestWrapper12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091public class ParameterRequestWrapper extends HttpServletRequestWrapper &#123; private static final Logger logger = LoggerFactory.getLogger(ParameterRequestWrapper.class); private Map&lt;String, String[]&gt; parameters = new LinkedHashMap&lt;String, String[]&gt;(); //是否可重复读取流 private boolean isReadInputStream = false; //pyload parameter 主体 private String parameterBody = null; //解密状态 private boolean decryptionState = false; /** * input stream 的buffer * */ public ParameterRequestWrapper(HttpServletRequest request) throws UnsupportedEncodingException &#123; super(request); //request 解密 RequestEnriry requestEnriry = ParameterUtils.decrypt(request); if (null != requestEnriry) &#123; //获取解密后的对象 Map&lt;String, String[]&gt; parameterMap = requestEnriry.getParameterMap(); //流是否被读取了 isReadInputStream = requestEnriry.isReadInputStream(); if (isReadInputStream) &#123; parameterBody = requestEnriry.getParameterBody(); &#125; //解密是否成功 decryptionState = requestEnriry.isPass(); if (null != parameterMap &amp;&amp; !parameterMap.isEmpty()) &#123; parameters = parameterMap; &#125; &#125; &#125; @Override public String getParameter(String key) &#123; String[] values = parameters.get(key); return StringUtils.arrayToString(values); &#125; @Override public Map&lt;String, String[]&gt; getParameterMap() &#123; return parameters; &#125; @Override public Enumeration&lt;String&gt; getParameterNames() &#123; return new Vector&lt;String&gt;(parameters.keySet()).elements(); &#125; @Override public String[] getParameterValues(String name) &#123; String[] result = null; Object value = parameters.get(name); if (value == null) &#123; result = null; &#125; else if (value instanceof String[]) &#123; result = (String[]) value; &#125; else if (value instanceof String) &#123; result = new String[]&#123;(String) value&#125;; &#125; else &#123; result = new String[]&#123;value.toString()&#125;; &#125; return result; &#125; @Override public ServletInputStream getInputStream() throws IOException &#123; if (isReadInputStream) &#123; if (null != parameterBody) &#123; final ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(parameterBody.getBytes()); //构建可重复读取的流 return new DelegatingServletInputStream(byteArrayInputStream); &#125; &#125; else &#123; return super.getInputStream(); &#125; return null; &#125; public boolean isDecryptionState() &#123; return decryptionState; &#125; public void setDecryptionState(boolean decryptionState) &#123; this.decryptionState = decryptionState; &#125;构建filter123456789101112131415161718public class ParametersFilter extends OncePerRequestFilter &#123; @Override protected void doFilterInternal(HttpServletRequest request, HttpServletResponse response, FilterChain chain) throws ServletException, IOException &#123; //强制指定编码，解决解密后乱码问题 request.setCharacterEncoding(\"UTF-8\"); ParameterRequestWrapper parameterRequestWrapper = new ParameterRequestWrapper(request); //获取加密状态 boolean isDecryptionState = parameterRequestWrapper.isDecryptionState(); if (isDecryptionState) &#123; chain.doFilter(parameterRequestWrapper, response); &#125; else &#123; //返回加密失败的状态，可以在页面处理 response.setStatus(911); &#125; &#125;&#125;在web.xml 设置filter需要RequestContextListener 支持，在web.xml 中配置1234567891011121314!-- 参数过滤器 --&gt; &lt;filter&gt; &lt;filter-name&gt;ParametersFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.xxx.common.security.web.filter.ParametersFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;ParametersFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- request固化器 --&gt; &lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.request.RequestContextListener&lt;/listener-class&gt; &lt;/listener&gt;这样就配置完了对于普通的parameterMap参数解密先检查参数名称是否是加密的key 我们可以指定一个不容易重名的例如“$@$.ecryptedData“如果加密了 就就行解密 解密完成后通过fastJson将JSON串转换为MAP检查是否存在我们JS中定义的时间戳 如果不存在 则判断解密失败代码片段如下参数解密123456789101112131415161718192021public void decrypt(HttpServletRequest request, RequestEnriry requestEnriry) &#123;//检查是否是form表单提交的 if (check(request)) &#123; Map&lt;String, String[]&gt; parameterMap = requestEnriry.getParameterMap(); //检查是否加密 boolean isEncrypt = isEncrypt(parameterMap); if (isEncrypt) &#123; requestEnriry.setEncrypt(isEncrypt); //获取加密的参数 String encParameter = getEncryptedParameter(parameterMap); //解密数据 String decParameter = decryptData(encParameter, getSecretKey(request)); if (StringUtils.isNotEmpty(decParameter)) &#123; //参数转换 Map&lt;String, String[]&gt; decParameterMap = encParameterConver(decParameter);//将参数封装到实体中 requestEnriry.putParameterMap(decParameterMap);//设置传过来的时间戳 requestEnriry.setTimestamp(getEncryptedTimestamp(decParameterMap)); &#125; &#125; &#125; &#125;检查参数是否加密123456789 public boolean isEncrypt(Map parameterMap) &#123;Map&lt;String, String[]&gt; parameterMap = requestEnriry.getParameterMap(); if (null != parameterMap &amp;&amp; !parameterMap.isEmpty()) &#123; if (null != parameterMap &amp;&amp; !parameterMap.isEmpty() &amp;&amp; parameterMap.containsKey(\"$@$.ecryptedData\")) &#123; flag = true; &#125; &#125; return flag; &#125;获取加密的参数12345678910public String getEncryptedParameter(Map&lt;String, String[]&gt; parameterMap) &#123; String ecryptedParam = null; if (null != parameterMap &amp;&amp; !parameterMap.isEmpty()) &#123; String[] parameterArray = parameterMap.get(\"$@$.ecryptedData\"); if (null != parameterArray &amp;&amp; parameterArray.length &gt; 0) &#123; ecryptedParam = parameterArray[0]; &#125; &#125; return ecryptedParam; &#125;检查是否需要解密操作1234567public boolean check(HttpServletRequest request) &#123; Map parameterMap = request.getParameterMap(); if (null != parameterMap &amp;&amp; !parameterMap.isEmpty()) &#123; return true; &#125; return false; &#125;参数转换12345678910111213141516171819202122public Map&lt;String, String[]&gt; encParameterConver(String decryptionJson) &#123; Map&lt;String, String[]&gt; mappingMap = new LinkedHashMap&lt;String, String[]&gt;(); if (null != mappingMap &amp;&amp; StringUtils.isNotEmpty(decryptionJson)) &#123; Map&lt;String, String[]&gt; parameterMap = null; parameterMap = ParameterUtils.jsonToMap(decryptionJson); if (null != parameterMap &amp;&amp; !parameterMap.isEmpty()) &#123; Set&lt;String&gt; keys = parameterMap.keySet(); for (String key : keys) &#123; if (StringUtils.isNotEmpty(key)) &#123; String[] value = parameterMap.get(key); if (null != value) &#123; value = ParameterUtils.decodeURI(value); &#125; if (null != value) &#123; mappingMap.put(key, value); &#125; &#125; &#125; &#125; &#125; return mappingMap; &#125;获取时间戳12345678910public String getEncryptedTimestamp(Map&lt;String, String[]&gt; parameterMap) &#123; String timestamp = null; if (null != parameterMap &amp;&amp; !parameterMap.isEmpty()) &#123; String[] valueArray = parameterMap.get(\"$@$.tmp\"); if (null != valueArray &amp;&amp; valueArray.length &gt; 0) &#123; timestamp = valueArray[0]; &#125; &#125; return timestamp; &#125;对于AJAX PYLOAD 载荷的参数解密跟普通的一样解密一样只是有几点区别pyload需要有contentTypecontentType 不能包含multipart/form-data 即不支持文件上传pyload 需要吧解析的参数还原为原始的字符串 可能是JSON字符串或者是URL参数代码片段如下参数解密123456789101112131415161718192021222324252627282930public void decrypt(HttpServletRequest request, RequestEnriry requestEnriry) &#123;//检查是否需要解密 if (check(request)) &#123; //获取pyload 参数 String pyloadParameter = getPyloadParameter(request); //设置流读取状态为true requestEnriry.setReadInputStream(true); if (StringUtils.isNotEmpty(pyloadParameter)) &#123; requestEnriry.setParameterBody(pyloadParameter); //将pyload参数解析 Map&lt;String, String[]&gt; parameterMap = ParameterUtils.getUrlParams(pyloadParameter); //检查是否加密 boolean isEncrypt = isEncrypt(parameterMap); if (isEncrypt) &#123; requestEnriry.setEncrypt(isEncrypt); String encParameter = getEncryptedParameter(parameterMap); if (StringUtils.isNotEmpty(encParameter)) &#123; String decParameter = decryptData(encParameter, getSecretKey(request)); requestEnriry.setParameterBody(decParameter); Map&lt;String, String[]&gt; map = ParameterUtils.jsonToMap(decParameter); if (null != map &amp;&amp; !map.isEmpty()) &#123; requestEnriry.setTimestamp(getEncryptedTimestamp(map)); requestEnriry.putParameterMap(map); &#125; &#125; &#125; &#125; &#125; &#125;检查是否是pyload形式1234567public boolean check(HttpServletRequest request) &#123; String contentType = getContentType(request); if (StringUtils.isNotEmpty(contentType) &amp;&amp; !contentType.contains(\"multipart/form-data\")) &#123; return true; &#125; return false; &#125;获取pyload 参数12345678910111213141516171819202122232425262728public String getPyloadParameter(HttpServletRequest request) &#123; String ecryptedParam = null; InputStream inputStream = null; try &#123; inputStream = request.getInputStream(); &#125; catch (IOException e) &#123; logger.error(\"Error reading the request body…\", e); &#125; if (null != inputStream) &#123; StringBuilder stringBuilder = new StringBuilder(); if (inputStream != null) &#123; try &#123; BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream)); char[] charBuffer = new char[CHAR_BUFFER_LENGTH]; int bytesRead; while ((bytesRead = bufferedReader.read(charBuffer)) &gt; 0) &#123; stringBuilder.append(charBuffer, BUFFER_START_POSITION, bytesRead); &#125; &#125; catch (IOException e) &#123; logger.error(\"Fail to read input stream\", e); &#125; &#125; else &#123; stringBuilder.append(\"\"); &#125; ecryptedParam = stringBuilder.toString(); &#125; return ecryptedParam; &#125;其他公共类 RequestEnriry123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384public class RequestEnriry &#123; private Map&lt;String, String[]&gt; parameterMap = new HashMap&lt;String, String[]&gt;(); private String parameterBody; private boolean isEncrypt = false; private boolean isReadInputStream = false; private String timestamp = null; public RequestEnriry() &#123; &#125; public RequestEnriry(Map&lt;String, String[]&gt; requestParameterMap) &#123; if (null != requestParameterMap &amp;&amp; !requestParameterMap.isEmpty()) &#123; parameterMap.putAll(requestParameterMap); &#125; &#125; public void handle() &#123; parameterMap.remove(SecurityConstant.ECRYPTED_PARAM_NAME); &#125; public boolean isPass() &#123; boolean isPass = false; if (isEncrypt) &#123; if (StringUtils.isNotEmpty(timestamp)) &#123; isPass = true; &#125; &#125; else &#123; isPass = true; &#125; return isPass; &#125; public Map&lt;String, String[]&gt; getParameterMap() &#123; return parameterMap; &#125; public void setParameterMap(Map&lt;String, String[]&gt; parameterMap) &#123; this.parameterMap = parameterMap; &#125; public void putParameterMap(Map&lt;String, String[]&gt; subParameterMap) &#123; parameterMap.putAll(subParameterMap); &#125; public String getParameterBody() &#123; return parameterBody; &#125; public void setParameterBody(String parameterBody) &#123; this.parameterBody = parameterBody; &#125; public boolean isEncrypt() &#123; return isEncrypt; &#125; public void setEncrypt(boolean encrypt) &#123; isEncrypt = encrypt; &#125; public String getTimestamp() &#123; return timestamp; &#125; public void setTimestamp(String timestamp) &#123; this.timestamp = timestamp; &#125; public boolean isReadInputStream() &#123; return isReadInputStream; &#125; public void setReadInputStream(boolean readInputStream) &#123; isReadInputStream = readInputStream; &#125;&#125;到这一步已经全部完成了，核心思想和代码已经完成","categories":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/categories/加密/"}],"tags":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/tags/加密/"}],"keywords":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/categories/加密/"}]},{"title":"系统加密服务-02","slug":"系统加密服务-02","date":"2018-03-02T23:05:22.000Z","updated":"2019-08-22T05:53:35.408Z","comments":true,"path":"系统加密服务-02.html","link":"","permalink":"http://www.baiyp.ren/系统加密服务-02.html","excerpt":"","text":"系统加密服务-页面JS加密涉及的问题因涉及的页面较多不能一个一个改，只能统一引用，最好使用header引入js的形式能够捕获form表单提交，在提交之前将提交的数据进行加密，并将加密的数据提交，原始数据不提交form表单序列化AJAX数据加密加密方式选择文件上传对于和上传数据一起的参数数据加密问题解决对于第一个问题 写统一的JS进行解决做好兼容性，对于form表单提交加密解决方案： 使用jquery监听form表单的submit方案，如果监听到form提交就将form表单对应输入框的元素进行序列化，序列为JSON数组（因为后台Request接收数组，兼容类似于checkBox重复name）将序列化的JSON进行加密，并将加密的数据插入到表单中，并将加密的输入框元素设置为disabled（这样元素就不会提交了）提交表单就只剩下加密的数据了。123456789101112131415$(function () &#123;//监听form表单提交 $(\"form\").submit(function (data) &#123; //获取提交的URL var url = $(this).attr(\"action\"); //检查是否需要提交 if ($.getSubmit()) &#123; //检查是否需要加密 if ($.isEncrypt(url)) &#123; //数据加密 $(this).formEncryption(); &#125; &#125; &#125;);&#125;);对于form表单序列化解决方案：对于表单序列化要排除一些不需要加密的元素例如file,button,image等，对于checkbox和redio可能存在多个相同的name，要使用JSON数据来接收，用于区分后台接受到“,”分割的字符串springMvc 会自动将request参数数组转换为“,”分割的字符串，但有些很老的代码是不支持的，要兼容底层request区分数组和“,”分割的字符串要使用JSON数组来接收，并将序列化的name值进行保存，用于某些情况下将加密后disable后的元素去掉disabled，并将加密设置为jquery插件的形式使用。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253(function ($) &#123;//需要排除的元素 var excludeInputType = [\"file\", \"button\", \"submit\", \"image\", \"reset\"]; $.fn.extend(&#123; //序列化方法 \"serializeJSON\": function () &#123; //表单数据 var formData = &#123;&#125;; //加密的元素数组 var disabledKeys = []; this.find(\"input,select,textarea\").each(function () &#123; if (!$(this).is(\":disabled\")) &#123; var name = $(this).attr(\"name\"); var value = $(this).val(); var valueArray = new Array(value); var type = $(this).attr(\"type\"); var flag = true; for (var i = 0; i &lt; excludeInputType.length; i++) &#123; if (type == excludeInputType[i]) &#123; flag = false; return true; &#125; &#125; disabledKeys.push(name); switch (type) &#123; case \"checkbox\": if (!$(this).is(':checked')) &#123; return true; &#125; break; case \"radio\": if (!$(this).is(':checked')) &#123; return true; &#125; break; &#125; // var v = $.getJsonValue(formData, name); if (v) &#123; v.push(value); valueArray = v; &#125; formData = $.putJson(formData, name, valueArray); &#125; &#125;); $.setDisableKey(disabledKeys); formData = $.arrayParameterSerialize(formData); return formData; &#125; &#125;);&#125;)对于AJAX数据提交解决方案：使用 $.ajaxPrefilter 捕获ajax提交，得到提交的数据，并进行解析，加密并将原始数据覆盖为新的数据12345678910111213141516171819202122232425262728$.ajaxPrefilter(function (options, originalOptions, jqXHR) &#123;//获取ajax数据 var data = options.data; //获取ajaxurl var url = options.url; //是否需要加密 if ($.isEncrypt(url)) &#123; if (data) &#123; var parameter = &#123;&#125;; //检查字符串是否是json字符串 if ($.strIsJSON(data)) &#123; //将json字符串转换为json对象 parameter = JSON.parse(data); &#125; else &#123; //对于普通的数据?xxx=1&amp; 形式的数据进行解析转换为json对象 parameter = $.parseParameter(data); &#125; //添加时间戳 parameter = $.addTmp(parameter); //数据加密 data = $.encryptData(parameter); var dataJson = &#123;&#125;; dataJson = $.putJson(dataJson, $.getEcryptedParameterName(), data); data = $.jsonToParameter(dataJson); //将原始数据覆盖为加密的数据 options.data = data; &#125; &#125;数据加密解决方案 使用 des形式加密，可以自己定义加密方式，但要保证前后台都能加密解密。加密最好加上时间戳 用于后台检查是否解密成功（如果解密后没有这个时间戳字段代表解密失败）还可以用于其他的作用，例如检查加密的字符串超时时间。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980(function ($) &#123; var isSubmit_disabled = true; var disabled_keys = []; $.ajaxSetup(&#123; contentType: \"application/x-www-form-urlencoded;charset=utf-8\", complete: function (xhr, textStatus) &#123; if (xhr.status == 911) &#123; layer.msg('当前页面已失效，正在刷新浏览器', &#123;icon: 0, shade: 0.8&#125;, function () &#123; window.location.href = $.getRootPath(); &#125;); return false; &#125; &#125; &#125;); $.ajaxPrefilter(function (options, originalOptions, jqXHR) &#123; var data = options.data; var url = options.url; if ($.isEncrypt(url)) &#123; if (data) &#123; var parameter = &#123;&#125;; if ($.strIsJSON(data)) &#123; parameter = JSON.parse(data); &#125; else &#123; parameter = $.parseParameter(data); &#125; parameter = $.addTmp(parameter); data = $.encryptData(parameter); var dataJson = &#123;&#125;; dataJson = $.putJson(dataJson, $.getEcryptedParameterName(), data); data = $.jsonToParameter(dataJson); options.data = data; &#125; &#125; &#125;); $.fn.extend(&#123; formEncryption: function () &#123; var data = &#123;&#125;; var ecryptedParameterName = $.getEcryptedParameterName(); var url = $(this).attr(\"action\"); if ($.isEncrypt(url)) &#123; var inputArray = this.serializeJSON(); if (!inputArray[ecryptedParameterName]) &#123; $(this).disabledForm(); for (var key in inputArray) &#123; var value = inputArray[key]; data = $.putJson(data, key, value); &#125; data = $.addTmp(data); var encData = $.encryptData(data); if ($.isNotEmpty(encData)) &#123; var encDataInput = $(\"&lt;input type='hidden' name = '\" + ecryptedParameterName + \"' value='\" + encData + \"'/&gt;\"); this.append(encDataInput); &#125; &#125; &#125; &#125;, encryptionSubmit: function () &#123; this.formEncryption(); this.submit(); &#125;, disabledForm: function () &#123; var disableKeys = $.getDisableKey(); var ecryptedParameterName = $.getEcryptedParameterName(); for (var i = 0; i &lt; disableKeys.length; i++) &#123; if (disableKeys[i] != ecryptedParameterName) &#123; $(this).find(\"[name='\" + disableKeys[i] + \"']\").attr(\"disabled\", \"disabled\"); &#125; &#125; &#125;, enableForm: function () &#123; var disableKeys = $.getDisableKey(); var ecryptedParameterName = $.getEcryptedParameterName(); $(this).find(\"[name='\" + ecryptedParameterName + \"']\").remove(); for (var i = 0; i &lt; disableKeys.length; i++) &#123; $(this).find(\"[name='\" + disableKeys[i] + \"']\").attr(\"disabled\", false); &#125; &#125; &#125;);上下是一个文件 不知道怎么回事 makedown 显示不全一个完整的123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778 $.extend(&#123; urlDataEncrypt: function (url, extParams) &#123; var secretKey = $.getSecretKey(); var baseUrl = $.parseUrl(url); var params = $.parseUrlParameter(url); params = $.initEncryptParam(params); if ($.isNotEmpty(extParams) &amp;&amp; $.isJson(extParams)) &#123; $.putJson(params, extParams); &#125; var encryptUrl = url; if ($.isEmpty(secretKey)) &#123; encryptUrl = baseUrl + \"?\" + $.jsonToParameter(params); &#125; else &#123; var ecryptedData = $.encryptData(params); params = $.addTmp(params); encryptUrl = baseUrl + \"?\" + $.getEcryptedParameterName() + \"=\" + ecryptedData; &#125; return encryptUrl; &#125;, encryptData: function (data) &#123; var ecryptedData = \"\"; if ($.isJson(data)) &#123; var jsonStr = JSON.stringify(data); ecryptedData = strEnc(jsonStr, $.getSecretKey()); &#125; else &#123; if (!data.match(\"^\\&#123;(.+:.+,*)&#123;1,&#125;\\&#125;$\")) &#123; var params = $.parseParameter(data); var jsonStr = JSON.stringify(params); ecryptedData = strEnc(jsonStr, $.getSecretKey()); &#125; else &#123; var jsonStr = JSON.stringify(jsonData); ecryptedData = strEnc(jsonStr, $.getSecretKey()); &#125; &#125; return ecryptedData; &#125;, initEncryptParam: function (data) &#123; if ($.isEmpty(data)) &#123; data = &#123;&#125;; &#125; else if (!$.isJson(data)) &#123; data = jQuery.parseJSON(data); &#125; data = $.addTmp(data); return data; &#125;, isEncrypt: function (url) &#123; var flag = true; var secretKey = $.getSecretKey(); if ($.isEmpty(secretKey)) &#123; flag = false; &#125; else &#123; var encryptExclude = $.encryptExcludeUrl(); if (encryptExclude &amp;&amp; $.isArray(encryptExclude)) &#123; for (var i = 0; i &lt;= encryptExclude.length; i++) &#123; if (encryptExclude[i] == url) &#123; flag = false; break; &#125; &#125; &#125; &#125; return flag; &#125;, setSubmit: function (obj) &#123; isSubmit_disabled = obj; &#125;, getSubmit: function () &#123; return isSubmit_disabled; &#125;, setDisableKey: function (keys) &#123; if (keys &amp;&amp; keys[0] != $.getEcryptedParameterName()) &#123; disabled_keys = keys; &#125; &#125;, getDisableKey: function () &#123; return disabled_keys; &#125;, &#125;);&#125;)(window.jQuery);","categories":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/categories/加密/"}],"tags":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/tags/加密/"}],"keywords":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/categories/加密/"}]},{"title":"系统加密服务-01","slug":"系统加密服务-01","date":"2018-03-02T23:03:28.000Z","updated":"2019-08-22T01:56:50.871Z","comments":true,"path":"系统加密服务-01.html","link":"","permalink":"http://www.baiyp.ren/系统加密服务-01.html","excerpt":"","text":"系统加密服务需求背景我们公司因为要紧急对系统进行安全加密，以前系统都是参数暴漏的，能够直接获取操作链接等数据，为防止系统关键数据被窃取，系统要进行全面加密，时间只有一个月，上级部门要来进行检查，因涉及到多个系统，上万个页面不能一个一个页面进行加密，特需要一套框架来支持。需要实现的功能对后端透明 后端不需要该任何代码对前端透明 前端不需要或者最好不改代码实现表单放重复提交实现重放攻击拦截实现XSS 脚本跨站攻击实现方案我们系统的讨论了一周时间实现方案如下通过JS 监听ajax 请求和form表单请求 并对请求的数据进行加密通过继承HttpServletRequestWrapper 实现参数解析以及XSS防注入使用拦截器搭配注解实现表单放重复提交在提交的JS中加入时间戳的方式配合拦截器和注解实现防重放攻击总体实现方案加密方式前台数据通过JS对form表单以及AJAX数据进行加密要兼容一些校验框架加密数据需要加入时间戳用于后台检查是否解密成功以及其他用处后台得到加密的数据进行解密通过重写HttpServletRequestWrapper 和OncePerRequestFilter 来实现如果是AJAX提交可能需要PYLOAD形式通过流的形式进行解析表单防重通过TOKEN形式来实现，网上很多实现，这里不多说了XXS防跨站脚本攻击通过将参数中的html代码转义来实现对应的JS加密和Java解密的资源可以查看下载","categories":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/categories/加密/"}],"tags":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/tags/加密/"}],"keywords":[{"name":"加密","slug":"加密","permalink":"http://www.baiyp.ren/categories/加密/"}]},{"title":"MYBATIS热部署","slug":"MYBATIS热部署","date":"2017-08-02T14:41:56.000Z","updated":"2019-08-22T01:57:00.236Z","comments":true,"path":"MYBATIS热部署.html","link":"","permalink":"http://www.baiyp.ren/MYBATIS热部署.html","excerpt":"","text":"mybatis热部署最近在使用mybatis，由于是刚刚开始用，用的并不顺手，目前是感觉有2个地方非常的不好用：mybatis调试不方便​ 由于dao层只有接口，实现只是一个map的xml文件，想加断点都没有地方加，直接导致的后果就是有时候出错了，完全是各种闭眼尝试，抓狂中。。。倒是可以把调试级别改成debug，会把执行的sql，以及参数都输出到控制台，可是一改成debug，那控制台输出的内容，就实在多到让人发指，甚至都会影响到代码的编写及调试，而且输出日志跟打断点调试根本就不是一个级别的。目前仍旧无法解决改问题。mybatis改sql要不停的重启服务​ 这个真心不能忍，map文件在系统重动后，map文件只加载一次，再修改map文件就不会生效了，如果要生效，就需要不停的重启服务。​ 后来找到一个办法，就是使用Mybatis-Plus插件。Mybatis-Plus插件的用法pom.xml的内容：123456789101112131415161718 &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.1&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;1.3.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus&lt;/artifactId&gt; &lt;version&gt;1.5&lt;/version&gt; &lt;scope&gt;system&lt;/scope&gt; &lt;systemPath&gt;$&#123;lib.dir&#125;/mybatis-plus-1.5.jar&lt;/systemPath&gt; &lt;/dependency&gt;​ 因为看Mybatis-Plus插件官网的说法，就是添加Mybatis-Plus插件会添加mybatis的依赖包，我已经引过mybatis的包了，不想让他再给我引了。Mybatis-Plus插件的地址：http://mvnrepository.com/artifact/com.baomidou/mybatis-plus/1.52. 然后修改spring的配置文件： 修改前 123&lt;bean id=\"sqlSessionFactory\" class=\"org.mybatis.spring.SqlSessionFactoryBean\"&gt; &lt;property name=\"dataSource\" ref=\"dynamicDataSource\" /&gt;&lt;property name=\"configLocation\" value=\"classpath:conf/mybatis-config.xml\"&gt;&lt;/property&gt;123456789101112 修改后 ```xml &lt;bean id=&quot;sqlSessionFactory&quot; class=&quot;com.baomidou.mybatisplus.spring.MybatisSqlSessionFactoryBean&quot;&gt; &lt;property name=&quot;dataSource&quot; ref=&quot;dynamicDataSource&quot; /&gt; &lt;property name=&quot;configLocation&quot; value=&quot;classpath:conf/mybatis-config.xml&quot;&gt;&lt;/property&gt; &lt;property name=&quot;mapperLocations&quot; value=&quot;classpath:com/huarui/mapping/$&#123;jdbc.dialect&#125;/*.xml&quot;&gt;&lt;/property&gt; &lt;/bean&gt; &lt;bean class=&quot;com.baomidou.mybatisplus.spring.MybatisMapperRefresh&quot;&gt; &lt;constructor-arg name=&quot;sqlSessionFactory&quot; ref=&quot;sqlSessionFactory&quot;/&gt; &lt;constructor-arg name=&quot;mapperLocations&quot; value=&quot;classpath:com/huarui/mapping/$&#123;jdbc.dialect&#125;/*.xml&quot;/&gt; &lt;constructor-arg name=&quot;delaySeconds&quot; value=&quot;5&quot;/&gt; &lt;constructor-arg name=&quot;sleepSeconds&quot; value=&quot;10&quot;/&gt; &lt;constructor-arg name=&quot;enabled&quot; value=&quot;true&quot;/&gt;&lt;/bean&gt;​ 修改后，改sql就会自动热加载了，其实也不是实时加载，原理是每隔一个时间刷新一下map，我这里设置的是delaySeconds是5秒，sleepSeconds是10秒。​来源: http://www.cnblogs.com/modou/p/6131354.html","categories":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.baiyp.ren/categories/mybatis/"}],"tags":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.baiyp.ren/tags/mybatis/"}],"keywords":[{"name":"mybatis","slug":"mybatis","permalink":"http://www.baiyp.ren/categories/mybatis/"}]},{"title":"关于我","slug":"about","date":"2016-08-03T22:27:45.000Z","updated":"2019-08-22T01:34:10.005Z","comments":true,"path":"about.html","link":"","permalink":"http://www.baiyp.ren/about.html","excerpt":"","text":"关于我白云鹏喜欢学习,研究技术,个人有点懒目前在北京工作，有一天突然发现JAVA 好多知识不会感觉饭碗要保不住了，然后边学习边把一些知识总结下以博客的形式展示出来，做个记录。联系我MAIL：baiyunpeng42@126.comGITHUB：baiyunpeng","categories":[],"tags":[],"keywords":[]}]}